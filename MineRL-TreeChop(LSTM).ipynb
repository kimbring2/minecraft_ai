{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/kimbring2/Steam/pysc2_env/lib/python3.6/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    }
   ],
   "source": [
    "import collections\n",
    "import gym\n",
    "import numpy as np\n",
    "import statistics\n",
    "import tensorflow as tf\n",
    "import tqdm\n",
    "import glob\n",
    "import random\n",
    "from matplotlib import pyplot as plt\n",
    "from tensorflow.keras import layers\n",
    "from typing import Any, List, Sequence, Tuple\n",
    "import gym\n",
    "import minerl\n",
    "import os\n",
    "from IPython.display import clear_output\n",
    "\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_virtual_device_configuration(gpus[0],\n",
    "            [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=4000)])\n",
    "\n",
    "workspace_path = '/media/kimbring2/Steam/minerl_2021'\n",
    "\n",
    "writer = tf.summary.create_file_writer(workspace_path + \"/tensorboard\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ActorCritic(tf.keras.Model):\n",
    "  \"\"\"Combined actor-critic network.\"\"\"\n",
    "  def __init__(\n",
    "      self, \n",
    "      num_actions: int, \n",
    "      num_hidden_units: int):\n",
    "    \"\"\"Initialize.\"\"\"\n",
    "    super().__init__()\n",
    "\n",
    "    self.num_actions = num_actions\n",
    "    \n",
    "    self.conv_1 = layers.Conv2D(16, 8, 4, padding=\"valid\", activation=\"relu\", kernel_regularizer='l2')\n",
    "    self.conv_2 = layers.Conv2D(32, 4, 2, padding=\"valid\", activation=\"relu\", kernel_regularizer='l2')\n",
    "    self.conv_3 = layers.Conv2D(32, 3, 1, padding=\"valid\", activation=\"relu\", kernel_regularizer='l2')\n",
    "    \n",
    "    self.lstm = layers.LSTM(128, return_sequences=True, return_state=True, kernel_regularizer='l2')\n",
    "    \n",
    "    self.common = layers.Dense(num_hidden_units, activation=\"relu\", kernel_regularizer='l2')\n",
    "    self.actor = layers.Dense(num_actions, kernel_regularizer='l2')\n",
    "    self.critic = layers.Dense(1, kernel_regularizer='l2')\n",
    "\n",
    "  def get_config(self):\n",
    "    config = super().get_config().copy()\n",
    "    config.update({\n",
    "        'num_actions': self.num_actions,\n",
    "        'num_hidden_units': self.num_hidden_units\n",
    "    })\n",
    "    return config\n",
    "    \n",
    "  def call(self, inputs: tf.Tensor, memory_state: tf.Tensor, carry_state: tf.Tensor, training) -> Tuple[tf.Tensor, tf.Tensor, \n",
    "                                                                                                        tf.Tensor, tf.Tensor]:\n",
    "    batch_size = tf.shape(inputs)[0]\n",
    "\n",
    "    conv_1 = self.conv_1(inputs)\n",
    "    conv_2 = self.conv_2(conv_1)\n",
    "    conv_3 = self.conv_3(conv_2)\n",
    "    #print(\"conv_3.shape: \", conv_3.shape)\n",
    "    conv_3_reshaped = layers.Reshape((4*4,32))(conv_3)\n",
    "    \n",
    "    initial_state = (memory_state, carry_state)\n",
    "    #print(\"initial_state: \", initial_state)\n",
    "    lstm_output, final_memory_state, final_carry_state  = self.lstm(conv_3_reshaped, initial_state=initial_state, \n",
    "                                                                    training=training)\n",
    "    \n",
    "    X_input = layers.Flatten()(lstm_output)\n",
    "    x = self.common(X_input)\n",
    "    \n",
    "    return tf.keras.layers.Softmax()(self.actor(x)), self.critic(x), final_memory_state, final_carry_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "!export MINERL_DATA_ROOT=/media/kimbring2/6224AA7924AA5039/minerl_data/data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-4-b13fc41e9527>:142: calling DatasetV2.from_generator (from tensorflow.python.data.ops.dataset_ops) with output_types is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use output_signature instead\n"
     ]
    }
   ],
   "source": [
    "import gym\n",
    "import minerl\n",
    "import numpy as np\n",
    "\n",
    "tree_data = minerl.data.make('MineRLTreechop-v0', data_dir=\"/media/kimbring2/6224AA7924AA5039/minerl_data/data\")\n",
    "\n",
    "class TrajetoryDataset(tf.data.Dataset):\n",
    "    def _generator(num_trajectorys):\n",
    "        while True:\n",
    "            trajectory_names = tree_data.get_trajectory_names()\n",
    "            #print(\"len(trajectory_names): \", len(trajectory_names))\n",
    "            \n",
    "            trajectory_name = random.choice(trajectory_names)\n",
    "            print(\"trajectory_name: \", trajectory_name)\n",
    "            \n",
    "            trajectory = tree_data.load_data(trajectory_name, skip_interval=0, include_metadata=False)\n",
    "            #print(\"trajectory: \", trajectory)\n",
    "            \n",
    "            all_actions = []\n",
    "            all_obs = []\n",
    "            for dataset_observation, dataset_action, reward, next_state, done in trajectory:  \n",
    "                #state_pov = dataset_observation['pov']\n",
    "                \n",
    "                inventory_channel = np.zeros((64,64,1))\n",
    "                if 'inventory' in dataset_observation:\n",
    "                    region_max_height = dataset_observation['pov'].shape[0]\n",
    "                    region_max_width = dataset_observation['pov'].shape[1]\n",
    "                    rs = 8\n",
    "                    if min(region_max_height, region_max_width) < rs:\n",
    "                        raise ValueError(\"'region_size' is too large.\")\n",
    "                    num_element_width = region_max_width // rs\n",
    "\n",
    "                    inventory_channel = np.zeros(shape=list(dataset_observation['pov'].shape[:-1]) + [1], \n",
    "                                                 dtype=dataset_observation['pov'].dtype)\n",
    "                    #print(\"state['inventory'].keys(): \" + str(state['inventory'].keys()))\n",
    "                    for key_idx, key in enumerate(dataset_observation['inventory'].keys()):\n",
    "                        #print(\"key.shape : \" + str(key))\n",
    "                        #print(\"state['inventory'][key][i] : \" + str(state['inventory'][key][i]))\n",
    "                        item_scaled = np.clip(1 - 1 / (dataset_observation['inventory'][key] + 1),  # Inversed\n",
    "                                                0, 1)\n",
    "                        #print(\"item_scaled : \" + str(item_scaled))\n",
    "                        item_channel = np.ones(shape=[rs, rs, 1], dtype=dataset_observation['pov'].dtype) * item_scaled\n",
    "                        width_low = (key_idx % num_element_width) * rs\n",
    "                        height_low = (key_idx // num_element_width) * rs\n",
    "\n",
    "                        if height_low + rs > region_max_height:\n",
    "                            raise ValueError(\"Too many elements on 'inventory'. Please decrease 'region_size' of each component.\")\n",
    "\n",
    "                        inventory_channel[height_low:(height_low + rs), width_low:(width_low + rs), :] = item_channel\n",
    "\n",
    "                observation = np.concatenate((dataset_observation['pov'] / 255.0, inventory_channel), axis=2)\n",
    "\n",
    "                action_camera_0 = dataset_action['camera'][0]\n",
    "                action_camera_1 = dataset_action['camera'][1]\n",
    "                action_attack = dataset_action['attack']\n",
    "                action_forward = dataset_action['forward']\n",
    "                action_jump = dataset_action['jump']\n",
    "                action_back = dataset_action['back']\n",
    "                action_left = dataset_action['left']\n",
    "                action_right = dataset_action['right']\n",
    "                action_sneak = dataset_action['sneak']\n",
    "\n",
    "                camera_threshols = (abs(action_camera_0) + abs(action_camera_1)) / 2.0\n",
    "                if (camera_threshols > 2.5):\n",
    "                    if ( (action_camera_1 < 0) & ( abs(action_camera_0) < abs(action_camera_1) ) ):\n",
    "                        if (action_attack == 0):\n",
    "                            action_index = 0\n",
    "                        else:\n",
    "                            action_index = 1\n",
    "                    elif ( (action_camera_1 > 0) & ( abs(action_camera_0) < abs(action_camera_1) ) ):\n",
    "                        if (action_attack == 0):\n",
    "                            action_index = 2\n",
    "                        else:\n",
    "                            action_index = 3\n",
    "                    elif ( (action_camera_0 < 0) & ( abs(action_camera_0) > abs(action_camera_1) ) ):\n",
    "                        if (action_attack == 0):\n",
    "                            action_index = 4\n",
    "                        else:\n",
    "                            action_index = 5\n",
    "                    elif ( (action_camera_0 > 0) & ( abs(action_camera_0) > abs(action_camera_1) ) ):\n",
    "                        if (action_attack == 0):\n",
    "                            action_index = 6\n",
    "                        else:\n",
    "                            action_index = 7\n",
    "\n",
    "                elif (action_forward == 1):\n",
    "                    if (action_attack == 0):\n",
    "                        action_index = 8\n",
    "                    else:\n",
    "                        action_index = 9\n",
    "                elif (action_jump == 1):\n",
    "                    if (action_attack == 0):\n",
    "                        action_index = 10\n",
    "                    else:\n",
    "                        action_index = 11\n",
    "                elif (action_back == 1):\n",
    "                    if (action_attack == 0):\n",
    "                        action_index = 12\n",
    "                    else:\n",
    "                        action_index = 13\n",
    "                elif (action_left == 1):\n",
    "                    if (action_attack == 0):\n",
    "                        action_index = 14\n",
    "                    else:\n",
    "                        action_index = 15\n",
    "                elif (action_right == 1):\n",
    "                    if (action_attack == 0):\n",
    "                        action_index = 16\n",
    "                    else:\n",
    "                        action_index = 17\n",
    "                elif (action_sneak == 1):\n",
    "                    if (action_attack == 0):\n",
    "                        action_index = 18\n",
    "                    else:\n",
    "                        action_index = 19\n",
    "                else:\n",
    "                    continue\n",
    "\n",
    "                if (dataset_action['attack'] == 0 and dataset_action['back'] == 0 and dataset_action['camera'][0] == 0.0 and \n",
    "                    dataset_action['camera'][1] == 0.0 and dataset_action['forward'] == 0 and dataset_action['jump'] == 0 and \n",
    "                    dataset_action['left'] == 0 and dataset_action['right'] == 0 and dataset_action['sneak'] == 0):\n",
    "                    #print(\"continue: \")\n",
    "                    continue\n",
    "\n",
    "                #print(\"observation.shape: \", observation.shape)\n",
    "                #print(\"action_index: \", action_index)\n",
    "                #print(\"done: \", done)\n",
    "\n",
    "                all_obs.append(observation)\n",
    "                all_actions.append(np.array([action_index]))\n",
    "\n",
    "            print(\"len(all_obs): \", len(all_obs))\n",
    "            print(\"\")\n",
    "            yield (all_obs, all_actions)\n",
    "\n",
    "            break\n",
    "    \n",
    "    def __new__(cls, num_trajectorys=3):\n",
    "      return tf.data.Dataset.from_generator(\n",
    "          cls._generator,\n",
    "          output_types=(tf.dtypes.float32, tf.dtypes.int32),\n",
    "          args=(num_trajectorys,)\n",
    "    )\n",
    "\n",
    "dataset = tf.data.Dataset.range(1).interleave(TrajetoryDataset, \n",
    "  num_parallel_calls=tf.data.experimental.AUTOTUNE).batch(1).prefetch(tf.data.experimental.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_actions = 20\n",
    "num_hidden_units = 512\n",
    "\n",
    "#model = tf.keras.models.load_model('MineRL_SL_Model')\n",
    "model = ActorCritic(num_actions, num_hidden_units)\n",
    "#model.load_weights(\"model/MineRL_SL_Model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "cce_loss = tf.keras.losses.CategoricalCrossentropy()\n",
    "optimizer = tf.keras.optimizers.Adam(0.0001)\n",
    "\n",
    "@tf.function\n",
    "def supervised_replay(replay_obs_list, replay_act_list, memory_state, carry_state):\n",
    "    replay_obs_array = tf.concat(replay_obs_list, 0)\n",
    "    replay_act_array = tf.concat(replay_act_list, 0)\n",
    "    replay_memory_state_array = tf.concat(memory_state, 0)\n",
    "    replay_carry_state_array = tf.concat(carry_state, 0)\n",
    "\n",
    "    memory_state = replay_memory_state_array\n",
    "    carry_state = replay_carry_state_array\n",
    "\n",
    "    batch_size = replay_obs_array.shape[0]\n",
    "    tf.print(\"batch_size: \", batch_size)\n",
    "    \n",
    "    with tf.GradientTape() as tape:\n",
    "        act_probs = tf.TensorArray(dtype=tf.float32, size=0, dynamic_size=True)\n",
    "        for i in tf.range(0, batch_size):\n",
    "            prediction = model(tf.expand_dims(replay_obs_array[i,:,:,:], 0), memory_state, carry_state, training=True)\n",
    "            act_pi = prediction[0]\n",
    "            memory_state = prediction[2]\n",
    "            carry_state = prediction[3]\n",
    "        \n",
    "            act_probs = act_probs.write(i, act_pi[0])\n",
    "\n",
    "        act_probs = act_probs.stack()\n",
    "\n",
    "        tf.print(\"replay_act_array: \", replay_act_array)\n",
    "        tf.print(\"tf.argmax(act_probs, 1): \", tf.argmax(act_probs, 1))\n",
    "\n",
    "        replay_act_array_onehot = tf.one_hot(replay_act_array, num_actions)\n",
    "        replay_act_array_onehot = tf.reshape(replay_act_array_onehot, (batch_size, num_actions))\n",
    "        act_loss = cce_loss(replay_act_array_onehot, act_probs)\n",
    "\n",
    "        #tf.print(\"act_loss: \", act_loss)\n",
    "        regularization_loss = tf.reduce_sum(model.losses)\n",
    "        total_loss = act_loss + 1e-5 * regularization_loss\n",
    "    \n",
    "        #tf.print(\"total_loss: \", total_loss)\n",
    "        #tf.print(\"\")\n",
    "        \n",
    "    grads = tape.gradient(total_loss, model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
    "\n",
    "    return total_loss, memory_state, carry_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trajectory_name:  v3_remorseful_current_savage-1_4442-6943\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2461/2461 [00:00<00:00, 8776.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(all_obs):  988\n",
      "\n",
      "episode_size:  988\n",
      "batch_size:  32\n",
      "replay_act_array:  [[8]\n",
      " [8]\n",
      " [8]\n",
      " ...\n",
      " [8]\n",
      " [8]\n",
      " [8]]\n",
      "tf.argmax(act_probs, 1):  [8 8 8 ... 8 8 8]\n",
      "total_loss:  tf.Tensor(0.124798596, shape=(), dtype=float32)\n",
      "\n",
      "batch_size:  32\n",
      "replay_act_array:  [[8]\n",
      " [8]\n",
      " [8]\n",
      " ...\n",
      " [3]\n",
      " [3]\n",
      " [3]]\n",
      "tf.argmax(act_probs, 1):  [8 8 8 ... 8 8 8]\n",
      "total_loss:  tf.Tensor(1.4398816, shape=(), dtype=float32)\n",
      "\n",
      "batch_size:  32\n",
      "replay_act_array:  [[3]\n",
      " [3]\n",
      " [5]\n",
      " ...\n",
      " [8]\n",
      " [8]\n",
      " [8]]\n",
      "tf.argmax(act_probs, 1):  [8 8 8 ... 8 8 8]\n",
      "total_loss:  tf.Tensor(1.9246454, shape=(), dtype=float32)\n",
      "\n",
      "batch_size:  32\n",
      "replay_act_array:  [[8]\n",
      " [8]\n",
      " [8]\n",
      " ...\n",
      " [15]\n",
      " [15]\n",
      " [9]]\n",
      "tf.argmax(act_probs, 1):  [8 8 8 ... 8 8 8]\n",
      "total_loss:  tf.Tensor(1.3502458, shape=(), dtype=float32)\n",
      "\n",
      "batch_size:  32\n",
      "replay_act_array:  [[9]\n",
      " [7]\n",
      " [7]\n",
      " ...\n",
      " [3]\n",
      " [3]\n",
      " [3]]\n",
      "tf.argmax(act_probs, 1):  [8 8 8 ... 6 8 8]\n",
      "total_loss:  tf.Tensor(2.4858916, shape=(), dtype=float32)\n",
      "\n",
      "batch_size:  32\n",
      "replay_act_array:  [[2]\n",
      " [8]\n",
      " [8]\n",
      " ...\n",
      " [8]\n",
      " [8]\n",
      " [8]]\n",
      "tf.argmax(act_probs, 1):  [8 8 8 ... 8 8 8]\n",
      "total_loss:  tf.Tensor(1.9686335, shape=(), dtype=float32)\n",
      "\n",
      "batch_size:  32\n",
      "replay_act_array:  [[8]\n",
      " [8]\n",
      " [8]\n",
      " ...\n",
      " [8]\n",
      " [8]\n",
      " [8]]\n",
      "tf.argmax(act_probs, 1):  [8 8 8 ... 8 8 8]\n",
      "total_loss:  tf.Tensor(0.63076377, shape=(), dtype=float32)\n",
      "\n",
      "batch_size:  32\n",
      "replay_act_array:  [[8]\n",
      " [8]\n",
      " [8]\n",
      " ...\n",
      " [7]\n",
      " [7]\n",
      " [9]]\n",
      "tf.argmax(act_probs, 1):  [8 8 8 ... 8 8 8]\n",
      "total_loss:  tf.Tensor(1.3712908, shape=(), dtype=float32)\n",
      "\n",
      "batch_size:  32\n",
      "replay_act_array:  [[9]\n",
      " [9]\n",
      " [7]\n",
      " ...\n",
      " [5]\n",
      " [5]\n",
      " [5]]\n",
      "tf.argmax(act_probs, 1):  [5 5 5 ... 8 8 8]\n",
      "total_loss:  tf.Tensor(1.8213748, shape=(), dtype=float32)\n",
      "\n",
      "batch_size:  32\n",
      "replay_act_array:  [[9]\n",
      " [9]\n",
      " [9]\n",
      " ...\n",
      " [3]\n",
      " [7]\n",
      " [7]]\n",
      "tf.argmax(act_probs, 1):  [8 8 8 ... 8 8 8]\n",
      "total_loss:  tf.Tensor(2.012347, shape=(), dtype=float32)\n",
      "\n",
      "batch_size:  32\n",
      "replay_act_array:  [[7]\n",
      " [7]\n",
      " [7]\n",
      " ...\n",
      " [6]\n",
      " [8]\n",
      " [2]]\n",
      "tf.argmax(act_probs, 1):  [8 8 9 ... 9 9 9]\n",
      "total_loss:  tf.Tensor(2.3019073, shape=(), dtype=float32)\n",
      "\n",
      "batch_size:  32\n",
      "replay_act_array:  [[8]\n",
      " [8]\n",
      " [8]\n",
      " ...\n",
      " [8]\n",
      " [8]\n",
      " [8]]\n",
      "tf.argmax(act_probs, 1):  [9 8 8 ... 6 6 6]\n",
      "total_loss:  tf.Tensor(1.8832577, shape=(), dtype=float32)\n",
      "\n",
      "batch_size:  32\n",
      "replay_act_array:  [[8]\n",
      " [8]\n",
      " [8]\n",
      " ...\n",
      " [5]\n",
      " [17]\n",
      " [17]]\n",
      "tf.argmax(act_probs, 1):  [9 9 9 ... 8 8 8]\n",
      "total_loss:  tf.Tensor(2.4417422, shape=(), dtype=float32)\n",
      "\n",
      "batch_size:  32\n",
      "replay_act_array:  [[1]\n",
      " [1]\n",
      " [5]\n",
      " ...\n",
      " [8]\n",
      " [8]\n",
      " [8]]\n",
      "tf.argmax(act_probs, 1):  [8 8 8 ... 8 8 8]\n",
      "total_loss:  tf.Tensor(2.2537863, shape=(), dtype=float32)\n",
      "\n",
      "batch_size:  32\n",
      "replay_act_array:  [[8]\n",
      " [8]\n",
      " [2]\n",
      " ...\n",
      " [15]\n",
      " [3]\n",
      " [3]]\n",
      "tf.argmax(act_probs, 1):  [8 8 8 ... 8 8 8]\n",
      "total_loss:  tf.Tensor(2.068126, shape=(), dtype=float32)\n",
      "\n",
      "batch_size:  32\n",
      "replay_act_array:  [[4]\n",
      " [4]\n",
      " [4]\n",
      " ...\n",
      " [0]\n",
      " [6]\n",
      " [6]]\n",
      "tf.argmax(act_probs, 1):  [8 8 8 ... 8 8 8]\n",
      "total_loss:  tf.Tensor(2.804551, shape=(), dtype=float32)\n",
      "\n",
      "batch_size:  32\n",
      "replay_act_array:  [[8]\n",
      " [8]\n",
      " [0]\n",
      " ...\n",
      " [9]\n",
      " [9]\n",
      " [1]]\n",
      "tf.argmax(act_probs, 1):  [8 8 8 ... 8 8 8]\n",
      "total_loss:  tf.Tensor(1.7790563, shape=(), dtype=float32)\n",
      "\n",
      "batch_size:  32\n",
      "replay_act_array:  [[1]\n",
      " [3]\n",
      " [3]\n",
      " ...\n",
      " [0]\n",
      " [6]\n",
      " [0]]\n",
      "tf.argmax(act_probs, 1):  [8 8 8 ... 6 6 6]\n",
      "total_loss:  tf.Tensor(2.748619, shape=(), dtype=float32)\n",
      "\n",
      "batch_size:  32\n",
      "replay_act_array:  [[6]\n",
      " [14]\n",
      " [14]\n",
      " ...\n",
      " [5]\n",
      " [5]\n",
      " [3]]\n",
      "tf.argmax(act_probs, 1):  [8 6 6 ... 8 8 8]\n",
      "total_loss:  tf.Tensor(2.1712945, shape=(), dtype=float32)\n",
      "\n",
      "batch_size:  32\n",
      "replay_act_array:  [[9]\n",
      " [9]\n",
      " [9]\n",
      " ...\n",
      " [5]\n",
      " [5]\n",
      " [5]]\n",
      "tf.argmax(act_probs, 1):  [8 8 8 ... 5 5 6]\n",
      "total_loss:  tf.Tensor(1.9227997, shape=(), dtype=float32)\n",
      "\n",
      "batch_size:  32\n",
      "replay_act_array:  [[0]\n",
      " [0]\n",
      " [6]\n",
      " ...\n",
      " [8]\n",
      " [8]\n",
      " [8]]\n",
      "tf.argmax(act_probs, 1):  [6 6 6 ... 8 8 8]\n",
      "total_loss:  tf.Tensor(1.928064, shape=(), dtype=float32)\n",
      "\n",
      "batch_size:  32\n",
      "replay_act_array:  [[2]\n",
      " [2]\n",
      " [2]\n",
      " ...\n",
      " [8]\n",
      " [8]\n",
      " [8]]\n",
      "tf.argmax(act_probs, 1):  [8 8 8 ... 8 8 8]\n",
      "total_loss:  tf.Tensor(1.2342528, shape=(), dtype=float32)\n",
      "\n",
      "batch_size:  32\n",
      "replay_act_array:  [[8]\n",
      " [4]\n",
      " [4]\n",
      " ...\n",
      " [9]\n",
      " [9]\n",
      " [9]]\n",
      "tf.argmax(act_probs, 1):  [8 8 8 ... 8 8 8]\n",
      "total_loss:  tf.Tensor(1.6450728, shape=(), dtype=float32)\n",
      "\n",
      "batch_size:  32\n",
      "replay_act_array:  [[5]\n",
      " [5]\n",
      " [5]\n",
      " ...\n",
      " [5]\n",
      " [5]\n",
      " [5]]\n",
      "tf.argmax(act_probs, 1):  [8 8 5 ... 8 8 8]\n",
      "total_loss:  tf.Tensor(2.1555502, shape=(), dtype=float32)\n",
      "\n",
      "batch_size:  32\n",
      "replay_act_array:  [[5]\n",
      " [9]\n",
      " [9]\n",
      " ...\n",
      " [8]\n",
      " [0]\n",
      " [0]]\n",
      "tf.argmax(act_probs, 1):  [9 9 9 ... 8 8 8]\n",
      "total_loss:  tf.Tensor(2.1519134, shape=(), dtype=float32)\n",
      "\n",
      "batch_size:  32\n",
      "replay_act_array:  [[0]\n",
      " [8]\n",
      " [8]\n",
      " ...\n",
      " [0]\n",
      " [1]\n",
      " [9]]\n",
      "tf.argmax(act_probs, 1):  [8 8 8 ... 8 8 8]\n",
      "total_loss:  tf.Tensor(1.0182548, shape=(), dtype=float32)\n",
      "\n",
      "batch_size:  32\n",
      "replay_act_array:  [[9]\n",
      " [9]\n",
      " [9]\n",
      " ...\n",
      " [11]\n",
      " [9]\n",
      " [9]]\n",
      "tf.argmax(act_probs, 1):  [8 8 8 ... 8 8 8]\n",
      "total_loss:  tf.Tensor(2.2209313, shape=(), dtype=float32)\n",
      "\n",
      "batch_size:  32\n",
      "replay_act_array:  [[9]\n",
      " [9]\n",
      " [9]\n",
      " ...\n",
      " [8]\n",
      " [8]\n",
      " [8]]\n",
      "tf.argmax(act_probs, 1):  [8 8 8 ... 8 8 8]\n"
     ]
    }
   ],
   "source": [
    "def supervised_train(dataset, training_episode):\n",
    "    for batch in dataset:\n",
    "        episode_size = batch[0].shape[1]\n",
    "        print(\"episode_size: \", episode_size)\n",
    "    \n",
    "        replay_obs_list = batch[0][0]\n",
    "        replay_act_list = batch[1][0]\n",
    "     \n",
    "        memory_state = np.zeros([1,128], dtype=np.float32)\n",
    "        carry_state =  np.zeros([1,128], dtype=np.float32)\n",
    "        step_length = 32\n",
    "        for episode_index in range(0, episode_size, step_length):\n",
    "            obs = replay_obs_list[episode_index:episode_index+step_length,:,:,:]\n",
    "            act = replay_act_list[episode_index:episode_index+step_length,:]\n",
    "            \n",
    "            #print(\"len(obs): \", len(obs))\n",
    "            if len(obs) != step_length:\n",
    "                break\n",
    "            \n",
    "            total_loss, next_memory_state, next_carry_state = supervised_replay(obs, act, memory_state, carry_state)\n",
    "            memory_state = next_memory_state\n",
    "            carry_state = next_carry_state\n",
    "        \n",
    "            print(\"total_loss: \", total_loss)\n",
    "            print(\"\")\n",
    "            \n",
    "        with writer.as_default():\n",
    "            tf.summary.scalar(\"total_loss\", total_loss, step=training_episode)\n",
    "            writer.flush()\n",
    "\n",
    "        if training_episode % 100 == 0:\n",
    "            model.save_weights(workspace_path + '/model/supervised_model_' + str(training_episode))\n",
    "            \n",
    "        clear_output(wait=True)\n",
    "        \n",
    "for training_episode in range(0, 2000000):\n",
    "    supervised_train(dataset, training_episode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def render(obs):\n",
    "    obs = cv2.cvtColor(obs, cv2.COLOR_RGB2BGR)\n",
    "    cv2.imshow('obs', obs)\n",
    "    cv2.waitKey(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "import gym\n",
    "import numpy as np\n",
    "import statistics\n",
    "import tensorflow as tf\n",
    "import tqdm\n",
    "import glob\n",
    "import random\n",
    "import cv2\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from tensorflow.keras import layers\n",
    "from typing import Any, List, Sequence, Tuple\n",
    "import tensorflow_probability as tfp\n",
    "\n",
    "tfd = tfp.distributions\n",
    "\n",
    "import gym\n",
    "import minerl\n",
    "\n",
    "model.load_weights(workspace_path + \"/model/supervised_model_12000\")\n",
    "\n",
    "# Create the environment\n",
    "env = gym.make('MineRLTreechop-v0')\n",
    "\n",
    "seed = 980\n",
    "env.seed(seed)\n",
    "tf.random.set_seed(seed)\n",
    "np.random.seed(seed)\n",
    "\n",
    "reward_sum = 0\n",
    "for i_episode in range(0, 10000):\n",
    "    observation = env.reset()\n",
    "    \n",
    "    inventory_channel = np.zeros((64,64,1))\n",
    "    if 'inventory' in observation:\n",
    "        region_max_height = observation['pov'].shape[0]\n",
    "        region_max_width = observation['pov'].shape[1]\n",
    "        rs = 8\n",
    "        if min(region_max_height, region_max_width) < rs:\n",
    "            raise ValueError(\"'region_size' is too large.\")\n",
    "            \n",
    "        num_element_width = region_max_width // rs\n",
    "\n",
    "        inventory_channel = np.zeros(shape=list(observation['pov'].shape[:-1]) + [1], \n",
    "                                     dtype=observation['pov'].dtype)\n",
    "        #print(\"state['inventory'].keys(): \" + str(state['inventory'].keys()))\n",
    "        for key_idx, key in enumerate(observation['inventory'].keys()):\n",
    "            #print(\"key.shape : \" + str(key))\n",
    "            #print(\"state['inventory'][key][i] : \" + str(state['inventory'][key][i]))\n",
    "            item_scaled = np.clip(1 - 1 / (observation['inventory'][key] + 1),  # Inversed\n",
    "                                  0, 1)\n",
    "            #print(\"item_scaled : \" + str(item_scaled))\n",
    "            item_channel = np.ones(shape=[rs, rs, 1], dtype=observation['pov'].dtype) * item_scaled\n",
    "            width_low = (key_idx % num_element_width) * rs\n",
    "            height_low = (key_idx // num_element_width) * rs\n",
    "\n",
    "            if height_low + rs > region_max_height:\n",
    "                raise ValueError(\"Too many elements on 'inventory'. Please decrease 'region_size' of each component.\")\n",
    "\n",
    "            inventory_channel[height_low:(height_low + rs), width_low:(width_low + rs), :] = item_channel\n",
    "\n",
    "    state = np.concatenate((observation['pov'] / 255.0, inventory_channel), axis=2)\n",
    "    state = tf.constant(state, dtype=tf.float32)\n",
    "    \n",
    "    memory_state = tf.zeros([1,128], dtype=np.float32)\n",
    "    carry_state = tf.zeros([1,128], dtype=np.float32)\n",
    "    step = 0\n",
    "    while True:\n",
    "        step += 1\n",
    "\n",
    "        state = tf.expand_dims(state, 0)\n",
    "        action_probs, _, memory_state, carry_state = model(state, memory_state, carry_state)\n",
    "        \n",
    "        action_dist = tfd.Categorical(probs=action_probs)\n",
    "        action_index = int(action_dist.sample()[0])\n",
    "        #print(\"action_index: \", action_index)\n",
    "        #if random.random() <= 0.01:\n",
    "        #    action_index = random.randint(0,18)\n",
    "        #else:\n",
    "        #    action_index = np.argmax(np.squeeze(action_probs))\n",
    "        #print(\"action_index: \", action_index)\n",
    "        \n",
    "        action = env.action_space.noop()\n",
    "        if (action_index == 0):\n",
    "            action['camera'] = [0, -5]\n",
    "            action['attack'] = 0\n",
    "        elif (action_index == 1):\n",
    "            action['camera'] = [0, -5]\n",
    "            action['attack'] = 1\n",
    "        elif (action_index == 2):\n",
    "            action['camera'] = [0, 5]\n",
    "            action['attack'] = 0\n",
    "        elif (action_index == 3):\n",
    "            action['camera'] = [0, 5]\n",
    "            action['attack'] = 1\n",
    "        elif (action_index == 4):\n",
    "            action['camera'] = [-5, 0]\n",
    "            action['attack'] = 0\n",
    "        elif (action_index == 5):\n",
    "            action['camera'] = [-5, 0]\n",
    "            action['attack'] = 1\n",
    "        elif (action_index == 6):\n",
    "            action['camera'] = [5, 0]\n",
    "            action['attack'] = 0\n",
    "        elif (action_index == 7):\n",
    "            action['camera'] = [5, 0]\n",
    "            \n",
    "        elif (action_index == 8):\n",
    "            action['forward'] = 1\n",
    "            action['attack'] = 0\n",
    "        elif (action_index == 9):\n",
    "            action['forward'] = 1\n",
    "            action['attack'] = 1\n",
    "            \n",
    "        elif (action_index == 10):\n",
    "            action['jump'] = 1\n",
    "            action['attack'] = 0\n",
    "        elif (action_index == 11):\n",
    "            action['jump'] = 1\n",
    "            action['attack'] = 1\n",
    "            \n",
    "        elif (action_index == 12):\n",
    "            action['back'] = 1\n",
    "            action['attack'] = 0\n",
    "        elif (action_index == 13):\n",
    "            action['back'] = 1\n",
    "            action['attack'] = 1\n",
    "            \n",
    "        elif (action_index == 14):\n",
    "            action['left'] = 1\n",
    "            action['attack'] = 0\n",
    "        elif (action_index == 15):\n",
    "            action['left'] = 1\n",
    "            action['attack'] = 1\n",
    "            \n",
    "        elif (action_index == 16):\n",
    "            action['right'] = 1\n",
    "            action['attack'] = 0\n",
    "        elif (action_index == 17):\n",
    "            action['right'] = 1\n",
    "            action['attack'] = 1 \n",
    "            \n",
    "        elif (action_index == 18):\n",
    "            action['sneak'] = 1\n",
    "            action['attack'] = 0\n",
    "        elif (action_index == 19):\n",
    "            action['sneak'] = 1\n",
    "            action['attack'] = 1 \n",
    "        \n",
    "        observation_1, reward, done, info = env.step(action)\n",
    "        render(observation_1['pov'])\n",
    "        \n",
    "        inventory_channel_1 = np.zeros((64,64,1))\n",
    "        if 'inventory' in observation_1:\n",
    "            region_max_height = observation_1['pov'].shape[0]\n",
    "            region_max_width = observation_1['pov'].shape[1]\n",
    "            rs = 8\n",
    "            if min(region_max_height, region_max_width) < rs:\n",
    "                raise ValueError(\"'region_size' is too large.\")\n",
    "                \n",
    "            num_element_width = region_max_width // rs\n",
    "\n",
    "            inventory_channel_1 = np.zeros(shape=list(observation_1['pov'].shape[:-1]) + [1], \n",
    "                                           dtype=observation_1['pov'].dtype)\n",
    "            #print(\"state['inventory'].keys(): \" + str(state['inventory'].keys()))\n",
    "            for key_idx, key in enumerate(observation_1['inventory'].keys()):\n",
    "                #print(\"key.shape : \" + str(key))\n",
    "                #print(\"state['inventory'][key][i] : \" + str(state['inventory'][key][i]))\n",
    "                item_scaled = np.clip(1 - 1 / (observation_1['inventory'][key] + 1),  # Inversed\n",
    "                                      0, 1)\n",
    "                #print(\"item_scaled : \" + str(item_scaled))\n",
    "                item_channel = np.ones(shape=[rs, rs, 1], dtype=observation_1['pov'].dtype) * item_scaled\n",
    "                width_low = (key_idx % num_element_width) * rs\n",
    "                height_low = (key_idx // num_element_width) * rs\n",
    "\n",
    "                if height_low + rs > region_max_height:\n",
    "                    raise ValueError(\"Too many elements on 'inventory'. Please decrease 'region_size' of each component.\")\n",
    "\n",
    "                inventory_channel_1[height_low:(height_low + rs), width_low:(width_low + rs), :] = item_channel\n",
    "\n",
    "        next_state = np.concatenate((observation_1['pov'] / 255.0, inventory_channel_1), axis=2)\n",
    "        next_state = tf.constant(next_state, dtype=tf.float32)\n",
    "        \n",
    "        reward_sum += reward\n",
    "\n",
    "        state = next_state\n",
    "        if done:\n",
    "            print(\"Total reward: {:.2f},  Total step: {:.2f}\".format(reward_sum, step))\n",
    "            step = 0\n",
    "            reward_sum = 0  \n",
    "            #observation = env.reset()\n",
    "            break\n",
    "\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import minerl\n",
    "import gym\n",
    "import cv2\n",
    "env = gym.make('MineRLNavigateDense-v0')\n",
    "\n",
    "\n",
    "obs  = env.reset()\n",
    "done = False\n",
    "net_reward = 0\n",
    "\n",
    "\n",
    "def render(obs):\n",
    "    obs = cv2.cvtColor(obs, cv2.COLOR_RGB2BGR)\n",
    "    cv2.imshow('obs', obs)\n",
    "    cv2.waitKey(1)\n",
    "\n",
    "    \n",
    "while not done:\n",
    "    action = env.action_space.noop()\n",
    "\n",
    "    action['camera'] = [0, 0.03*obs[\"compass\"][\"angle\"]]\n",
    "    action['back'] = 0\n",
    "    action['forward'] = 1\n",
    "    action['jump'] = 1\n",
    "    action['attack'] = 1\n",
    "\n",
    "    obs, reward, done, info = env.step(action)\n",
    "    #print(\"obs.keys(): \", obs.keys())\n",
    "    render(obs['pov'])\n",
    "    \n",
    "    net_reward += reward\n",
    "    print(\"Total reward: \", net_reward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pysc2_env",
   "language": "python",
   "name": "pysc2_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
