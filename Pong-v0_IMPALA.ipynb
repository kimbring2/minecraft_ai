{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total_step:  1014\n",
      "episode: 0/200000, thread: 0, score: -21.0, average: -21.00 SAVING\n",
      "total_step:  2138\n",
      "episode: 1/200000, thread: 0, score: -21.0, average: -21.00 SAVING\n",
      "total_step:  3538\n",
      "episode: 2/200000, thread: 0, score: -19.0, average: -20.33 SAVING\n",
      "total_step:  4541\n",
      "episode: 3/200000, thread: 0, score: -21.0, average: -20.50 \n",
      "total_step:  5645\n",
      "episode: 4/200000, thread: 0, score: -21.0, average: -20.60 \n",
      "total_step:  6825\n",
      "episode: 5/200000, thread: 0, score: -21.0, average: -20.67 \n",
      "total_step:  8175\n",
      "episode: 6/200000, thread: 0, score: -19.0, average: -20.43 \n",
      "total_step:  9353\n",
      "episode: 7/200000, thread: 0, score: -20.0, average: -20.38 \n",
      "total_step:  10375\n",
      "episode: 8/200000, thread: 0, score: -21.0, average: -20.44 \n",
      "total_step:  11682\n",
      "episode: 9/200000, thread: 0, score: -20.0, average: -20.40 \n",
      "total_step:  12972\n",
      "episode: 10/200000, thread: 0, score: -21.0, average: -20.45 \n",
      "total_step:  14344\n",
      "episode: 11/200000, thread: 0, score: -19.0, average: -20.33 SAVING\n",
      "total_step:  15376\n",
      "episode: 12/200000, thread: 0, score: -21.0, average: -20.38 \n",
      "total_step:  16551\n",
      "episode: 13/200000, thread: 0, score: -21.0, average: -20.43 \n",
      "total_step:  17932\n",
      "episode: 14/200000, thread: 0, score: -21.0, average: -20.47 \n",
      "total_step:  19037\n",
      "episode: 15/200000, thread: 0, score: -21.0, average: -20.50 \n",
      "total_step:  20256\n",
      "episode: 16/200000, thread: 0, score: -21.0, average: -20.53 \n",
      "total_step:  21485\n",
      "episode: 17/200000, thread: 0, score: -20.0, average: -20.50 \n",
      "total_step:  22662\n",
      "episode: 18/200000, thread: 0, score: -21.0, average: -20.53 \n",
      "total_step:  23793\n",
      "episode: 19/200000, thread: 0, score: -21.0, average: -20.55 \n",
      "total_step:  24952\n",
      "episode: 20/200000, thread: 0, score: -20.0, average: -20.52 \n",
      "total_step:  26139\n",
      "episode: 21/200000, thread: 0, score: -20.0, average: -20.50 \n",
      "total_step:  27236\n",
      "episode: 22/200000, thread: 0, score: -21.0, average: -20.52 \n",
      "total_step:  28617\n",
      "episode: 23/200000, thread: 0, score: -20.0, average: -20.50 \n",
      "total_step:  29827\n",
      "episode: 24/200000, thread: 0, score: -20.0, average: -20.48 \n",
      "total_step:  31138\n",
      "episode: 25/200000, thread: 0, score: -20.0, average: -20.46 \n",
      "total_step:  32438\n",
      "episode: 26/200000, thread: 0, score: -20.0, average: -20.44 \n",
      "total_step:  33529\n",
      "episode: 27/200000, thread: 0, score: -21.0, average: -20.46 \n",
      "total_step:  35239\n",
      "episode: 28/200000, thread: 0, score: -18.0, average: -20.38 \n",
      "total_step:  36396\n",
      "episode: 29/200000, thread: 0, score: -20.0, average: -20.37 \n",
      "total_step:  37546\n",
      "episode: 30/200000, thread: 0, score: -20.0, average: -20.35 \n",
      "total_step:  38648\n",
      "episode: 31/200000, thread: 0, score: -21.0, average: -20.38 \n",
      "total_step:  39994\n",
      "episode: 32/200000, thread: 0, score: -21.0, average: -20.39 \n",
      "total_step:  41120\n",
      "episode: 33/200000, thread: 0, score: -21.0, average: -20.41 \n",
      "total_step:  42414\n",
      "episode: 34/200000, thread: 0, score: -21.0, average: -20.43 \n",
      "total_step:  43648\n",
      "episode: 35/200000, thread: 0, score: -21.0, average: -20.44 \n",
      "total_step:  44981\n",
      "episode: 36/200000, thread: 0, score: -19.0, average: -20.41 \n",
      "total_step:  46085\n",
      "episode: 37/200000, thread: 0, score: -21.0, average: -20.42 \n",
      "total_step:  47211\n",
      "episode: 38/200000, thread: 0, score: -20.0, average: -20.41 \n",
      "total_step:  48325\n",
      "episode: 39/200000, thread: 0, score: -21.0, average: -20.43 \n",
      "total_step:  49642\n",
      "episode: 40/200000, thread: 0, score: -19.0, average: -20.39 \n",
      "total_step:  51056\n",
      "episode: 41/200000, thread: 0, score: -21.0, average: -20.40 \n",
      "total_step:  52076\n",
      "episode: 42/200000, thread: 0, score: -21.0, average: -20.42 \n",
      "total_step:  53099\n",
      "episode: 43/200000, thread: 0, score: -21.0, average: -20.43 \n",
      "total_step:  54116\n",
      "episode: 44/200000, thread: 0, score: -21.0, average: -20.44 \n",
      "total_step:  55309\n",
      "episode: 45/200000, thread: 0, score: -20.0, average: -20.43 \n",
      "total_step:  56768\n",
      "episode: 46/200000, thread: 0, score: -18.0, average: -20.38 \n",
      "total_step:  58136\n",
      "episode: 47/200000, thread: 0, score: -21.0, average: -20.40 \n",
      "total_step:  59342\n",
      "episode: 48/200000, thread: 0, score: -20.0, average: -20.39 \n",
      "total_step:  60494\n",
      "episode: 49/200000, thread: 0, score: -21.0, average: -20.40 \n",
      "total_step:  61766\n",
      "episode: 50/200000, thread: 0, score: -20.0, average: -20.38 \n",
      "total_step:  62985\n",
      "episode: 51/200000, thread: 0, score: -20.0, average: -20.36 \n",
      "total_step:  64112\n",
      "episode: 52/200000, thread: 0, score: -21.0, average: -20.40 \n",
      "total_step:  65235\n",
      "episode: 53/200000, thread: 0, score: -20.0, average: -20.38 \n",
      "total_step:  66289\n",
      "episode: 54/200000, thread: 0, score: -21.0, average: -20.38 \n",
      "total_step:  67736\n",
      "episode: 55/200000, thread: 0, score: -19.0, average: -20.34 \n",
      "total_step:  69156\n",
      "episode: 56/200000, thread: 0, score: -19.0, average: -20.34 \n",
      "total_step:  70277\n",
      "episode: 57/200000, thread: 0, score: -21.0, average: -20.36 \n",
      "total_step:  71300\n",
      "episode: 58/200000, thread: 0, score: -21.0, average: -20.36 \n",
      "total_step:  72410\n",
      "episode: 59/200000, thread: 0, score: -21.0, average: -20.38 \n",
      "total_step:  73650\n",
      "episode: 60/200000, thread: 0, score: -20.0, average: -20.36 \n",
      "total_step:  74857\n",
      "episode: 61/200000, thread: 0, score: -20.0, average: -20.38 \n",
      "total_step:  75965\n",
      "episode: 62/200000, thread: 0, score: -21.0, average: -20.38 \n",
      "total_step:  77528\n",
      "episode: 63/200000, thread: 0, score: -17.0, average: -20.30 SAVING\n",
      "total_step:  78574\n",
      "episode: 64/200000, thread: 0, score: -21.0, average: -20.30 SAVING\n",
      "total_step:  79863\n",
      "episode: 65/200000, thread: 0, score: -21.0, average: -20.30 SAVING\n",
      "total_step:  81125\n",
      "episode: 66/200000, thread: 0, score: -20.0, average: -20.28 SAVING\n",
      "total_step:  82357\n",
      "episode: 67/200000, thread: 0, score: -20.0, average: -20.28 SAVING\n",
      "total_step:  83372\n",
      "episode: 68/200000, thread: 0, score: -21.0, average: -20.28 SAVING\n",
      "total_step:  85119\n",
      "episode: 69/200000, thread: 0, score: -18.0, average: -20.22 SAVING\n",
      "total_step:  86569\n",
      "episode: 70/200000, thread: 0, score: -20.0, average: -20.22 SAVING\n",
      "total_step:  87869\n",
      "episode: 71/200000, thread: 0, score: -21.0, average: -20.24 \n",
      "total_step:  89109\n",
      "episode: 72/200000, thread: 0, score: -20.0, average: -20.22 SAVING\n",
      "total_step:  90123\n",
      "episode: 73/200000, thread: 0, score: -21.0, average: -20.24 \n",
      "total_step:  91286\n",
      "episode: 74/200000, thread: 0, score: -21.0, average: -20.26 \n",
      "total_step:  92324\n",
      "episode: 75/200000, thread: 0, score: -21.0, average: -20.28 \n",
      "total_step:  93433\n",
      "episode: 76/200000, thread: 0, score: -21.0, average: -20.30 \n",
      "total_step:  94783\n",
      "episode: 77/200000, thread: 0, score: -20.0, average: -20.28 \n",
      "total_step:  96025\n",
      "episode: 78/200000, thread: 0, score: -20.0, average: -20.32 \n",
      "total_step:  97432\n",
      "episode: 79/200000, thread: 0, score: -20.0, average: -20.32 \n",
      "total_step:  98547\n",
      "episode: 80/200000, thread: 0, score: -20.0, average: -20.32 \n",
      "total_step:  99774\n",
      "episode: 81/200000, thread: 0, score: -20.0, average: -20.30 \n",
      "total_step:  101113\n",
      "episode: 82/200000, thread: 0, score: -21.0, average: -20.30 \n",
      "total_step:  102243\n",
      "episode: 83/200000, thread: 0, score: -21.0, average: -20.30 \n",
      "total_step:  103374\n",
      "episode: 84/200000, thread: 0, score: -21.0, average: -20.30 \n",
      "total_step:  104607\n",
      "episode: 85/200000, thread: 0, score: -21.0, average: -20.30 \n",
      "total_step:  105617\n",
      "episode: 86/200000, thread: 0, score: -21.0, average: -20.34 \n",
      "total_step:  106825\n",
      "episode: 87/200000, thread: 0, score: -20.0, average: -20.32 \n",
      "total_step:  108053\n",
      "episode: 88/200000, thread: 0, score: -20.0, average: -20.32 \n",
      "total_step:  109289\n",
      "episode: 89/200000, thread: 0, score: -20.0, average: -20.30 \n",
      "total_step:  110537\n",
      "episode: 90/200000, thread: 0, score: -19.0, average: -20.30 \n",
      "total_step:  111816\n",
      "episode: 91/200000, thread: 0, score: -21.0, average: -20.30 \n",
      "total_step:  112891\n",
      "episode: 92/200000, thread: 0, score: -21.0, average: -20.30 \n",
      "total_step:  113900\n",
      "episode: 93/200000, thread: 0, score: -21.0, average: -20.30 \n",
      "total_step:  115122\n",
      "episode: 94/200000, thread: 0, score: -21.0, average: -20.30 \n",
      "total_step:  116447\n",
      "episode: 95/200000, thread: 0, score: -19.0, average: -20.28 \n",
      "total_step:  118145\n",
      "episode: 96/200000, thread: 0, score: -18.0, average: -20.28 \n",
      "total_step:  119227\n",
      "episode: 97/200000, thread: 0, score: -21.0, average: -20.28 \n",
      "total_step:  120360\n",
      "episode: 98/200000, thread: 0, score: -20.0, average: -20.28 \n",
      "total_step:  121453\n",
      "episode: 99/200000, thread: 0, score: -21.0, average: -20.28 \n",
      "total_step:  122653\n",
      "episode: 100/200000, thread: 0, score: -21.0, average: -20.30 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total_step:  123915\n",
      "episode: 101/200000, thread: 0, score: -21.0, average: -20.32 \n",
      "total_step:  124974\n",
      "episode: 102/200000, thread: 0, score: -21.0, average: -20.32 \n",
      "total_step:  126122\n",
      "episode: 103/200000, thread: 0, score: -21.0, average: -20.34 \n",
      "total_step:  127504\n",
      "episode: 104/200000, thread: 0, score: -20.0, average: -20.32 \n",
      "total_step:  128807\n",
      "episode: 105/200000, thread: 0, score: -20.0, average: -20.34 \n",
      "total_step:  130004\n",
      "episode: 106/200000, thread: 0, score: -20.0, average: -20.36 \n",
      "total_step:  131021\n",
      "episode: 107/200000, thread: 0, score: -21.0, average: -20.36 \n",
      "total_step:  132053\n",
      "episode: 108/200000, thread: 0, score: -21.0, average: -20.36 \n",
      "total_step:  133229\n",
      "episode: 109/200000, thread: 0, score: -21.0, average: -20.36 \n",
      "total_step:  134677\n",
      "episode: 110/200000, thread: 0, score: -19.0, average: -20.34 \n",
      "total_step:  135868\n",
      "episode: 111/200000, thread: 0, score: -21.0, average: -20.36 \n",
      "total_step:  137190\n",
      "episode: 112/200000, thread: 0, score: -19.0, average: -20.32 \n",
      "total_step:  138232\n",
      "episode: 113/200000, thread: 0, score: -21.0, average: -20.40 \n",
      "total_step:  139537\n",
      "episode: 114/200000, thread: 0, score: -21.0, average: -20.40 \n",
      "total_step:  140587\n",
      "episode: 115/200000, thread: 0, score: -21.0, average: -20.40 \n",
      "total_step:  141792\n",
      "episode: 116/200000, thread: 0, score: -20.0, average: -20.40 \n",
      "total_step:  142980\n",
      "episode: 117/200000, thread: 0, score: -21.0, average: -20.42 \n",
      "total_step:  144320\n",
      "episode: 118/200000, thread: 0, score: -21.0, average: -20.42 \n",
      "total_step:  145491\n",
      "episode: 119/200000, thread: 0, score: -21.0, average: -20.48 \n",
      "total_step:  146625\n",
      "episode: 120/200000, thread: 0, score: -20.0, average: -20.48 \n",
      "total_step:  147979\n",
      "episode: 121/200000, thread: 0, score: -21.0, average: -20.48 \n",
      "total_step:  149425\n",
      "episode: 122/200000, thread: 0, score: -20.0, average: -20.48 \n",
      "total_step:  150913\n",
      "episode: 123/200000, thread: 0, score: -18.0, average: -20.42 \n",
      "total_step:  152204\n",
      "episode: 124/200000, thread: 0, score: -21.0, average: -20.42 \n",
      "total_step:  153531\n",
      "episode: 125/200000, thread: 0, score: -19.0, average: -20.38 \n",
      "total_step:  154586\n",
      "episode: 126/200000, thread: 0, score: -21.0, average: -20.38 \n",
      "total_step:  155931\n",
      "episode: 127/200000, thread: 0, score: -20.0, average: -20.38 \n",
      "total_step:  157085\n",
      "episode: 128/200000, thread: 0, score: -20.0, average: -20.38 \n",
      "total_step:  158249\n",
      "episode: 129/200000, thread: 0, score: -20.0, average: -20.38 \n",
      "total_step:  159666\n",
      "episode: 130/200000, thread: 0, score: -21.0, average: -20.40 \n",
      "total_step:  161009\n",
      "episode: 131/200000, thread: 0, score: -19.0, average: -20.38 \n",
      "total_step:  162136\n",
      "episode: 132/200000, thread: 0, score: -20.0, average: -20.36 \n",
      "total_step:  163302\n",
      "episode: 133/200000, thread: 0, score: -20.0, average: -20.34 \n",
      "total_step:  164433\n",
      "episode: 134/200000, thread: 0, score: -21.0, average: -20.34 \n",
      "total_step:  166103\n",
      "episode: 135/200000, thread: 0, score: -17.0, average: -20.26 \n",
      "total_step:  167388\n",
      "episode: 136/200000, thread: 0, score: -19.0, average: -20.22 SAVING\n",
      "total_step:  168496\n",
      "episode: 137/200000, thread: 0, score: -21.0, average: -20.24 \n",
      "total_step:  169640\n",
      "episode: 138/200000, thread: 0, score: -21.0, average: -20.26 \n",
      "total_step:  170926\n",
      "episode: 139/200000, thread: 0, score: -20.0, average: -20.26 \n",
      "total_step:  171931\n",
      "episode: 140/200000, thread: 0, score: -21.0, average: -20.30 \n",
      "total_step:  173075\n",
      "episode: 141/200000, thread: 0, score: -21.0, average: -20.30 \n",
      "total_step:  174244\n",
      "episode: 142/200000, thread: 0, score: -21.0, average: -20.30 \n",
      "total_step:  175436\n",
      "episode: 143/200000, thread: 0, score: -20.0, average: -20.28 \n",
      "total_step:  176488\n",
      "episode: 144/200000, thread: 0, score: -21.0, average: -20.28 \n",
      "total_step:  177794\n",
      "episode: 145/200000, thread: 0, score: -20.0, average: -20.30 \n",
      "total_step:  179045\n",
      "episode: 146/200000, thread: 0, score: -21.0, average: -20.36 \n",
      "total_step:  180181\n",
      "episode: 147/200000, thread: 0, score: -21.0, average: -20.36 \n",
      "total_step:  181619\n",
      "episode: 148/200000, thread: 0, score: -18.0, average: -20.32 \n",
      "total_step:  182867\n",
      "episode: 149/200000, thread: 0, score: -19.0, average: -20.28 \n",
      "total_step:  184025\n",
      "episode: 150/200000, thread: 0, score: -21.0, average: -20.28 \n",
      "total_step:  185416\n",
      "episode: 151/200000, thread: 0, score: -20.0, average: -20.26 \n",
      "total_step:  187006\n",
      "episode: 152/200000, thread: 0, score: -18.0, average: -20.20 SAVING\n",
      "total_step:  188324\n",
      "episode: 153/200000, thread: 0, score: -20.0, average: -20.18 SAVING\n",
      "total_step:  189449\n",
      "episode: 154/200000, thread: 0, score: -21.0, average: -20.20 \n",
      "total_step:  190592\n",
      "episode: 155/200000, thread: 0, score: -20.0, average: -20.20 \n",
      "total_step:  192172\n",
      "episode: 156/200000, thread: 0, score: -16.0, average: -20.12 SAVING\n",
      "total_step:  193818\n",
      "episode: 157/200000, thread: 0, score: -17.0, average: -20.04 SAVING\n",
      "total_step:  195115\n",
      "episode: 158/200000, thread: 0, score: -20.0, average: -20.02 SAVING\n",
      "total_step:  196788\n",
      "episode: 159/200000, thread: 0, score: -19.0, average: -19.98 SAVING\n",
      "total_step:  197981\n",
      "episode: 160/200000, thread: 0, score: -20.0, average: -20.00 \n",
      "total_step:  199150\n",
      "episode: 161/200000, thread: 0, score: -21.0, average: -20.00 \n",
      "total_step:  200352\n",
      "episode: 162/200000, thread: 0, score: -20.0, average: -20.02 \n",
      "total_step:  201439\n",
      "episode: 163/200000, thread: 0, score: -21.0, average: -20.02 \n",
      "total_step:  202643\n",
      "episode: 164/200000, thread: 0, score: -21.0, average: -20.02 \n",
      "total_step:  203669\n",
      "episode: 165/200000, thread: 0, score: -21.0, average: -20.02 \n",
      "total_step:  205028\n",
      "episode: 166/200000, thread: 0, score: -20.0, average: -20.02 \n",
      "total_step:  206505\n",
      "episode: 167/200000, thread: 0, score: -20.0, average: -20.00 \n",
      "total_step:  207523\n",
      "episode: 168/200000, thread: 0, score: -21.0, average: -20.00 \n",
      "total_step:  208649\n",
      "episode: 169/200000, thread: 0, score: -20.0, average: -19.98 SAVING\n",
      "total_step:  210110\n",
      "episode: 170/200000, thread: 0, score: -20.0, average: -19.98 SAVING\n",
      "total_step:  211159\n",
      "episode: 171/200000, thread: 0, score: -21.0, average: -19.98 SAVING\n",
      "total_step:  212371\n",
      "episode: 172/200000, thread: 0, score: -21.0, average: -20.00 \n",
      "total_step:  213505\n",
      "episode: 173/200000, thread: 0, score: -21.0, average: -20.06 \n",
      "total_step:  214771\n",
      "episode: 174/200000, thread: 0, score: -20.0, average: -20.04 \n",
      "total_step:  215905\n",
      "episode: 175/200000, thread: 0, score: -21.0, average: -20.08 \n",
      "total_step:  217046\n",
      "episode: 176/200000, thread: 0, score: -21.0, average: -20.08 \n",
      "total_step:  218215\n",
      "episode: 177/200000, thread: 0, score: -20.0, average: -20.08 \n",
      "total_step:  219738\n",
      "episode: 178/200000, thread: 0, score: -18.0, average: -20.04 \n",
      "total_step:  221088\n",
      "episode: 179/200000, thread: 0, score: -20.0, average: -20.04 \n",
      "total_step:  222294\n",
      "episode: 180/200000, thread: 0, score: -21.0, average: -20.04 \n",
      "total_step:  223512\n",
      "episode: 181/200000, thread: 0, score: -20.0, average: -20.06 \n",
      "total_step:  224813\n",
      "episode: 182/200000, thread: 0, score: -20.0, average: -20.06 \n",
      "total_step:  225832\n",
      "episode: 183/200000, thread: 0, score: -21.0, average: -20.08 \n",
      "total_step:  227353\n",
      "episode: 184/200000, thread: 0, score: -21.0, average: -20.08 \n",
      "total_step:  228572\n",
      "episode: 185/200000, thread: 0, score: -21.0, average: -20.16 \n",
      "total_step:  229670\n",
      "episode: 186/200000, thread: 0, score: -21.0, average: -20.20 \n",
      "total_step:  230705\n",
      "episode: 187/200000, thread: 0, score: -21.0, average: -20.20 \n",
      "total_step:  232053\n",
      "episode: 188/200000, thread: 0, score: -21.0, average: -20.20 \n",
      "total_step:  233160\n",
      "episode: 189/200000, thread: 0, score: -21.0, average: -20.22 \n",
      "total_step:  234278\n",
      "episode: 190/200000, thread: 0, score: -20.0, average: -20.20 \n",
      "total_step:  235412\n",
      "episode: 191/200000, thread: 0, score: -21.0, average: -20.20 \n",
      "total_step:  236642\n",
      "episode: 192/200000, thread: 0, score: -20.0, average: -20.18 \n",
      "total_step:  237851\n",
      "episode: 193/200000, thread: 0, score: -21.0, average: -20.20 \n",
      "total_step:  239151\n",
      "episode: 194/200000, thread: 0, score: -21.0, average: -20.20 \n",
      "total_step:  240360\n",
      "episode: 195/200000, thread: 0, score: -20.0, average: -20.20 \n",
      "total_step:  241609\n",
      "episode: 196/200000, thread: 0, score: -19.0, average: -20.16 \n",
      "total_step:  242724\n",
      "episode: 197/200000, thread: 0, score: -21.0, average: -20.16 \n",
      "total_step:  243742\n",
      "episode: 198/200000, thread: 0, score: -21.0, average: -20.22 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total_step:  244828\n",
      "episode: 199/200000, thread: 0, score: -21.0, average: -20.26 \n",
      "total_step:  246038\n",
      "episode: 200/200000, thread: 0, score: -20.0, average: -20.24 \n",
      "total_step:  247171\n",
      "episode: 201/200000, thread: 0, score: -21.0, average: -20.26 \n",
      "total_step:  248533\n",
      "episode: 202/200000, thread: 0, score: -19.0, average: -20.28 \n",
      "total_step:  249841\n",
      "episode: 203/200000, thread: 0, score: -20.0, average: -20.28 \n",
      "total_step:  251293\n",
      "episode: 204/200000, thread: 0, score: -21.0, average: -20.28 \n",
      "total_step:  252413\n",
      "episode: 205/200000, thread: 0, score: -21.0, average: -20.30 \n",
      "total_step:  253612\n",
      "episode: 206/200000, thread: 0, score: -21.0, average: -20.40 \n",
      "total_step:  254764\n",
      "episode: 207/200000, thread: 0, score: -21.0, average: -20.48 \n",
      "total_step:  255950\n",
      "episode: 208/200000, thread: 0, score: -21.0, average: -20.50 \n",
      "total_step:  257155\n",
      "episode: 209/200000, thread: 0, score: -21.0, average: -20.54 \n",
      "total_step:  258210\n",
      "episode: 210/200000, thread: 0, score: -21.0, average: -20.56 \n",
      "total_step:  259540\n",
      "episode: 211/200000, thread: 0, score: -20.0, average: -20.54 \n",
      "total_step:  260774\n",
      "episode: 212/200000, thread: 0, score: -20.0, average: -20.54 \n",
      "total_step:  261900\n",
      "episode: 213/200000, thread: 0, score: -20.0, average: -20.52 \n",
      "total_step:  263152\n",
      "episode: 214/200000, thread: 0, score: -21.0, average: -20.52 \n",
      "total_step:  264454\n",
      "episode: 215/200000, thread: 0, score: -20.0, average: -20.50 \n",
      "total_step:  265618\n",
      "episode: 216/200000, thread: 0, score: -20.0, average: -20.50 \n",
      "total_step:  266750\n",
      "episode: 217/200000, thread: 0, score: -21.0, average: -20.52 \n",
      "total_step:  267946\n",
      "episode: 218/200000, thread: 0, score: -21.0, average: -20.52 \n",
      "total_step:  269137\n",
      "episode: 219/200000, thread: 0, score: -20.0, average: -20.52 \n",
      "total_step:  270282\n",
      "episode: 220/200000, thread: 0, score: -21.0, average: -20.54 \n",
      "total_step:  271571\n",
      "episode: 221/200000, thread: 0, score: -20.0, average: -20.52 \n",
      "total_step:  272688\n",
      "episode: 222/200000, thread: 0, score: -20.0, average: -20.50 \n",
      "total_step:  273901\n",
      "episode: 223/200000, thread: 0, score: -21.0, average: -20.50 \n",
      "total_step:  275178\n",
      "episode: 224/200000, thread: 0, score: -20.0, average: -20.50 \n",
      "total_step:  276304\n",
      "episode: 225/200000, thread: 0, score: -20.0, average: -20.48 \n",
      "total_step:  277595\n",
      "episode: 226/200000, thread: 0, score: -19.0, average: -20.44 \n",
      "total_step:  279063\n",
      "episode: 227/200000, thread: 0, score: -21.0, average: -20.46 \n",
      "total_step:  280380\n",
      "episode: 228/200000, thread: 0, score: -19.0, average: -20.48 \n",
      "total_step:  281433\n",
      "episode: 229/200000, thread: 0, score: -21.0, average: -20.50 \n",
      "total_step:  282491\n",
      "episode: 230/200000, thread: 0, score: -21.0, average: -20.50 \n",
      "total_step:  283693\n",
      "episode: 231/200000, thread: 0, score: -21.0, average: -20.52 \n",
      "total_step:  284898\n",
      "episode: 232/200000, thread: 0, score: -20.0, average: -20.52 \n",
      "total_step:  286260\n",
      "episode: 233/200000, thread: 0, score: -18.0, average: -20.46 \n",
      "total_step:  287286\n",
      "episode: 234/200000, thread: 0, score: -21.0, average: -20.46 \n",
      "total_step:  288381\n",
      "episode: 235/200000, thread: 0, score: -21.0, average: -20.46 \n",
      "total_step:  289539\n",
      "episode: 236/200000, thread: 0, score: -21.0, average: -20.46 \n",
      "total_step:  290602\n",
      "episode: 237/200000, thread: 0, score: -21.0, average: -20.46 \n",
      "total_step:  291953\n",
      "episode: 238/200000, thread: 0, score: -20.0, average: -20.44 \n",
      "total_step:  293367\n",
      "episode: 239/200000, thread: 0, score: -20.0, average: -20.42 \n",
      "total_step:  294707\n",
      "episode: 240/200000, thread: 0, score: -20.0, average: -20.42 \n",
      "total_step:  295844\n",
      "episode: 241/200000, thread: 0, score: -21.0, average: -20.42 \n",
      "total_step:  297075\n",
      "episode: 242/200000, thread: 0, score: -20.0, average: -20.42 \n",
      "total_step:  298378\n",
      "episode: 243/200000, thread: 0, score: -20.0, average: -20.40 \n",
      "total_step:  299402\n",
      "episode: 244/200000, thread: 0, score: -21.0, average: -20.40 \n",
      "total_step:  300819\n",
      "episode: 245/200000, thread: 0, score: -21.0, average: -20.42 \n",
      "total_step:  302061\n",
      "episode: 246/200000, thread: 0, score: -20.0, average: -20.44 \n",
      "total_step:  303157\n",
      "episode: 247/200000, thread: 0, score: -21.0, average: -20.44 \n",
      "total_step:  304420\n",
      "episode: 248/200000, thread: 0, score: -21.0, average: -20.44 \n",
      "total_step:  305761\n",
      "episode: 249/200000, thread: 0, score: -19.0, average: -20.40 \n",
      "total_step:  307243\n",
      "episode: 250/200000, thread: 0, score: -19.0, average: -20.38 \n",
      "total_step:  308495\n",
      "episode: 251/200000, thread: 0, score: -21.0, average: -20.38 \n",
      "total_step:  309774\n",
      "episode: 252/200000, thread: 0, score: -20.0, average: -20.40 \n",
      "total_step:  311069\n",
      "episode: 253/200000, thread: 0, score: -20.0, average: -20.40 \n",
      "total_step:  312283\n",
      "episode: 254/200000, thread: 0, score: -21.0, average: -20.40 \n",
      "total_step:  313603\n",
      "episode: 255/200000, thread: 0, score: -20.0, average: -20.38 \n",
      "total_step:  314896\n",
      "episode: 256/200000, thread: 0, score: -20.0, average: -20.36 \n",
      "total_step:  316077\n",
      "episode: 257/200000, thread: 0, score: -21.0, average: -20.36 \n",
      "total_step:  317475\n",
      "episode: 258/200000, thread: 0, score: -19.0, average: -20.32 \n",
      "total_step:  318724\n",
      "episode: 259/200000, thread: 0, score: -21.0, average: -20.32 \n",
      "total_step:  320056\n",
      "episode: 260/200000, thread: 0, score: -19.0, average: -20.28 \n",
      "total_step:  321342\n",
      "episode: 261/200000, thread: 0, score: -20.0, average: -20.28 \n",
      "total_step:  322557\n",
      "episode: 262/200000, thread: 0, score: -20.0, average: -20.28 \n",
      "total_step:  323742\n",
      "episode: 263/200000, thread: 0, score: -21.0, average: -20.30 \n",
      "total_step:  324940\n",
      "episode: 264/200000, thread: 0, score: -20.0, average: -20.28 \n",
      "total_step:  326037\n",
      "episode: 265/200000, thread: 0, score: -21.0, average: -20.30 \n",
      "total_step:  327538\n",
      "episode: 266/200000, thread: 0, score: -19.0, average: -20.28 \n",
      "total_step:  328769\n",
      "episode: 267/200000, thread: 0, score: -20.0, average: -20.26 \n",
      "total_step:  330365\n",
      "episode: 268/200000, thread: 0, score: -19.0, average: -20.22 \n",
      "total_step:  331725\n",
      "episode: 269/200000, thread: 0, score: -19.0, average: -20.20 \n",
      "total_step:  332760\n",
      "episode: 270/200000, thread: 0, score: -21.0, average: -20.20 \n",
      "total_step:  333843\n",
      "episode: 271/200000, thread: 0, score: -21.0, average: -20.22 \n",
      "total_step:  335000\n",
      "episode: 272/200000, thread: 0, score: -21.0, average: -20.24 \n",
      "total_step:  336430\n",
      "episode: 273/200000, thread: 0, score: -20.0, average: -20.22 \n",
      "total_step:  337565\n",
      "episode: 274/200000, thread: 0, score: -21.0, average: -20.24 \n",
      "total_step:  338856\n",
      "episode: 275/200000, thread: 0, score: -20.0, average: -20.24 \n",
      "total_step:  340020\n",
      "episode: 276/200000, thread: 0, score: -21.0, average: -20.28 \n",
      "total_step:  341302\n",
      "episode: 277/200000, thread: 0, score: -19.0, average: -20.24 \n",
      "total_step:  342968\n",
      "episode: 278/200000, thread: 0, score: -19.0, average: -20.24 \n",
      "total_step:  344290\n",
      "episode: 279/200000, thread: 0, score: -19.0, average: -20.20 \n",
      "total_step:  345479\n",
      "episode: 280/200000, thread: 0, score: -21.0, average: -20.20 \n",
      "total_step:  346804\n",
      "episode: 281/200000, thread: 0, score: -20.0, average: -20.18 \n",
      "total_step:  348531\n",
      "episode: 282/200000, thread: 0, score: -17.0, average: -20.12 \n",
      "total_step:  349778\n",
      "episode: 283/200000, thread: 0, score: -19.0, average: -20.14 \n",
      "total_step:  351171\n",
      "episode: 284/200000, thread: 0, score: -19.0, average: -20.10 \n",
      "total_step:  352542\n",
      "episode: 285/200000, thread: 0, score: -19.0, average: -20.06 \n",
      "total_step:  354083\n",
      "episode: 286/200000, thread: 0, score: -20.0, average: -20.04 \n",
      "total_step:  355200\n",
      "episode: 287/200000, thread: 0, score: -21.0, average: -20.04 \n",
      "total_step:  356313\n",
      "episode: 288/200000, thread: 0, score: -21.0, average: -20.06 \n",
      "total_step:  357448\n",
      "episode: 289/200000, thread: 0, score: -21.0, average: -20.08 \n",
      "total_step:  359238\n",
      "episode: 290/200000, thread: 0, score: -16.0, average: -20.00 \n",
      "total_step:  360339\n",
      "episode: 291/200000, thread: 0, score: -21.0, average: -20.00 \n",
      "total_step:  361486\n",
      "episode: 292/200000, thread: 0, score: -21.0, average: -20.02 \n",
      "total_step:  362859\n",
      "episode: 293/200000, thread: 0, score: -20.0, average: -20.02 \n",
      "total_step:  364125\n",
      "episode: 294/200000, thread: 0, score: -21.0, average: -20.02 \n",
      "total_step:  365344\n",
      "episode: 295/200000, thread: 0, score: -20.0, average: -20.00 \n",
      "total_step:  366642\n",
      "episode: 296/200000, thread: 0, score: -20.0, average: -20.00 \n",
      "total_step:  367745\n",
      "episode: 297/200000, thread: 0, score: -21.0, average: -20.00 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total_step:  369130\n",
      "episode: 298/200000, thread: 0, score: -18.0, average: -19.94 SAVING\n",
      "total_step:  370400\n",
      "episode: 299/200000, thread: 0, score: -20.0, average: -19.96 \n",
      "total_step:  371526\n",
      "episode: 300/200000, thread: 0, score: -20.0, average: -19.98 \n",
      "total_step:  372964\n",
      "episode: 301/200000, thread: 0, score: -19.0, average: -19.94 SAVING\n",
      "total_step:  374205\n",
      "episode: 302/200000, thread: 0, score: -20.0, average: -19.94 SAVING\n",
      "total_step:  375328\n",
      "episode: 303/200000, thread: 0, score: -20.0, average: -19.94 SAVING\n",
      "total_step:  376473\n",
      "episode: 304/200000, thread: 0, score: -21.0, average: -19.94 SAVING\n",
      "total_step:  377798\n",
      "episode: 305/200000, thread: 0, score: -20.0, average: -19.94 SAVING\n",
      "total_step:  378969\n",
      "episode: 306/200000, thread: 0, score: -21.0, average: -19.96 \n",
      "total_step:  380197\n",
      "episode: 307/200000, thread: 0, score: -20.0, average: -19.94 SAVING\n",
      "total_step:  381777\n",
      "episode: 308/200000, thread: 0, score: -18.0, average: -19.92 SAVING\n",
      "total_step:  383052\n",
      "episode: 309/200000, thread: 0, score: -20.0, average: -19.90 SAVING\n",
      "total_step:  384191\n",
      "episode: 310/200000, thread: 0, score: -21.0, average: -19.94 \n",
      "total_step:  385317\n",
      "episode: 311/200000, thread: 0, score: -20.0, average: -19.94 \n",
      "total_step:  386439\n",
      "episode: 312/200000, thread: 0, score: -21.0, average: -19.96 \n",
      "total_step:  387614\n",
      "episode: 313/200000, thread: 0, score: -21.0, average: -19.96 \n",
      "total_step:  388981\n",
      "episode: 314/200000, thread: 0, score: -20.0, average: -19.96 \n",
      "total_step:  390093\n",
      "episode: 315/200000, thread: 0, score: -21.0, average: -19.96 \n",
      "total_step:  391716\n",
      "episode: 316/200000, thread: 0, score: -20.0, average: -19.98 \n",
      "total_step:  393033\n",
      "episode: 317/200000, thread: 0, score: -20.0, average: -19.98 \n",
      "total_step:  394494\n",
      "episode: 318/200000, thread: 0, score: -21.0, average: -20.02 \n",
      "total_step:  395661\n",
      "episode: 319/200000, thread: 0, score: -21.0, average: -20.06 \n",
      "total_step:  396782\n",
      "episode: 320/200000, thread: 0, score: -21.0, average: -20.06 \n",
      "total_step:  397952\n",
      "episode: 321/200000, thread: 0, score: -20.0, average: -20.04 \n",
      "total_step:  399316\n",
      "episode: 322/200000, thread: 0, score: -20.0, average: -20.02 \n",
      "total_step:  400437\n",
      "episode: 323/200000, thread: 0, score: -21.0, average: -20.04 \n",
      "total_step:  401673\n",
      "episode: 324/200000, thread: 0, score: -20.0, average: -20.02 \n",
      "total_step:  403039\n",
      "episode: 325/200000, thread: 0, score: -19.0, average: -20.00 \n",
      "total_step:  404231\n",
      "episode: 326/200000, thread: 0, score: -20.0, average: -19.98 \n",
      "total_step:  405468\n",
      "episode: 327/200000, thread: 0, score: -20.0, average: -20.00 \n",
      "total_step:  406619\n",
      "episode: 328/200000, thread: 0, score: -20.0, average: -20.02 \n",
      "total_step:  407709\n",
      "episode: 329/200000, thread: 0, score: -21.0, average: -20.06 \n",
      "total_step:  409071\n",
      "episode: 330/200000, thread: 0, score: -21.0, average: -20.06 \n",
      "total_step:  410126\n",
      "episode: 331/200000, thread: 0, score: -21.0, average: -20.08 \n",
      "total_step:  411251\n",
      "episode: 332/200000, thread: 0, score: -20.0, average: -20.14 \n",
      "total_step:  412357\n",
      "episode: 333/200000, thread: 0, score: -20.0, average: -20.16 \n",
      "total_step:  413522\n",
      "episode: 334/200000, thread: 0, score: -20.0, average: -20.18 \n",
      "total_step:  414706\n",
      "episode: 335/200000, thread: 0, score: -20.0, average: -20.20 \n",
      "total_step:  416176\n",
      "episode: 336/200000, thread: 0, score: -18.0, average: -20.16 \n",
      "total_step:  417293\n",
      "episode: 337/200000, thread: 0, score: -21.0, average: -20.16 \n",
      "total_step:  418435\n",
      "episode: 338/200000, thread: 0, score: -21.0, average: -20.16 \n",
      "total_step:  419961\n",
      "episode: 339/200000, thread: 0, score: -17.0, average: -20.08 \n",
      "total_step:  421063\n",
      "episode: 340/200000, thread: 0, score: -21.0, average: -20.18 \n",
      "total_step:  422147\n",
      "episode: 341/200000, thread: 0, score: -21.0, average: -20.18 \n",
      "total_step:  423326\n",
      "episode: 342/200000, thread: 0, score: -21.0, average: -20.18 \n",
      "total_step:  424468\n",
      "episode: 343/200000, thread: 0, score: -21.0, average: -20.20 \n",
      "total_step:  425688\n",
      "episode: 344/200000, thread: 0, score: -21.0, average: -20.20 \n",
      "total_step:  426733\n",
      "episode: 345/200000, thread: 0, score: -21.0, average: -20.22 \n",
      "total_step:  428014\n",
      "episode: 346/200000, thread: 0, score: -19.0, average: -20.20 \n",
      "total_step:  429066\n",
      "episode: 347/200000, thread: 0, score: -21.0, average: -20.20 \n",
      "total_step:  430693\n",
      "episode: 348/200000, thread: 0, score: -20.0, average: -20.24 \n",
      "total_step:  431878\n",
      "episode: 349/200000, thread: 0, score: -21.0, average: -20.26 \n",
      "total_step:  433059\n",
      "episode: 350/200000, thread: 0, score: -21.0, average: -20.28 \n",
      "total_step:  434294\n",
      "episode: 351/200000, thread: 0, score: -20.0, average: -20.30 \n",
      "total_step:  435698\n",
      "episode: 352/200000, thread: 0, score: -19.0, average: -20.28 \n",
      "total_step:  437004\n",
      "episode: 353/200000, thread: 0, score: -20.0, average: -20.28 \n",
      "total_step:  438083\n",
      "episode: 354/200000, thread: 0, score: -21.0, average: -20.28 \n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import gym\n",
    "import pylab\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.layers import Input, Dense, Lambda, Add, Conv2D, Flatten\n",
    "from tensorflow.keras.optimizers import Adam, RMSprop\n",
    "from tensorflow.keras import backend as K\n",
    "import cv2\n",
    "import threading\n",
    "from threading import Thread, Lock\n",
    "import time\n",
    "import tensorflow_probability as tfp\n",
    "from typing import Any, List, Sequence, Tuple\n",
    "\n",
    "#os.environ['CUDA_VISIBLE_DEVICES'] = '-1'\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_virtual_device_configuration(gpus[0],\n",
    "          [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=4000)])\n",
    "\n",
    "tfd = tfp.distributions\n",
    "\n",
    "\n",
    "class ActorCritic(tf.keras.Model):\n",
    "  \"\"\"Combined actor-critic network.\"\"\"\n",
    "  def __init__(self, num_actions: int, num_hidden_units: int):\n",
    "    \"\"\"Initialize.\"\"\"\n",
    "    super().__init__()\n",
    "\n",
    "    self.num_actions = num_actions\n",
    "    \n",
    "    self.conv_1 = tf.keras.layers.Conv2D(16, 8, 4, padding=\"valid\", activation=\"relu\")\n",
    "    self.conv_2 = tf.keras.layers.Conv2D(32, 4, 2, padding=\"valid\", activation=\"relu\")\n",
    "    self.conv_3 = tf.keras.layers.Conv2D(32, 3, 1, padding=\"valid\", activation=\"relu\")\n",
    "    \n",
    "    self.dense_1 = Dense(512, activation=\"relu\")\n",
    "    self.dense_2 = Dense(256, activation=\"relu\")\n",
    "    self.dense_3 = Dense(64, activation=\"relu\")\n",
    "    \n",
    "    self.actor = tf.keras.layers.Dense(num_actions)\n",
    "    self.critic = tf.keras.layers.Dense(1)\n",
    "\n",
    "  def get_config(self):\n",
    "    config = super().get_config().copy()\n",
    "    config.update({\n",
    "        'num_actions': self.num_actions,\n",
    "        'num_hidden_units': self.num_hidden_units\n",
    "    })\n",
    "    \n",
    "    return config\n",
    "    \n",
    "  def call(self, inputs: tf.Tensor, training) -> Tuple[tf.Tensor, tf.Tensor, tf.Tensor, tf.Tensor]:\n",
    "    batch_size = tf.shape(inputs)[0]\n",
    "\n",
    "    conv_1 = self.conv_1(inputs)\n",
    "    conv_2 = self.conv_2(conv_1)\n",
    "    conv_3 = self.conv_3(conv_2)\n",
    "\n",
    "    X_Flattened = Flatten()(conv_3)\n",
    "    X_input = self.dense_1(X_Flattened)\n",
    "    X_input = self.dense_2(X_input)\n",
    "    x = self.dense_3(X_input)\n",
    "\n",
    "    return self.actor(x), self.critic(x)\n",
    "\n",
    "\n",
    "def safe_log(x):\n",
    "  \"\"\"Computes a safe logarithm which returns 0 if x is zero.\"\"\"\n",
    "  return tf.where(\n",
    "      tf.math.equal(x, 0),\n",
    "      tf.zeros_like(x),\n",
    "      tf.math.log(tf.math.maximum(1e-12, x)))\n",
    "\n",
    "\n",
    "def take_vector_elements(vectors, indices):\n",
    "    \"\"\"\n",
    "    For a batch of vectors, take a single vector component\n",
    "    out of each vector.\n",
    "    Args:\n",
    "      vectors: a [batch x dims] Tensor.\n",
    "      indices: an int32 Tensor with `batch` entries.\n",
    "    Returns:\n",
    "      A Tensor with `batch` entries, one for each vector.\n",
    "    \"\"\"\n",
    "    return tf.gather_nd(vectors, tf.stack([tf.range(tf.shape(vectors)[0]), indices], axis=1))\n",
    "\n",
    "\n",
    "huber_loss = tf.keras.losses.Huber(reduction=tf.keras.losses.Reduction.SUM)\n",
    "sparse_ce = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True, reduction=tf.keras.losses.Reduction.SUM)\n",
    "mse_loss = tf.keras.losses.MeanSquaredError()\n",
    "\n",
    "\n",
    "class IMPALA_Agent:\n",
    "    # IMPALA Main Optimization Algorithm\n",
    "    def __init__(self, env_name):\n",
    "        # Initialization Environment and parameters\n",
    "        self.env_name = env_name       \n",
    "        self.env = gym.make(env_name)\n",
    "        self.action_size = self.env.action_space.n\n",
    "        self.EPISODES, self.episode, self.max_average = 200000, 0, -21.0 # specific for pong\n",
    "        \n",
    "        self.memory_size = 25000\n",
    "        self.memory = []\n",
    "        self.lock = Lock()\n",
    "        self.lr = 0.00005\n",
    "\n",
    "        num_hidden_units = 512\n",
    "    \n",
    "        self.batch_size = 128\n",
    "        self.ROWS = 80\n",
    "        self.COLS = 80\n",
    "        self.REM_STEP = 4\n",
    "        \n",
    "        self.state_size = (self.COLS, self.ROWS, self.REM_STEP)\n",
    "        self.image_memory = np.zeros(self.state_size)\n",
    "        \n",
    "        # Instantiate plot memory\n",
    "        self.scores, self.episodes, self.average = [], [], []\n",
    "\n",
    "        self.Save_Path = 'Models'\n",
    "        \n",
    "        if not os.path.exists(self.Save_Path): os.makedirs(self.Save_Path)\n",
    "        self.path = '{}_IMPALA_{}'.format(self.env_name, self.lr)\n",
    "        self.model_name = os.path.join(self.Save_Path, self.path)\n",
    "\n",
    "        # Create Actor-Critic network model\n",
    "        self.model = ActorCritic(self.action_size, num_hidden_units)\n",
    "        \n",
    "        self.optimizer = tf.keras.optimizers.Adam(self.lr)\n",
    "\n",
    "    def remember(self, state, action, policy, reward, done):\n",
    "        experience = state, action, policy, reward, done\n",
    "        if len(self.memory) <= self.memory_size:\n",
    "            self.memory.append((experience))\n",
    "        else:\n",
    "            self.memory = []\n",
    "            \n",
    "    def act(self, state):\n",
    "        prediction = self.model(state, training=False)\n",
    "        dist = tfd.Categorical(logits=prediction[0])\n",
    "        action = int(dist.sample()[0])\n",
    "        policy = prediction[0]\n",
    "        \n",
    "        return action, policy\n",
    "\n",
    "    def update(self, states, actions, agent_policies, rewards, dones):\n",
    "        online_variables = self.model.trainable_variables\n",
    "        with tf.GradientTape() as tape:\n",
    "            tape.watch(online_variables)\n",
    "            \n",
    "            learner_outputs = self.model(states, training=True)\n",
    "            \n",
    "            agent_logits = tf.nn.softmax(agent_policies[:-1])\n",
    "            actions = actions[:-1]\n",
    "            rewards = rewards[1:]\n",
    "            dones = dones[1:]\n",
    "        \n",
    "            learner_policies = learner_outputs[0]\n",
    "            learner_logits = tf.nn.softmax(learner_policies[:-1])\n",
    "            \n",
    "            learner_values = learner_outputs[1]\n",
    "            learner_values = tf.squeeze(learner_values)\n",
    "            \n",
    "            bootstrap_value = learner_values[-1]\n",
    "            learner_values = learner_values[:-1]\n",
    "            \n",
    "            discounting = 0.99\n",
    "            discounts = tf.cast(~dones, tf.float32) * discounting\n",
    "            \n",
    "            actions = tf.convert_to_tensor(actions, dtype=tf.int32)\n",
    "                \n",
    "            target_action_probs = take_vector_elements(learner_logits, actions)\n",
    "            target_action_log_probs = tf.math.log(target_action_probs)\n",
    "            \n",
    "            behaviour_action_probs = take_vector_elements(agent_logits, actions)\n",
    "            behaviour_action_log_probs = tf.math.log(behaviour_action_probs)\n",
    "            \n",
    "            lambda_ = 1.0\n",
    "            \n",
    "            log_rhos = target_action_log_probs - behaviour_action_log_probs\n",
    "            \n",
    "            log_rhos = tf.convert_to_tensor(log_rhos, dtype=tf.float32)\n",
    "            discounts = tf.convert_to_tensor(discounts, dtype=tf.float32)\n",
    "            rewards = tf.convert_to_tensor(rewards, dtype=tf.float32)\n",
    "            values = tf.convert_to_tensor(learner_values, dtype=tf.float32)\n",
    "            bootstrap_value = tf.convert_to_tensor(bootstrap_value, dtype=tf.float32)\n",
    "            \n",
    "            clip_rho_threshold = tf.convert_to_tensor(1.0, dtype=tf.float32)\n",
    "            clip_pg_rho_threshold = tf.convert_to_tensor(1.0, dtype=tf.float32)\n",
    "            \n",
    "            rhos = tf.math.exp(log_rhos)\n",
    "            \n",
    "            clipped_rhos = tf.minimum(clip_rho_threshold, rhos, name='clipped_rhos')\n",
    "            \n",
    "            cs = tf.minimum(1.0, rhos, name='cs')\n",
    "            cs *= tf.convert_to_tensor(lambda_, dtype=tf.float32)\n",
    "\n",
    "            values_t_plus_1 = tf.concat([values[1:], tf.expand_dims(bootstrap_value, 0)], axis=0)\n",
    "            deltas = clipped_rhos * (rewards + discounts * values_t_plus_1 - values)\n",
    "        \n",
    "            acc = tf.zeros_like(bootstrap_value)\n",
    "            vs_minus_v_xs = []\n",
    "            for i in range(int(discounts.shape[0]) - 1, -1, -1):\n",
    "                discount, c, delta = discounts[i], cs[i], deltas[i]\n",
    "                acc = delta + discount * c * acc\n",
    "                vs_minus_v_xs.append(acc)  \n",
    "            \n",
    "            vs_minus_v_xs = vs_minus_v_xs[::-1]\n",
    "            \n",
    "            vs = tf.add(vs_minus_v_xs, values, name='vs')\n",
    "            vs_t_plus_1 = tf.concat([vs[1:], tf.expand_dims(bootstrap_value, 0)], axis=0)\n",
    "            clipped_pg_rhos = tf.minimum(clip_pg_rho_threshold, rhos, name='clipped_pg_rhos')\n",
    "            \n",
    "            pg_advantages = (clipped_pg_rhos * (rewards + discounts * vs_t_plus_1 - values))\n",
    "            \n",
    "            vs = tf.stop_gradient(vs)\n",
    "            pg_advantages = tf.stop_gradient(pg_advantages)\n",
    "            \n",
    "            actor_loss = -tf.reduce_mean(target_action_log_probs * pg_advantages)\n",
    "            \n",
    "            baseline_cost = 0.5\n",
    "            v_error = values - vs\n",
    "            critic_loss = baseline_cost * 0.5 * tf.reduce_mean(tf.square(v_error))\n",
    "            \n",
    "            total_loss = actor_loss + critic_loss\n",
    "\n",
    "        grads = tape.gradient(total_loss, self.model.trainable_variables)\n",
    "        self.optimizer.apply_gradients(zip(grads, self.model.trainable_variables))\n",
    "    \n",
    "    def replay(self):\n",
    "        memory_len = len(self.memory)\n",
    "        if len(self.memory) > self.batch_size:\n",
    "            start_index = random.randint(0, memory_len - self.batch_size)\n",
    "            minibatch = self.memory[start_index:start_index+self.batch_size]\n",
    "        else:\n",
    "            return\n",
    "\n",
    "        states = np.zeros((self.batch_size, *self.state_size), dtype=np.float32)\n",
    "        actions = np.zeros(self.batch_size, dtype=np.int32)\n",
    "        policies = np.zeros((self.batch_size, self.action_size), dtype=np.float32)\n",
    "        rewards = np.zeros(self.batch_size, dtype=np.float32)\n",
    "        dones = np.zeros(self.batch_size, dtype=np.bool)\n",
    "        for i in range(len(minibatch)):\n",
    "            states[i] = minibatch[i][0]\n",
    "            actions[i] = minibatch[i][1]\n",
    "            policies[i] = minibatch[i][2]\n",
    "            rewards[i] = minibatch[i][3]\n",
    "            dones[i] = minibatch[i][4]\n",
    "            \n",
    "        self.update(states, actions, policies, rewards, dones)\n",
    "        \n",
    "    def load(self, model_name):\n",
    "        self.model = load_model(model_name, compile=False)\n",
    "\n",
    "    def save(self):\n",
    "        self.model.save(self.model_name)\n",
    "\n",
    "    pylab.figure(figsize=(18, 9))\n",
    "    def PlotModel(self, score, episode):\n",
    "        self.scores.append(score)\n",
    "        self.episodes.append(episode)\n",
    "        self.average.append(sum(self.scores[-50:]) / len(self.scores[-50:]))\n",
    "        if str(episode)[-2:] == \"00\":# much faster than episode % 100\n",
    "            pylab.plot(self.episodes, self.scores, 'b')\n",
    "            pylab.plot(self.episodes, self.average, 'r')\n",
    "            pylab.ylabel('Score', fontsize=18)\n",
    "            pylab.xlabel('Steps', fontsize=18)\n",
    "            try:\n",
    "                pylab.savefig(self.path + \".png\")\n",
    "            except OSError:\n",
    "                pass\n",
    "\n",
    "        return self.average[-1]\n",
    "    \n",
    "    def imshow(self, image, rem_step=0):\n",
    "        cv2.imshow(self.model_name + str(rem_step), image[rem_step,...])\n",
    "        if cv2.waitKey(25) & 0xFF == ord(\"q\"):\n",
    "            cv2.destroyAllWindows()\n",
    "            return\n",
    "\n",
    "    def GetImage(self, frame):        \n",
    "        # croping frame to 80x80 size\n",
    "        frame_cropped = frame[35:195:2, ::2,:]\n",
    "        if frame_cropped.shape[0] != self.COLS or frame_cropped.shape[1] != self.ROWS:\n",
    "            # OpenCV resize function \n",
    "            frame_cropped = cv2.resize(frame, (self.COLS, self.ROWS), interpolation=cv2.INTER_CUBIC)\n",
    "        \n",
    "        # converting to RGB (numpy way)\n",
    "        frame_rgb = 0.299*frame_cropped[:,:,0] + 0.587*frame_cropped[:,:,1] + 0.114*frame_cropped[:,:,2]\n",
    "        # converting to RGB (OpenCV way)\n",
    "        #frame_rgb = cv2.cvtColor(frame_cropped, cv2.COLOR_RGB2GRAY)     \n",
    "\n",
    "        # dividing by 255 we expresses value to 0-1 representation\n",
    "        new_frame = np.array(frame_rgb).astype(np.float32) / 255.0\n",
    "\n",
    "        # push our data by 1 frame, similar as deq() function work\n",
    "        self.image_memory = np.roll(self.image_memory, 1, axis=2)\n",
    "\n",
    "        # inserting new frame to free space\n",
    "        self.image_memory[:,:,0] = new_frame\n",
    "\n",
    "        # show image frame   \n",
    "        #self.imshow(self.image_memory, 0)\n",
    "        #self.imshow(self.image_memory, 1)\n",
    "        #self.imshow(self.image_memory, 2)\n",
    "        #self.imshow(self.image_memory, 3)\n",
    "\n",
    "        return np.expand_dims(self.image_memory, axis=0)\n",
    "        \n",
    "    def reset(self, env):\n",
    "        frame = env.reset()\n",
    "        for i in range(self.REM_STEP):\n",
    "            state = self.GetImage(frame)\n",
    "\n",
    "        return state\n",
    "\n",
    "    def step(self, action, env):\n",
    "        next_state, reward, done, info = env.step(action)\n",
    "        next_state = self.GetImage(next_state)\n",
    "        \n",
    "        return next_state, reward, done, info\n",
    "    \n",
    "    def train(self, n_threads):\n",
    "        self.env.close()\n",
    "        # Instantiate one environment per thread\n",
    "        envs = [gym.make(self.env_name) for i in range(n_threads)]\n",
    "\n",
    "        # Create threads\n",
    "        threads = [threading.Thread(\n",
    "                target=self.train_threading,\n",
    "                daemon=True,\n",
    "                args=(self, envs[i], i)) for i in range(n_threads)]\n",
    "\n",
    "        for t in threads:\n",
    "            time.sleep(2)\n",
    "            t.start()\n",
    "            \n",
    "        for t in threads:\n",
    "            time.sleep(10)\n",
    "            t.join()\n",
    "    \n",
    "    def render(self, obs):\n",
    "        cv2.imshow('obs', obs)\n",
    "        cv2.waitKey(1)\n",
    "    \n",
    "    def train_threading(self, agent, env, thread):\n",
    "        max_average = 15.0\n",
    "        total_step = 0\n",
    "        for e in range(self.EPISODES):\n",
    "            state = self.reset(env)\n",
    "\n",
    "            done = False\n",
    "            score = 0\n",
    "            SAVING = ''\n",
    "            while not done:\n",
    "                #self.env.render()\n",
    "                #self.render(state[0])\n",
    "                \n",
    "                action, policy = self.act(state)\n",
    "                \n",
    "                next_state, reward, done, _ = self.step(action, env)\n",
    "                \n",
    "                self.remember(state, action, policy, reward / 20.0, done)\n",
    "                state = next_state\n",
    "                score += reward\n",
    "                if done:\n",
    "                    break\n",
    "                \n",
    "                self.lock.acquire()\n",
    "                if total_step % 300 == 0:\n",
    "                    # train model\n",
    "                    self.replay()\n",
    "                self.lock.release()\n",
    "                    \n",
    "                total_step += 1\n",
    "                \n",
    "            # Update episode count\n",
    "            with self.lock:\n",
    "                average = self.PlotModel(score, self.episode)\n",
    "                # saving best models\n",
    "                if average >= self.max_average:\n",
    "                    self.max_average = average\n",
    "                    #self.save()\n",
    "                    SAVING = \"SAVING\"\n",
    "                else:\n",
    "                    SAVING = \"\"\n",
    "                \n",
    "                print(\"total_step: \", total_step)\n",
    "                print(\"episode: {}/{}, thread: {}, score: {}, average: {:.2f} {}\".format(self.episode, self.EPISODES, thread, score, average, SAVING))\n",
    "                if(self.episode < self.EPISODES):\n",
    "                    self.episode += 1\n",
    "                 \n",
    "    def test(self, Actor_name, Critic_name):\n",
    "        self.load(Actor_name, Critic_name)\n",
    "        for e in range(100):\n",
    "            state = self.reset(self.env)\n",
    "            done = False\n",
    "            score = 0\n",
    "            while not done:\n",
    "                self.env.render()\n",
    "                action = np.argmax(self.Actor.predict(state))\n",
    "                state, reward, done, _ = self.step(action, self.env, state)\n",
    "                score += reward\n",
    "                if done:\n",
    "                    print(\"episode: {}/{}, score: {}\".format(e, self.EPISODES, score))\n",
    "                    break\n",
    "\n",
    "        self.env.close()\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    env_name = 'Pong-v0'\n",
    "    agent = IMPALA_Agent(env_name)\n",
    "    \n",
    "    #agent.run() # use as IMPALA\n",
    "    agent.train(n_threads=1) # use as IMPALA\n",
    "    #agent.test('Models/Pong-v0_A3C_2.5e-05_Actor.h5', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pysc2_env",
   "language": "python",
   "name": "pysc2_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
