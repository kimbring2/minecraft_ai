{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total_step_1:  1286\n",
      "total_step_2:  0\n",
      "episode: 0/2000000, thread: 0, score: -20.0, average: -20.00 SAVING\n",
      "total_step_1:  0\n",
      "total_step_2:  1220\n",
      "episode: 1/2000000, thread: 1, score: -21.0, average: -20.50 \n",
      "total_step_1:  2457\n",
      "total_step_2:  0\n",
      "episode: 2/2000000, thread: 0, score: -21.0, average: -20.67 \n",
      "total_step_1:  0\n",
      "total_step_2:  2539\n",
      "episode: 3/2000000, thread: 1, score: -20.0, average: -20.50 \n",
      "total_step_1:  3716\n",
      "total_step_2:  0\n",
      "episode: 4/2000000, thread: 0, score: -20.0, average: -20.40 \n",
      "total_step_1:  0\n",
      "total_step_2:  3634\n",
      "episode: 5/2000000, thread: 1, score: -21.0, average: -20.50 \n",
      "total_step_1:  0\n",
      "total_step_2:  4676\n",
      "episode: 6/2000000, thread: 1, score: -21.0, average: -20.57 \n",
      "total_step_1:  4973\n",
      "total_step_2:  0\n",
      "episode: 7/2000000, thread: 0, score: -21.0, average: -20.62 \n",
      "total_step_1:  6002\n",
      "total_step_2:  0\n",
      "episode: 8/2000000, thread: 0, score: -21.0, average: -20.67 \n",
      "total_step_1:  0\n",
      "total_step_2:  5986\n",
      "episode: 9/2000000, thread: 1, score: -20.0, average: -20.60 \n",
      "total_step_1:  7278\n",
      "total_step_2:  0\n",
      "episode: 10/2000000, thread: 0, score: -20.0, average: -20.55 \n",
      "total_step_1:  0\n",
      "total_step_2:  7514\n",
      "episode: 11/2000000, thread: 1, score: -20.0, average: -20.50 \n",
      "total_step_1:  8548\n",
      "total_step_2:  0\n",
      "episode: 12/2000000, thread: 0, score: -20.0, average: -20.46 \n",
      "total_step_1:  0\n",
      "total_step_2:  8600\n",
      "episode: 13/2000000, thread: 1, score: -21.0, average: -20.50 \n",
      "total_step_1:  9803\n",
      "total_step_2:  0\n",
      "episode: 14/2000000, thread: 0, score: -20.0, average: -20.47 \n",
      "total_step_1:  0\n",
      "total_step_2:  10018\n",
      "episode: 15/2000000, thread: 1, score: -21.0, average: -20.50 \n",
      "total_step_1:  10981\n",
      "total_step_2:  0\n",
      "episode: 16/2000000, thread: 0, score: -21.0, average: -20.53 \n",
      "total_step_1:  0\n",
      "total_step_2:  11257\n",
      "episode: 17/2000000, thread: 1, score: -19.0, average: -20.44 \n",
      "total_step_1:  12304\n",
      "total_step_2:  0\n",
      "episode: 18/2000000, thread: 0, score: -21.0, average: -20.47 \n",
      "total_step_1:  0\n",
      "total_step_2:  12308\n",
      "episode: 19/2000000, thread: 1, score: -21.0, average: -20.50 \n",
      "total_step_1:  13467\n",
      "total_step_2:  0\n",
      "episode: 20/2000000, thread: 0, score: -20.0, average: -20.48 \n",
      "total_step_1:  0\n",
      "total_step_2:  13661\n",
      "episode: 21/2000000, thread: 1, score: -19.0, average: -20.41 \n",
      "total_step_1:  14710\n",
      "total_step_2:  0\n",
      "episode: 22/2000000, thread: 0, score: -20.0, average: -20.39 \n",
      "total_step_1:  0\n",
      "total_step_2:  15220\n",
      "episode: 23/2000000, thread: 1, score: -20.0, average: -20.38 \n",
      "total_step_1:  15883\n",
      "total_step_2:  0\n",
      "episode: 24/2000000, thread: 0, score: -20.0, average: -20.36 \n",
      "total_step_1:  0\n",
      "total_step_2:  16398\n",
      "episode: 25/2000000, thread: 1, score: -21.0, average: -20.38 \n",
      "total_step_1:  17003\n",
      "total_step_2:  0\n",
      "episode: 26/2000000, thread: 0, score: -21.0, average: -20.41 \n",
      "total_step_1:  0\n",
      "total_step_2:  17491\n",
      "episode: 27/2000000, thread: 1, score: -21.0, average: -20.43 \n",
      "total_step_1:  18022\n",
      "total_step_2:  0\n",
      "episode: 28/2000000, thread: 0, score: -21.0, average: -20.45 \n",
      "total_step_1:  19109\n",
      "total_step_2:  0\n",
      "episode: 29/2000000, thread: 0, score: -21.0, average: -20.47 \n",
      "total_step_1:  0\n",
      "total_step_2:  19072\n",
      "episode: 30/2000000, thread: 1, score: -19.0, average: -20.42 \n",
      "total_step_1:  0\n",
      "total_step_2:  20199\n",
      "episode: 31/2000000, thread: 1, score: -21.0, average: -20.44 \n",
      "total_step_1:  20450\n",
      "total_step_2:  0\n",
      "episode: 32/2000000, thread: 0, score: -19.0, average: -20.39 \n",
      "total_step_1:  0\n",
      "total_step_2:  21346\n",
      "episode: 33/2000000, thread: 1, score: -20.0, average: -20.38 \n",
      "total_step_1:  21813\n",
      "total_step_2:  0\n",
      "episode: 34/2000000, thread: 0, score: -20.0, average: -20.37 \n",
      "total_step_1:  22922\n",
      "total_step_2:  0\n",
      "episode: 35/2000000, thread: 0, score: -21.0, average: -20.39 \n",
      "total_step_1:  0\n",
      "total_step_2:  22772\n",
      "episode: 36/2000000, thread: 1, score: -19.0, average: -20.35 \n",
      "total_step_1:  24132\n",
      "total_step_2:  0\n",
      "episode: 37/2000000, thread: 0, score: -21.0, average: -20.37 \n",
      "total_step_1:  0\n",
      "total_step_2:  23960\n",
      "episode: 38/2000000, thread: 1, score: -21.0, average: -20.38 \n",
      "total_step_1:  0\n",
      "total_step_2:  25162\n",
      "episode: 39/2000000, thread: 1, score: -20.0, average: -20.38 \n",
      "total_step_1:  25485\n",
      "total_step_2:  0\n",
      "episode: 40/2000000, thread: 0, score: -18.0, average: -20.32 \n",
      "total_step_1:  26627\n",
      "total_step_2:  0\n",
      "episode: 41/2000000, thread: 0, score: -21.0, average: -20.33 \n",
      "total_step_1:  0\n",
      "total_step_2:  26562\n",
      "episode: 42/2000000, thread: 1, score: -20.0, average: -20.33 \n",
      "total_step_1:  27747\n",
      "total_step_2:  0\n",
      "episode: 43/2000000, thread: 0, score: -21.0, average: -20.34 \n",
      "total_step_1:  0\n",
      "total_step_2:  27596\n",
      "episode: 44/2000000, thread: 1, score: -21.0, average: -20.36 \n",
      "total_step_1:  28993\n",
      "total_step_2:  0\n",
      "episode: 45/2000000, thread: 0, score: -21.0, average: -20.37 \n",
      "total_step_1:  0\n",
      "total_step_2:  28793\n",
      "episode: 46/2000000, thread: 1, score: -21.0, average: -20.38 \n",
      "total_step_1:  30022\n",
      "total_step_2:  0\n",
      "episode: 47/2000000, thread: 0, score: -21.0, average: -20.40 \n",
      "total_step_1:  0\n",
      "total_step_2:  29824\n",
      "episode: 48/2000000, thread: 1, score: -21.0, average: -20.41 \n",
      "total_step_1:  0\n",
      "total_step_2:  30991\n",
      "episode: 49/2000000, thread: 1, score: -21.0, average: -20.42 \n",
      "total_step_1:  31207\n",
      "total_step_2:  0\n",
      "episode: 50/2000000, thread: 0, score: -21.0, average: -20.44 \n",
      "total_step_1:  0\n",
      "total_step_2:  32097\n",
      "episode: 51/2000000, thread: 1, score: -21.0, average: -20.44 \n",
      "total_step_1:  32525\n",
      "total_step_2:  0\n",
      "episode: 52/2000000, thread: 0, score: -20.0, average: -20.42 \n",
      "total_step_1:  0\n",
      "total_step_2:  33181\n",
      "episode: 53/2000000, thread: 1, score: -21.0, average: -20.44 \n",
      "total_step_1:  33664\n",
      "total_step_2:  0\n",
      "episode: 54/2000000, thread: 0, score: -21.0, average: -20.46 \n",
      "total_step_1:  0\n",
      "total_step_2:  34455\n",
      "episode: 55/2000000, thread: 1, score: -20.0, average: -20.44 \n",
      "total_step_1:  34799\n",
      "total_step_2:  0\n",
      "episode: 56/2000000, thread: 0, score: -21.0, average: -20.44 \n",
      "total_step_1:  0\n",
      "total_step_2:  35559\n",
      "episode: 57/2000000, thread: 1, score: -21.0, average: -20.44 \n",
      "total_step_1:  35899\n",
      "total_step_2:  0\n",
      "episode: 58/2000000, thread: 0, score: -21.0, average: -20.44 \n",
      "total_step_1:  37175\n",
      "total_step_2:  0\n",
      "episode: 59/2000000, thread: 0, score: -20.0, average: -20.44 \n",
      "total_step_1:  0\n",
      "total_step_2:  37040\n",
      "episode: 60/2000000, thread: 1, score: -20.0, average: -20.44 \n",
      "total_step_1:  38227\n",
      "total_step_2:  0\n",
      "episode: 61/2000000, thread: 0, score: -21.0, average: -20.46 \n",
      "total_step_1:  0\n",
      "total_step_2:  38433\n",
      "episode: 62/2000000, thread: 1, score: -19.0, average: -20.44 \n",
      "total_step_1:  39525\n",
      "total_step_2:  0\n",
      "episode: 63/2000000, thread: 0, score: -20.0, average: -20.42 \n",
      "total_step_1:  0\n",
      "total_step_2:  39728\n",
      "episode: 64/2000000, thread: 1, score: -19.0, average: -20.40 \n",
      "total_step_1:  40908\n",
      "total_step_2:  0\n",
      "episode: 65/2000000, thread: 0, score: -18.0, average: -20.34 \n",
      "total_step_1:  0\n",
      "total_step_2:  40850\n",
      "episode: 66/2000000, thread: 1, score: -20.0, average: -20.32 \n",
      "total_step_1:  42017\n",
      "total_step_2:  0\n",
      "episode: 67/2000000, thread: 0, score: -21.0, average: -20.36 \n",
      "total_step_1:  0\n",
      "total_step_2:  41862\n",
      "episode: 68/2000000, thread: 1, score: -21.0, average: -20.36 \n",
      "total_step_1:  0\n",
      "total_step_2:  43066\n",
      "episode: 69/2000000, thread: 1, score: -21.0, average: -20.36 \n",
      "total_step_1:  43264\n",
      "total_step_2:  0\n",
      "episode: 70/2000000, thread: 0, score: -21.0, average: -20.38 \n",
      "total_step_1:  0\n",
      "total_step_2:  44080\n",
      "episode: 71/2000000, thread: 1, score: -21.0, average: -20.42 \n",
      "total_step_1:  44436\n",
      "total_step_2:  0\n",
      "episode: 72/2000000, thread: 0, score: -21.0, average: -20.44 \n",
      "total_step_1:  0\n",
      "total_step_2:  45242\n",
      "episode: 73/2000000, thread: 1, score: -20.0, average: -20.44 \n",
      "total_step_1:  45686\n",
      "total_step_2:  0\n",
      "episode: 74/2000000, thread: 0, score: -20.0, average: -20.44 \n",
      "total_step_1:  0\n",
      "total_step_2:  46408\n",
      "episode: 75/2000000, thread: 1, score: -20.0, average: -20.42 \n",
      "total_step_1:  46698\n",
      "total_step_2:  0\n",
      "episode: 76/2000000, thread: 0, score: -21.0, average: -20.42 \n",
      "total_step_1:  0\n",
      "total_step_2:  47678\n",
      "episode: 77/2000000, thread: 1, score: -20.0, average: -20.40 \n",
      "total_step_1:  48120\n",
      "total_step_2:  0\n",
      "episode: 78/2000000, thread: 0, score: -20.0, average: -20.38 \n",
      "total_step_1:  0\n",
      "total_step_2:  49203\n",
      "episode: 79/2000000, thread: 1, score: -18.0, average: -20.32 \n",
      "total_step_1:  49555\n",
      "total_step_2:  0\n",
      "episode: 80/2000000, thread: 0, score: -20.0, average: -20.34 \n",
      "total_step_1:  0\n",
      "total_step_2:  50220\n",
      "episode: 81/2000000, thread: 1, score: -21.0, average: -20.34 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total_step_1:  50862\n",
      "total_step_2:  0\n",
      "episode: 82/2000000, thread: 0, score: -20.0, average: -20.36 \n",
      "total_step_1:  0\n",
      "total_step_2:  51620\n",
      "episode: 83/2000000, thread: 1, score: -20.0, average: -20.36 \n",
      "total_step_1:  52068\n",
      "total_step_2:  0\n",
      "episode: 84/2000000, thread: 0, score: -20.0, average: -20.36 \n",
      "total_step_1:  0\n",
      "total_step_2:  52799\n",
      "episode: 85/2000000, thread: 1, score: -21.0, average: -20.36 \n",
      "total_step_1:  53201\n",
      "total_step_2:  0\n",
      "episode: 86/2000000, thread: 0, score: -21.0, average: -20.40 \n",
      "total_step_1:  0\n",
      "total_step_2:  54116\n",
      "episode: 87/2000000, thread: 1, score: -21.0, average: -20.40 \n",
      "total_step_1:  54457\n",
      "total_step_2:  0\n",
      "episode: 88/2000000, thread: 0, score: -20.0, average: -20.38 \n",
      "total_step_1:  0\n",
      "total_step_2:  55146\n",
      "episode: 89/2000000, thread: 1, score: -21.0, average: -20.40 \n",
      "total_step_1:  55653\n",
      "total_step_2:  0\n",
      "episode: 90/2000000, thread: 0, score: -20.0, average: -20.44 \n",
      "total_step_1:  0\n",
      "total_step_2:  56464\n",
      "episode: 91/2000000, thread: 1, score: -19.0, average: -20.40 \n",
      "total_step_1:  56670\n",
      "total_step_2:  0\n",
      "episode: 92/2000000, thread: 0, score: -21.0, average: -20.42 \n",
      "total_step_1:  0\n",
      "total_step_2:  57646\n",
      "episode: 93/2000000, thread: 1, score: -21.0, average: -20.42 \n",
      "total_step_1:  57935\n",
      "total_step_2:  0\n",
      "episode: 94/2000000, thread: 0, score: -19.0, average: -20.38 \n",
      "total_step_1:  0\n",
      "total_step_2:  58783\n",
      "episode: 95/2000000, thread: 1, score: -21.0, average: -20.38 \n",
      "total_step_1:  59030\n",
      "total_step_2:  0\n",
      "episode: 96/2000000, thread: 0, score: -21.0, average: -20.38 \n",
      "total_step_1:  60257\n",
      "total_step_2:  0\n",
      "episode: 97/2000000, thread: 0, score: -21.0, average: -20.38 \n",
      "total_step_1:  0\n",
      "total_step_2:  60318\n",
      "episode: 98/2000000, thread: 1, score: -20.0, average: -20.36 \n",
      "total_step_1:  61427\n",
      "total_step_2:  0\n",
      "episode: 99/2000000, thread: 0, score: -21.0, average: -20.36 \n",
      "total_step_1:  0\n",
      "total_step_2:  61457\n",
      "episode: 100/2000000, thread: 1, score: -21.0, average: -20.36 \n",
      "total_step_1:  0\n",
      "total_step_2:  62881\n",
      "episode: 101/2000000, thread: 1, score: -19.0, average: -20.32 \n",
      "total_step_1:  63096\n",
      "total_step_2:  0\n",
      "episode: 102/2000000, thread: 0, score: -21.0, average: -20.34 \n",
      "total_step_1:  0\n",
      "total_step_2:  64004\n",
      "episode: 103/2000000, thread: 1, score: -20.0, average: -20.32 \n",
      "total_step_1:  64116\n",
      "total_step_2:  0\n",
      "episode: 104/2000000, thread: 0, score: -21.0, average: -20.32 \n",
      "total_step_1:  0\n",
      "total_step_2:  65216\n",
      "episode: 105/2000000, thread: 1, score: -21.0, average: -20.34 \n",
      "total_step_1:  65492\n",
      "total_step_2:  0\n",
      "episode: 106/2000000, thread: 0, score: -20.0, average: -20.32 \n",
      "total_step_1:  0\n",
      "total_step_2:  66596\n",
      "episode: 107/2000000, thread: 1, score: -20.0, average: -20.30 \n",
      "total_step_1:  66680\n",
      "total_step_2:  0\n",
      "episode: 108/2000000, thread: 0, score: -21.0, average: -20.30 \n",
      "total_step_1:  67727\n",
      "total_step_2:  0\n",
      "episode: 109/2000000, thread: 0, score: -21.0, average: -20.32 \n",
      "total_step_1:  0\n",
      "total_step_2:  67853\n",
      "episode: 110/2000000, thread: 1, score: -20.0, average: -20.32 \n",
      "total_step_1:  0\n",
      "total_step_2:  69025\n",
      "episode: 111/2000000, thread: 1, score: -20.0, average: -20.30 \n",
      "total_step_1:  69095\n",
      "total_step_2:  0\n",
      "episode: 112/2000000, thread: 0, score: -19.0, average: -20.30 \n",
      "total_step_1:  0\n",
      "total_step_2:  70185\n",
      "episode: 113/2000000, thread: 1, score: -20.0, average: -20.30 \n",
      "total_step_1:  70397\n",
      "total_step_2:  0\n",
      "episode: 114/2000000, thread: 0, score: -20.0, average: -20.32 \n",
      "total_step_1:  0\n",
      "total_step_2:  71316\n",
      "episode: 115/2000000, thread: 1, score: -21.0, average: -20.38 \n",
      "total_step_1:  71448\n",
      "total_step_2:  0\n",
      "episode: 116/2000000, thread: 0, score: -21.0, average: -20.40 \n",
      "total_step_1:  0\n",
      "total_step_2:  72580\n",
      "episode: 117/2000000, thread: 1, score: -20.0, average: -20.38 \n",
      "total_step_1:  72905\n",
      "total_step_2:  0\n",
      "episode: 118/2000000, thread: 0, score: -18.0, average: -20.32 \n",
      "total_step_1:  0\n",
      "total_step_2:  73764\n",
      "episode: 119/2000000, thread: 1, score: -21.0, average: -20.32 \n",
      "total_step_1:  74035\n",
      "total_step_2:  0\n",
      "episode: 120/2000000, thread: 0, score: -21.0, average: -20.32 \n",
      "total_step_1:  0\n",
      "total_step_2:  74915\n",
      "episode: 121/2000000, thread: 1, score: -21.0, average: -20.32 \n",
      "total_step_1:  75455\n",
      "total_step_2:  0\n",
      "episode: 122/2000000, thread: 0, score: -19.0, average: -20.28 \n",
      "total_step_1:  0\n",
      "total_step_2:  76225\n",
      "episode: 123/2000000, thread: 1, score: -19.0, average: -20.26 \n",
      "total_step_1:  76544\n",
      "total_step_2:  0\n",
      "episode: 124/2000000, thread: 0, score: -21.0, average: -20.28 \n",
      "total_step_1:  0\n",
      "total_step_2:  77451\n",
      "episode: 125/2000000, thread: 1, score: -21.0, average: -20.30 \n",
      "total_step_1:  78397\n",
      "total_step_2:  0\n",
      "episode: 126/2000000, thread: 0, score: -18.0, average: -20.24 \n",
      "total_step_1:  0\n",
      "total_step_2:  78646\n",
      "episode: 127/2000000, thread: 1, score: -21.0, average: -20.26 \n",
      "total_step_1:  79564\n",
      "total_step_2:  0\n",
      "episode: 128/2000000, thread: 0, score: -20.0, average: -20.26 \n",
      "total_step_1:  0\n",
      "total_step_2:  79930\n",
      "episode: 129/2000000, thread: 1, score: -19.0, average: -20.28 \n",
      "total_step_1:  80698\n",
      "total_step_2:  0\n",
      "episode: 130/2000000, thread: 0, score: -21.0, average: -20.30 \n",
      "total_step_1:  0\n",
      "total_step_2:  81232\n",
      "episode: 131/2000000, thread: 1, score: -19.0, average: -20.26 \n",
      "total_step_1:  81878\n",
      "total_step_2:  0\n",
      "episode: 132/2000000, thread: 0, score: -21.0, average: -20.28 \n",
      "total_step_1:  0\n",
      "total_step_2:  82766\n",
      "episode: 133/2000000, thread: 1, score: -19.0, average: -20.26 \n",
      "total_step_1:  83268\n",
      "total_step_2:  0\n",
      "episode: 134/2000000, thread: 0, score: -21.0, average: -20.28 \n",
      "total_step_1:  0\n",
      "total_step_2:  84155\n",
      "episode: 135/2000000, thread: 1, score: -18.0, average: -20.22 \n",
      "total_step_1:  84489\n",
      "total_step_2:  0\n",
      "episode: 136/2000000, thread: 0, score: -20.0, average: -20.20 \n",
      "total_step_1:  0\n",
      "total_step_2:  85731\n",
      "episode: 137/2000000, thread: 1, score: -18.0, average: -20.14 \n",
      "total_step_1:  85682\n",
      "total_step_2:  0\n",
      "episode: 138/2000000, thread: 0, score: -21.0, average: -20.16 \n",
      "total_step_1:  86866\n",
      "total_step_2:  0\n",
      "episode: 139/2000000, thread: 0, score: -20.0, average: -20.14 \n",
      "total_step_1:  0\n",
      "total_step_2:  87333\n",
      "episode: 140/2000000, thread: 1, score: -20.0, average: -20.14 \n",
      "total_step_1:  88338\n",
      "total_step_2:  0\n",
      "episode: 141/2000000, thread: 0, score: -21.0, average: -20.18 \n",
      "total_step_1:  0\n",
      "total_step_2:  88828\n",
      "episode: 142/2000000, thread: 1, score: -19.0, average: -20.14 \n",
      "total_step_1:  89544\n",
      "total_step_2:  0\n",
      "episode: 143/2000000, thread: 0, score: -20.0, average: -20.12 \n",
      "total_step_1:  0\n",
      "total_step_2:  90202\n",
      "episode: 144/2000000, thread: 1, score: -21.0, average: -20.16 \n",
      "total_step_1:  90757\n",
      "total_step_2:  0\n",
      "episode: 145/2000000, thread: 0, score: -20.0, average: -20.14 \n",
      "total_step_1:  0\n",
      "total_step_2:  91621\n",
      "episode: 146/2000000, thread: 1, score: -20.0, average: -20.12 \n",
      "total_step_1:  92235\n",
      "total_step_2:  0\n",
      "episode: 147/2000000, thread: 0, score: -20.0, average: -20.10 \n",
      "total_step_1:  0\n",
      "total_step_2:  93052\n",
      "episode: 148/2000000, thread: 1, score: -18.0, average: -20.06 \n",
      "total_step_1:  93538\n",
      "total_step_2:  0\n",
      "episode: 149/2000000, thread: 0, score: -19.0, average: -20.02 \n",
      "total_step_1:  0\n",
      "total_step_2:  94265\n",
      "episode: 150/2000000, thread: 1, score: -20.0, average: -20.00 SAVING\n",
      "total_step_1:  94842\n",
      "total_step_2:  0\n",
      "episode: 151/2000000, thread: 0, score: -20.0, average: -20.02 \n",
      "total_step_1:  0\n",
      "total_step_2:  95693\n",
      "episode: 152/2000000, thread: 1, score: -19.0, average: -19.98 SAVING\n",
      "total_step_1:  96136\n",
      "total_step_2:  0\n",
      "episode: 153/2000000, thread: 0, score: -21.0, average: -20.00 \n",
      "total_step_1:  0\n",
      "total_step_2:  96962\n",
      "episode: 154/2000000, thread: 1, score: -19.0, average: -19.96 SAVING\n",
      "total_step_1:  97612\n",
      "total_step_2:  0\n",
      "episode: 155/2000000, thread: 0, score: -19.0, average: -19.92 SAVING\n",
      "total_step_1:  0\n",
      "total_step_2:  98278\n",
      "episode: 156/2000000, thread: 1, score: -21.0, average: -19.94 \n",
      "total_step_1:  98929\n",
      "total_step_2:  0\n",
      "episode: 157/2000000, thread: 0, score: -19.0, average: -19.92 SAVING\n",
      "total_step_1:  0\n",
      "total_step_2:  99551\n",
      "episode: 158/2000000, thread: 1, score: -21.0, average: -19.92 SAVING\n",
      "total_step_1:  100351\n",
      "total_step_2:  0\n",
      "episode: 159/2000000, thread: 0, score: -19.0, average: -19.88 SAVING\n",
      "total_step_1:  0\n",
      "total_step_2:  100658\n",
      "episode: 160/2000000, thread: 1, score: -20.0, average: -19.88 SAVING\n",
      "total_step_1:  101624\n",
      "total_step_2:  0\n",
      "episode: 161/2000000, thread: 0, score: -21.0, average: -19.90 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total_step_1:  0\n",
      "total_step_2:  101965\n",
      "episode: 162/2000000, thread: 1, score: -21.0, average: -19.94 \n",
      "total_step_1:  102796\n",
      "total_step_2:  0\n",
      "episode: 163/2000000, thread: 0, score: -21.0, average: -19.96 \n",
      "total_step_1:  0\n",
      "total_step_2:  103208\n",
      "episode: 164/2000000, thread: 1, score: -20.0, average: -19.96 \n",
      "total_step_1:  104009\n",
      "total_step_2:  0\n",
      "episode: 165/2000000, thread: 0, score: -20.0, average: -19.94 \n",
      "total_step_1:  0\n",
      "total_step_2:  104545\n",
      "episode: 166/2000000, thread: 1, score: -21.0, average: -19.94 \n",
      "total_step_1:  105233\n",
      "total_step_2:  0\n",
      "episode: 167/2000000, thread: 0, score: -20.0, average: -19.94 \n",
      "total_step_1:  0\n",
      "total_step_2:  105881\n",
      "episode: 168/2000000, thread: 1, score: -20.0, average: -19.98 \n",
      "total_step_1:  106325\n",
      "total_step_2:  0\n",
      "episode: 169/2000000, thread: 0, score: -21.0, average: -19.98 \n",
      "total_step_1:  0\n",
      "total_step_2:  107035\n",
      "episode: 170/2000000, thread: 1, score: -20.0, average: -19.96 \n",
      "total_step_1:  107720\n",
      "total_step_2:  0\n",
      "episode: 171/2000000, thread: 0, score: -19.0, average: -19.92 \n",
      "total_step_1:  0\n",
      "total_step_2:  108368\n",
      "episode: 172/2000000, thread: 1, score: -19.0, average: -19.92 \n",
      "total_step_1:  109382\n",
      "total_step_2:  0\n",
      "episode: 173/2000000, thread: 0, score: -17.0, average: -19.88 SAVING\n",
      "total_step_1:  0\n",
      "total_step_2:  109613\n",
      "episode: 174/2000000, thread: 1, score: -20.0, average: -19.86 SAVING\n",
      "total_step_1:  0\n",
      "total_step_2:  110657\n",
      "episode: 175/2000000, thread: 1, score: -21.0, average: -19.86 SAVING\n",
      "total_step_1:  110710\n",
      "total_step_2:  0\n",
      "episode: 176/2000000, thread: 0, score: -19.0, average: -19.88 \n",
      "total_step_1:  0\n",
      "total_step_2:  111792\n",
      "episode: 177/2000000, thread: 1, score: -21.0, average: -19.88 \n",
      "total_step_1:  111980\n",
      "total_step_2:  0\n",
      "episode: 178/2000000, thread: 0, score: -20.0, average: -19.88 \n",
      "total_step_1:  0\n",
      "total_step_2:  112954\n",
      "episode: 179/2000000, thread: 1, score: -20.0, average: -19.90 \n",
      "total_step_1:  113383\n",
      "total_step_2:  0\n",
      "episode: 180/2000000, thread: 0, score: -20.0, average: -19.88 \n",
      "total_step_1:  0\n",
      "total_step_2:  114423\n",
      "episode: 181/2000000, thread: 1, score: -20.0, average: -19.90 \n",
      "total_step_1:  114645\n",
      "total_step_2:  0\n",
      "episode: 182/2000000, thread: 0, score: -21.0, average: -19.90 \n",
      "total_step_1:  0\n",
      "total_step_2:  115749\n",
      "episode: 183/2000000, thread: 1, score: -20.0, average: -19.92 \n",
      "total_step_1:  115773\n",
      "total_step_2:  0\n",
      "episode: 184/2000000, thread: 0, score: -21.0, average: -19.92 \n",
      "total_step_1:  116925\n",
      "total_step_2:  0\n",
      "episode: 185/2000000, thread: 0, score: -20.0, average: -19.96 \n",
      "total_step_1:  0\n",
      "total_step_2:  117030\n",
      "episode: 186/2000000, thread: 1, score: -21.0, average: -19.98 \n",
      "total_step_1:  118251\n",
      "total_step_2:  0\n",
      "episode: 187/2000000, thread: 0, score: -19.0, average: -20.00 \n",
      "total_step_1:  0\n",
      "total_step_2:  118330\n",
      "episode: 188/2000000, thread: 1, score: -20.0, average: -19.98 \n",
      "total_step_1:  0\n",
      "total_step_2:  119536\n",
      "episode: 189/2000000, thread: 1, score: -21.0, average: -20.00 \n",
      "total_step_1:  119519\n",
      "total_step_2:  0\n",
      "episode: 190/2000000, thread: 0, score: -20.0, average: -20.00 \n",
      "total_step_1:  0\n",
      "total_step_2:  120685\n",
      "episode: 191/2000000, thread: 1, score: -21.0, average: -20.00 \n",
      "total_step_1:  120886\n",
      "total_step_2:  0\n",
      "episode: 192/2000000, thread: 0, score: -20.0, average: -20.02 \n",
      "total_step_1:  0\n",
      "total_step_2:  121986\n",
      "episode: 193/2000000, thread: 1, score: -19.0, average: -20.00 \n",
      "total_step_1:  122293\n",
      "total_step_2:  0\n",
      "episode: 194/2000000, thread: 0, score: -21.0, average: -20.00 \n",
      "total_step_1:  0\n",
      "total_step_2:  123227\n",
      "episode: 195/2000000, thread: 1, score: -20.0, average: -20.00 \n",
      "total_step_1:  123629\n",
      "total_step_2:  0\n",
      "episode: 196/2000000, thread: 0, score: -20.0, average: -20.00 \n",
      "total_step_1:  0\n",
      "total_step_2:  124422\n",
      "episode: 197/2000000, thread: 1, score: -21.0, average: -20.02 \n",
      "total_step_1:  124805\n",
      "total_step_2:  0\n",
      "episode: 198/2000000, thread: 0, score: -21.0, average: -20.08 \n",
      "total_step_1:  0\n",
      "total_step_2:  125727\n",
      "episode: 199/2000000, thread: 1, score: -20.0, average: -20.10 \n",
      "total_step_1:  126050\n",
      "total_step_2:  0\n",
      "episode: 200/2000000, thread: 0, score: -20.0, average: -20.10 \n",
      "total_step_1:  0\n",
      "total_step_2:  127074\n",
      "episode: 201/2000000, thread: 1, score: -20.0, average: -20.10 \n",
      "total_step_1:  127153\n",
      "total_step_2:  0\n",
      "episode: 202/2000000, thread: 0, score: -21.0, average: -20.14 \n",
      "total_step_1:  0\n",
      "total_step_2:  128261\n",
      "episode: 203/2000000, thread: 1, score: -21.0, average: -20.14 \n",
      "total_step_1:  128452\n",
      "total_step_2:  0\n",
      "episode: 204/2000000, thread: 0, score: -21.0, average: -20.18 \n",
      "total_step_1:  0\n",
      "total_step_2:  129655\n",
      "episode: 205/2000000, thread: 1, score: -20.0, average: -20.20 \n",
      "total_step_1:  130047\n",
      "total_step_2:  0\n",
      "episode: 206/2000000, thread: 0, score: -18.0, average: -20.14 \n",
      "total_step_1:  0\n",
      "total_step_2:  130867\n",
      "episode: 207/2000000, thread: 1, score: -21.0, average: -20.18 \n",
      "total_step_1:  131459\n",
      "total_step_2:  0\n",
      "episode: 208/2000000, thread: 0, score: -21.0, average: -20.18 \n",
      "total_step_1:  0\n",
      "total_step_2:  132156\n",
      "episode: 209/2000000, thread: 1, score: -20.0, average: -20.20 \n",
      "total_step_1:  132887\n",
      "total_step_2:  0\n",
      "episode: 210/2000000, thread: 0, score: -20.0, average: -20.20 \n",
      "total_step_1:  0\n",
      "total_step_2:  133443\n",
      "episode: 211/2000000, thread: 1, score: -21.0, average: -20.20 \n",
      "total_step_1:  134183\n",
      "total_step_2:  0\n",
      "episode: 212/2000000, thread: 0, score: -21.0, average: -20.20 \n",
      "total_step_1:  0\n",
      "total_step_2:  134743\n",
      "episode: 213/2000000, thread: 1, score: -20.0, average: -20.18 \n",
      "total_step_1:  135663\n",
      "total_step_2:  0\n",
      "episode: 214/2000000, thread: 0, score: -19.0, average: -20.16 \n",
      "total_step_1:  0\n",
      "total_step_2:  135903\n",
      "episode: 215/2000000, thread: 1, score: -20.0, average: -20.16 \n",
      "total_step_1:  0\n",
      "total_step_2:  137170\n",
      "episode: 216/2000000, thread: 1, score: -20.0, average: -20.14 \n",
      "total_step_1:  137299\n",
      "total_step_2:  0\n",
      "episode: 217/2000000, thread: 0, score: -17.0, average: -20.08 \n",
      "total_step_1:  0\n",
      "total_step_2:  138701\n",
      "episode: 218/2000000, thread: 1, score: -18.0, average: -20.04 \n",
      "total_step_1:  138685\n",
      "total_step_2:  0\n",
      "episode: 219/2000000, thread: 0, score: -21.0, average: -20.04 \n",
      "total_step_1:  0\n",
      "total_step_2:  139994\n",
      "episode: 220/2000000, thread: 1, score: -20.0, average: -20.04 \n",
      "total_step_1:  140525\n",
      "total_step_2:  0\n",
      "episode: 221/2000000, thread: 0, score: -19.0, average: -20.04 \n",
      "total_step_1:  0\n",
      "total_step_2:  141080\n",
      "episode: 222/2000000, thread: 1, score: -21.0, average: -20.08 \n",
      "total_step_1:  141659\n",
      "total_step_2:  0\n",
      "episode: 223/2000000, thread: 0, score: -21.0, average: -20.16 \n",
      "total_step_1:  0\n",
      "total_step_2:  142447\n",
      "episode: 224/2000000, thread: 1, score: -20.0, average: -20.16 \n",
      "total_step_1:  142778\n",
      "total_step_2:  0\n",
      "episode: 225/2000000, thread: 0, score: -21.0, average: -20.16 \n",
      "total_step_1:  0\n",
      "total_step_2:  143910\n",
      "episode: 226/2000000, thread: 1, score: -20.0, average: -20.18 \n",
      "total_step_1:  143993\n",
      "total_step_2:  0\n",
      "episode: 227/2000000, thread: 0, score: -20.0, average: -20.16 \n",
      "total_step_1:  145243\n",
      "total_step_2:  0\n",
      "episode: 228/2000000, thread: 0, score: -21.0, average: -20.18 \n",
      "total_step_1:  0\n",
      "total_step_2:  145614\n",
      "episode: 229/2000000, thread: 1, score: -18.0, average: -20.14 \n",
      "total_step_1:  146569\n",
      "total_step_2:  0\n",
      "episode: 230/2000000, thread: 0, score: -19.0, average: -20.12 \n",
      "total_step_1:  0\n",
      "total_step_2:  147398\n",
      "episode: 231/2000000, thread: 1, score: -19.0, average: -20.10 \n",
      "total_step_1:  147760\n",
      "total_step_2:  0\n",
      "episode: 232/2000000, thread: 0, score: -20.0, average: -20.08 \n",
      "total_step_1:  0\n",
      "total_step_2:  148891\n",
      "episode: 233/2000000, thread: 1, score: -21.0, average: -20.10 \n",
      "total_step_1:  149235\n",
      "total_step_2:  0\n",
      "episode: 234/2000000, thread: 0, score: -20.0, average: -20.08 \n",
      "total_step_1:  0\n",
      "total_step_2:  150301\n",
      "episode: 235/2000000, thread: 1, score: -20.0, average: -20.08 \n",
      "total_step_1:  150634\n",
      "total_step_2:  0\n",
      "episode: 236/2000000, thread: 0, score: -19.0, average: -20.04 \n",
      "total_step_1:  0\n",
      "total_step_2:  151975\n",
      "episode: 237/2000000, thread: 1, score: -18.0, average: -20.02 \n",
      "total_step_1:  151949\n",
      "total_step_2:  0\n",
      "episode: 238/2000000, thread: 0, score: -20.0, average: -20.02 \n",
      "total_step_1:  0\n",
      "total_step_2:  153114\n",
      "episode: 239/2000000, thread: 1, score: -21.0, average: -20.02 \n",
      "total_step_1:  153255\n",
      "total_step_2:  0\n",
      "episode: 240/2000000, thread: 0, score: -20.0, average: -20.02 \n",
      "total_step_1:  0\n",
      "total_step_2:  154505\n",
      "episode: 241/2000000, thread: 1, score: -20.0, average: -20.00 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total_step_1:  154733\n",
      "total_step_2:  0\n",
      "episode: 242/2000000, thread: 0, score: -19.0, average: -19.98 \n",
      "total_step_1:  0\n",
      "total_step_2:  155845\n",
      "episode: 243/2000000, thread: 1, score: -21.0, average: -20.02 \n",
      "total_step_1:  156500\n",
      "total_step_2:  0\n",
      "episode: 244/2000000, thread: 0, score: -18.0, average: -19.96 \n",
      "total_step_1:  0\n",
      "total_step_2:  157216\n",
      "episode: 245/2000000, thread: 1, score: -18.0, average: -19.92 \n",
      "total_step_1:  157949\n",
      "total_step_2:  0\n",
      "episode: 246/2000000, thread: 0, score: -18.0, average: -19.88 \n",
      "total_step_1:  0\n",
      "total_step_2:  158603\n",
      "episode: 247/2000000, thread: 1, score: -20.0, average: -19.86 SAVING\n",
      "total_step_1:  159212\n",
      "total_step_2:  0\n",
      "episode: 248/2000000, thread: 0, score: -19.0, average: -19.82 SAVING\n",
      "total_step_1:  0\n",
      "total_step_2:  159849\n",
      "episode: 249/2000000, thread: 1, score: -21.0, average: -19.84 \n",
      "total_step_1:  160424\n",
      "total_step_2:  0\n",
      "episode: 250/2000000, thread: 0, score: -20.0, average: -19.84 \n",
      "total_step_1:  0\n",
      "total_step_2:  161321\n",
      "episode: 251/2000000, thread: 1, score: -19.0, average: -19.82 SAVING\n",
      "total_step_1:  161961\n",
      "total_step_2:  0\n",
      "episode: 252/2000000, thread: 0, score: -19.0, average: -19.78 SAVING\n",
      "total_step_1:  0\n",
      "total_step_2:  162713\n",
      "episode: 253/2000000, thread: 1, score: -19.0, average: -19.74 SAVING\n",
      "total_step_1:  163287\n",
      "total_step_2:  0\n",
      "episode: 254/2000000, thread: 0, score: -21.0, average: -19.74 SAVING\n",
      "total_step_1:  0\n",
      "total_step_2:  164030\n",
      "episode: 255/2000000, thread: 1, score: -20.0, average: -19.74 SAVING\n",
      "total_step_1:  164847\n",
      "total_step_2:  0\n",
      "episode: 256/2000000, thread: 0, score: -19.0, average: -19.76 \n",
      "total_step_1:  0\n",
      "total_step_2:  165287\n",
      "episode: 257/2000000, thread: 1, score: -21.0, average: -19.76 \n",
      "total_step_1:  166025\n",
      "total_step_2:  0\n",
      "episode: 258/2000000, thread: 0, score: -20.0, average: -19.74 SAVING\n",
      "total_step_1:  0\n",
      "total_step_2:  166627\n",
      "episode: 259/2000000, thread: 1, score: -19.0, average: -19.72 SAVING\n",
      "total_step_1:  167186\n",
      "total_step_2:  0\n",
      "episode: 260/2000000, thread: 0, score: -21.0, average: -19.74 \n",
      "total_step_1:  0\n",
      "total_step_2:  167927\n",
      "episode: 261/2000000, thread: 1, score: -21.0, average: -19.74 \n",
      "total_step_1:  168333\n",
      "total_step_2:  0\n",
      "episode: 262/2000000, thread: 0, score: -21.0, average: -19.74 \n",
      "total_step_1:  0\n",
      "total_step_2:  169101\n",
      "episode: 263/2000000, thread: 1, score: -20.0, average: -19.74 \n",
      "total_step_1:  0\n",
      "total_step_2:  170299\n",
      "episode: 264/2000000, thread: 1, score: -21.0, average: -19.78 \n",
      "total_step_1:  170059\n",
      "total_step_2:  0\n",
      "episode: 265/2000000, thread: 0, score: -16.0, average: -19.70 SAVING\n",
      "total_step_1:  171319\n",
      "total_step_2:  0\n",
      "episode: 266/2000000, thread: 0, score: -20.0, average: -19.70 SAVING\n",
      "total_step_1:  0\n",
      "total_step_2:  171791\n",
      "episode: 267/2000000, thread: 1, score: -20.0, average: -19.76 \n",
      "total_step_1:  0\n",
      "total_step_2:  173066\n",
      "episode: 268/2000000, thread: 1, score: -21.0, average: -19.82 \n",
      "total_step_1:  173179\n",
      "total_step_2:  0\n",
      "episode: 269/2000000, thread: 0, score: -15.0, average: -19.70 SAVING\n",
      "total_step_1:  0\n",
      "total_step_2:  174522\n",
      "episode: 270/2000000, thread: 1, score: -19.0, average: -19.68 SAVING\n",
      "total_step_1:  174493\n",
      "total_step_2:  0\n",
      "episode: 271/2000000, thread: 0, score: -21.0, average: -19.72 \n",
      "total_step_1:  0\n",
      "total_step_2:  175835\n",
      "episode: 272/2000000, thread: 1, score: -20.0, average: -19.70 \n",
      "total_step_1:  175820\n",
      "total_step_2:  0\n",
      "episode: 273/2000000, thread: 0, score: -19.0, average: -19.66 SAVING\n",
      "total_step_1:  0\n",
      "total_step_2:  177449\n",
      "episode: 274/2000000, thread: 1, score: -18.0, average: -19.62 SAVING\n",
      "total_step_1:  177377\n",
      "total_step_2:  0\n",
      "episode: 275/2000000, thread: 0, score: -19.0, average: -19.58 SAVING\n",
      "total_step_1:  178617\n",
      "total_step_2:  0\n",
      "episode: 276/2000000, thread: 0, score: -20.0, average: -19.58 SAVING\n",
      "total_step_1:  0\n",
      "total_step_2:  179161\n",
      "episode: 277/2000000, thread: 1, score: -19.0, average: -19.56 SAVING\n",
      "total_step_1:  179967\n",
      "total_step_2:  0\n",
      "episode: 278/2000000, thread: 0, score: -20.0, average: -19.54 SAVING\n",
      "total_step_1:  0\n",
      "total_step_2:  180393\n",
      "episode: 279/2000000, thread: 1, score: -19.0, average: -19.56 \n",
      "total_step_1:  0\n",
      "total_step_2:  181856\n",
      "episode: 280/2000000, thread: 1, score: -20.0, average: -19.58 \n",
      "total_step_1:  181723\n",
      "total_step_2:  0\n",
      "episode: 281/2000000, thread: 0, score: -19.0, average: -19.58 \n",
      "total_step_1:  0\n",
      "total_step_2:  183422\n",
      "episode: 282/2000000, thread: 1, score: -19.0, average: -19.56 \n",
      "total_step_1:  183307\n",
      "total_step_2:  0\n",
      "episode: 283/2000000, thread: 0, score: -19.0, average: -19.52 SAVING\n",
      "total_step_1:  0\n",
      "total_step_2:  184773\n",
      "episode: 284/2000000, thread: 1, score: -20.0, average: -19.52 SAVING\n",
      "total_step_1:  184493\n",
      "total_step_2:  0\n",
      "episode: 285/2000000, thread: 0, score: -21.0, average: -19.54 \n",
      "total_step_1:  185729\n",
      "total_step_2:  0\n",
      "episode: 286/2000000, thread: 0, score: -20.0, average: -19.56 \n",
      "total_step_1:  0\n",
      "total_step_2:  186144\n",
      "episode: 287/2000000, thread: 1, score: -21.0, average: -19.62 \n",
      "total_step_1:  0\n",
      "total_step_2:  187551\n",
      "episode: 288/2000000, thread: 1, score: -18.0, average: -19.58 \n",
      "total_step_1:  187347\n",
      "total_step_2:  0\n",
      "episode: 289/2000000, thread: 0, score: -20.0, average: -19.56 \n",
      "total_step_1:  188847\n",
      "total_step_2:  0\n",
      "episode: 290/2000000, thread: 0, score: -18.0, average: -19.52 SAVING\n",
      "total_step_1:  0\n",
      "total_step_2:  189332\n",
      "episode: 291/2000000, thread: 1, score: -18.0, average: -19.48 SAVING\n",
      "total_step_1:  0\n",
      "total_step_2:  190562\n",
      "episode: 292/2000000, thread: 1, score: -20.0, average: -19.50 \n",
      "total_step_1:  190235\n",
      "total_step_2:  0\n",
      "episode: 293/2000000, thread: 0, score: -19.0, average: -19.46 SAVING\n",
      "total_step_1:  0\n",
      "total_step_2:  191813\n",
      "episode: 294/2000000, thread: 1, score: -21.0, average: -19.52 \n",
      "total_step_1:  191613\n",
      "total_step_2:  0\n",
      "episode: 295/2000000, thread: 0, score: -19.0, average: -19.54 \n",
      "total_step_1:  192949\n",
      "total_step_2:  0\n",
      "episode: 296/2000000, thread: 0, score: -18.0, average: -19.54 \n",
      "total_step_1:  0\n",
      "total_step_2:  193487\n",
      "episode: 297/2000000, thread: 1, score: -18.0, average: -19.50 \n",
      "total_step_1:  194292\n",
      "total_step_2:  0\n",
      "episode: 298/2000000, thread: 0, score: -20.0, average: -19.52 \n",
      "total_step_1:  0\n",
      "total_step_2:  194934\n",
      "episode: 299/2000000, thread: 1, score: -21.0, average: -19.52 \n",
      "total_step_1:  195609\n",
      "total_step_2:  0\n",
      "episode: 300/2000000, thread: 0, score: -18.0, average: -19.48 \n",
      "total_step_1:  0\n",
      "total_step_2:  196163\n",
      "episode: 301/2000000, thread: 1, score: -21.0, average: -19.52 \n",
      "total_step_1:  196976\n",
      "total_step_2:  0\n",
      "episode: 302/2000000, thread: 0, score: -20.0, average: -19.54 \n",
      "total_step_1:  0\n",
      "total_step_2:  197458\n",
      "episode: 303/2000000, thread: 1, score: -20.0, average: -19.56 \n",
      "total_step_1:  0\n",
      "total_step_2:  198717\n",
      "episode: 304/2000000, thread: 1, score: -21.0, average: -19.56 \n",
      "total_step_1:  198422\n",
      "total_step_2:  0\n",
      "episode: 305/2000000, thread: 0, score: -18.0, average: -19.52 \n",
      "total_step_1:  199719\n",
      "total_step_2:  0\n",
      "episode: 306/2000000, thread: 0, score: -20.0, average: -19.54 \n",
      "total_step_1:  0\n",
      "total_step_2:  200215\n",
      "episode: 307/2000000, thread: 1, score: -18.0, average: -19.48 \n",
      "total_step_1:  201027\n",
      "total_step_2:  0\n",
      "episode: 308/2000000, thread: 0, score: -20.0, average: -19.48 \n",
      "total_step_1:  0\n",
      "total_step_2:  201469\n",
      "episode: 309/2000000, thread: 1, score: -21.0, average: -19.52 \n",
      "total_step_1:  0\n",
      "total_step_2:  202854\n",
      "episode: 310/2000000, thread: 1, score: -20.0, average: -19.50 \n",
      "total_step_1:  202471\n",
      "total_step_2:  0\n",
      "episode: 311/2000000, thread: 0, score: -21.0, average: -19.50 \n",
      "total_step_1:  204076\n",
      "total_step_2:  0\n",
      "episode: 312/2000000, thread: 0, score: -19.0, average: -19.46 SAVING\n",
      "total_step_1:  0\n",
      "total_step_2:  204870\n",
      "episode: 313/2000000, thread: 1, score: -18.0, average: -19.42 SAVING\n",
      "total_step_1:  0\n",
      "total_step_2:  206058\n",
      "episode: 314/2000000, thread: 1, score: -21.0, average: -19.42 SAVING\n",
      "total_step_1:  205884\n",
      "total_step_2:  0\n",
      "episode: 315/2000000, thread: 0, score: -18.0, average: -19.46 \n",
      "total_step_1:  0\n",
      "total_step_2:  207249\n",
      "episode: 316/2000000, thread: 1, score: -20.0, average: -19.46 \n",
      "total_step_1:  207465\n",
      "total_step_2:  0\n",
      "episode: 317/2000000, thread: 0, score: -20.0, average: -19.46 \n",
      "total_step_1:  0\n",
      "total_step_2:  208559\n",
      "episode: 318/2000000, thread: 1, score: -19.0, average: -19.42 SAVING\n",
      "total_step_1:  208991\n",
      "total_step_2:  0\n",
      "episode: 319/2000000, thread: 0, score: -19.0, average: -19.50 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total_step_1:  0\n",
      "total_step_2:  209851\n",
      "episode: 320/2000000, thread: 1, score: -21.0, average: -19.54 \n",
      "total_step_1:  210655\n",
      "total_step_2:  0\n",
      "episode: 321/2000000, thread: 0, score: -19.0, average: -19.50 \n",
      "total_step_1:  0\n",
      "total_step_2:  211454\n",
      "episode: 322/2000000, thread: 1, score: -20.0, average: -19.50 \n",
      "total_step_1:  212001\n",
      "total_step_2:  0\n",
      "episode: 323/2000000, thread: 0, score: -20.0, average: -19.52 \n",
      "total_step_1:  0\n",
      "total_step_2:  212645\n",
      "episode: 324/2000000, thread: 1, score: -21.0, average: -19.58 \n",
      "total_step_1:  213536\n",
      "total_step_2:  0\n",
      "episode: 325/2000000, thread: 0, score: -18.0, average: -19.56 \n",
      "total_step_1:  0\n",
      "total_step_2:  214038\n",
      "episode: 326/2000000, thread: 1, score: -19.0, average: -19.54 \n",
      "total_step_1:  214919\n",
      "total_step_2:  0\n",
      "episode: 327/2000000, thread: 0, score: -20.0, average: -19.56 \n",
      "total_step_1:  0\n",
      "total_step_2:  215497\n",
      "episode: 328/2000000, thread: 1, score: -20.0, average: -19.56 \n",
      "total_step_1:  216220\n",
      "total_step_2:  0\n",
      "episode: 329/2000000, thread: 0, score: -20.0, average: -19.58 \n",
      "total_step_1:  0\n",
      "total_step_2:  216800\n",
      "episode: 330/2000000, thread: 1, score: -21.0, average: -19.60 \n",
      "total_step_1:  0\n",
      "total_step_2:  218435\n",
      "episode: 331/2000000, thread: 1, score: -21.0, average: -19.64 \n",
      "total_step_1:  217985\n",
      "total_step_2:  0\n",
      "episode: 332/2000000, thread: 0, score: -19.0, average: -19.64 \n",
      "total_step_1:  0\n",
      "total_step_2:  219811\n",
      "episode: 333/2000000, thread: 1, score: -21.0, average: -19.68 \n",
      "total_step_1:  219809\n",
      "total_step_2:  0\n",
      "episode: 334/2000000, thread: 0, score: -18.0, average: -19.64 \n",
      "total_step_1:  0\n",
      "total_step_2:  221585\n",
      "episode: 335/2000000, thread: 1, score: -20.0, average: -19.62 \n",
      "total_step_1:  221215\n",
      "total_step_2:  0\n",
      "episode: 336/2000000, thread: 0, score: -18.0, average: -19.58 \n",
      "total_step_1:  0\n",
      "total_step_2:  222818\n",
      "episode: 337/2000000, thread: 1, score: -20.0, average: -19.56 \n",
      "total_step_1:  222798\n",
      "total_step_2:  0\n",
      "episode: 338/2000000, thread: 0, score: -19.0, average: -19.58 \n",
      "total_step_1:  0\n",
      "total_step_2:  224479\n",
      "episode: 339/2000000, thread: 1, score: -18.0, average: -19.54 \n",
      "total_step_1:  224690\n",
      "total_step_2:  0\n",
      "episode: 340/2000000, thread: 0, score: -15.0, average: -19.48 \n",
      "total_step_1:  0\n",
      "total_step_2:  225935\n",
      "episode: 341/2000000, thread: 1, score: -21.0, average: -19.54 \n",
      "total_step_1:  226120\n",
      "total_step_2:  0\n",
      "episode: 342/2000000, thread: 0, score: -19.0, average: -19.52 \n",
      "total_step_1:  0\n",
      "total_step_2:  227418\n",
      "episode: 343/2000000, thread: 1, score: -19.0, average: -19.52 \n",
      "total_step_1:  228045\n",
      "total_step_2:  0\n",
      "episode: 344/2000000, thread: 0, score: -16.0, average: -19.42 SAVING\n",
      "total_step_1:  0\n",
      "total_step_2:  228878\n",
      "episode: 345/2000000, thread: 1, score: -19.0, average: -19.42 SAVING\n",
      "total_step_1:  229393\n",
      "total_step_2:  0\n",
      "episode: 346/2000000, thread: 0, score: -19.0, average: -19.44 \n",
      "total_step_1:  0\n",
      "total_step_2:  230343\n",
      "episode: 347/2000000, thread: 1, score: -21.0, average: -19.50 \n",
      "total_step_1:  230848\n",
      "total_step_2:  0\n",
      "episode: 348/2000000, thread: 0, score: -20.0, average: -19.50 \n",
      "total_step_1:  0\n",
      "total_step_2:  231902\n",
      "episode: 349/2000000, thread: 1, score: -19.0, average: -19.46 \n",
      "total_step_1:  232518\n",
      "total_step_2:  0\n",
      "episode: 350/2000000, thread: 0, score: -18.0, average: -19.46 \n",
      "total_step_1:  0\n",
      "total_step_2:  233290\n",
      "episode: 351/2000000, thread: 1, score: -19.0, average: -19.42 SAVING\n",
      "total_step_1:  234039\n",
      "total_step_2:  0\n",
      "episode: 352/2000000, thread: 0, score: -19.0, average: -19.40 SAVING\n",
      "total_step_1:  0\n",
      "total_step_2:  234970\n",
      "episode: 353/2000000, thread: 1, score: -19.0, average: -19.38 SAVING\n",
      "total_step_1:  0\n",
      "total_step_2:  236458\n",
      "episode: 354/2000000, thread: 1, score: -19.0, average: -19.34 SAVING\n",
      "total_step_1:  235919\n",
      "total_step_2:  0\n",
      "episode: 355/2000000, thread: 0, score: -19.0, average: -19.36 \n",
      "total_step_1:  237365\n",
      "total_step_2:  0\n",
      "episode: 356/2000000, thread: 0, score: -20.0, average: -19.36 \n",
      "total_step_1:  0\n",
      "total_step_2:  238125\n",
      "episode: 357/2000000, thread: 1, score: -18.0, average: -19.36 \n",
      "total_step_1:  239130\n",
      "total_step_2:  0\n",
      "episode: 358/2000000, thread: 0, score: -19.0, average: -19.34 SAVING\n",
      "total_step_1:  0\n",
      "total_step_2:  239823\n",
      "episode: 359/2000000, thread: 1, score: -17.0, average: -19.26 SAVING\n",
      "total_step_1:  240590\n",
      "total_step_2:  0\n",
      "episode: 360/2000000, thread: 0, score: -19.0, average: -19.24 SAVING\n",
      "total_step_1:  0\n",
      "total_step_2:  241389\n",
      "episode: 361/2000000, thread: 1, score: -20.0, average: -19.22 SAVING\n",
      "total_step_1:  241781\n",
      "total_step_2:  0\n",
      "episode: 362/2000000, thread: 0, score: -21.0, average: -19.26 \n",
      "total_step_1:  0\n",
      "total_step_2:  242946\n",
      "episode: 363/2000000, thread: 1, score: -19.0, average: -19.28 \n",
      "total_step_1:  243054\n",
      "total_step_2:  0\n",
      "episode: 364/2000000, thread: 0, score: -19.0, average: -19.24 \n",
      "total_step_1:  0\n",
      "total_step_2:  244590\n",
      "episode: 365/2000000, thread: 1, score: -19.0, average: -19.26 \n",
      "total_step_1:  244830\n",
      "total_step_2:  0\n",
      "episode: 366/2000000, thread: 0, score: -16.0, average: -19.18 SAVING\n",
      "total_step_1:  0\n",
      "total_step_2:  245964\n",
      "episode: 367/2000000, thread: 1, score: -20.0, average: -19.18 SAVING\n",
      "total_step_1:  246666\n",
      "total_step_2:  0\n",
      "episode: 368/2000000, thread: 0, score: -19.0, average: -19.18 SAVING\n",
      "total_step_1:  0\n",
      "total_step_2:  247483\n",
      "episode: 369/2000000, thread: 1, score: -17.0, average: -19.14 SAVING\n",
      "total_step_1:  248145\n",
      "total_step_2:  0\n",
      "episode: 370/2000000, thread: 0, score: -19.0, average: -19.10 SAVING\n",
      "total_step_1:  0\n",
      "total_step_2:  249198\n",
      "episode: 371/2000000, thread: 1, score: -18.0, average: -19.08 SAVING\n",
      "total_step_1:  249789\n",
      "total_step_2:  0\n",
      "episode: 372/2000000, thread: 0, score: -19.0, average: -19.06 SAVING\n",
      "total_step_1:  0\n",
      "total_step_2:  250806\n",
      "episode: 373/2000000, thread: 1, score: -19.0, average: -19.04 SAVING\n",
      "total_step_1:  251452\n",
      "total_step_2:  0\n",
      "episode: 374/2000000, thread: 0, score: -19.0, average: -19.00 SAVING\n",
      "total_step_1:  0\n",
      "total_step_2:  252484\n",
      "episode: 375/2000000, thread: 1, score: -20.0, average: -19.04 \n",
      "total_step_1:  252643\n",
      "total_step_2:  0\n",
      "episode: 376/2000000, thread: 0, score: -21.0, average: -19.08 \n",
      "total_step_1:  0\n",
      "total_step_2:  254422\n",
      "episode: 377/2000000, thread: 1, score: -17.0, average: -19.02 \n",
      "total_step_1:  253988\n",
      "total_step_2:  0\n",
      "episode: 378/2000000, thread: 0, score: -20.0, average: -19.02 \n",
      "total_step_1:  0\n",
      "total_step_2:  255986\n",
      "episode: 379/2000000, thread: 1, score: -19.0, average: -19.00 SAVING\n",
      "total_step_1:  255527\n",
      "total_step_2:  0\n",
      "episode: 380/2000000, thread: 0, score: -19.0, average: -18.96 SAVING\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import gym\n",
    "import pylab\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.layers import Input, Dense, Lambda, Add, Conv2D, Flatten\n",
    "from tensorflow.keras.optimizers import Adam, RMSprop\n",
    "from tensorflow.keras import backend as K\n",
    "import cv2\n",
    "import threading\n",
    "from threading import Thread, Lock\n",
    "import time\n",
    "import tensorflow_probability as tfp\n",
    "from typing import Any, List, Sequence, Tuple\n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '-1'\n",
    "#gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "#tf.config.experimental.set_virtual_device_configuration(gpus[0],\n",
    "#          [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=4000)])\n",
    "\n",
    "tfd = tfp.distributions\n",
    "\n",
    "class OurModel(tf.keras.Model):\n",
    "    def __init__(self, input_shape, action_space):\n",
    "        super(OurModel, self).__init__()\n",
    "        \n",
    "        self.flatten = Flatten()\n",
    "        self.dense_0 = Dense(512, activation='relu')\n",
    "        self.dense_1 = Dense(action_space)\n",
    "        self.dense_2 = Dense(1)\n",
    "        \n",
    "    def call(self, X_input):\n",
    "        X_input = self.flatten(X_input)\n",
    "        X_input = self.dense_0(X_input)\n",
    "        action_logit = self.dense_1(X_input)\n",
    "        value = self.dense_2(X_input)\n",
    "        \n",
    "        return action_logit, value\n",
    "\n",
    "\n",
    "def safe_log(x):\n",
    "  \"\"\"Computes a safe logarithm which returns 0 if x is zero.\"\"\"\n",
    "  return tf.where(\n",
    "      tf.math.equal(x, 0),\n",
    "      tf.zeros_like(x),\n",
    "      tf.math.log(tf.math.maximum(1e-12, x)))\n",
    "\n",
    "\n",
    "def take_vector_elements(vectors, indices):\n",
    "    \"\"\"\n",
    "    For a batch of vectors, take a single vector component\n",
    "    out of each vector.\n",
    "    Args:\n",
    "      vectors: a [batch x dims] Tensor.\n",
    "      indices: an int32 Tensor with `batch` entries.\n",
    "    Returns:\n",
    "      A Tensor with `batch` entries, one for each vector.\n",
    "    \"\"\"\n",
    "    return tf.gather_nd(vectors, tf.stack([tf.range(tf.shape(vectors)[0]), indices], axis=1))\n",
    "\n",
    "\n",
    "huber_loss = tf.keras.losses.Huber(reduction=tf.keras.losses.Reduction.SUM)\n",
    "sparse_ce = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True, reduction=tf.keras.losses.Reduction.SUM)\n",
    "mse_loss = tf.keras.losses.MeanSquaredError()\n",
    "\n",
    "\n",
    "class IMPALA_Agent:\n",
    "    # IMPALA Main Optimization Algorithm\n",
    "    def __init__(self, env_name):\n",
    "        # Initialization Environment and parameters\n",
    "        self.env_name = env_name       \n",
    "        self.env = gym.make(env_name)\n",
    "        self.action_size = self.env.action_space.n\n",
    "        self.EPISODES, self.episode, self.max_average = 2000000, 0, -21.0 # specific for pong\n",
    "        \n",
    "        self.memory_size = 50000\n",
    "        self.memory_1 = []\n",
    "        self.memory_2 = []\n",
    "        self.lock = Lock()\n",
    "        self.lr = 0.0001\n",
    "\n",
    "        num_hidden_units = 512\n",
    "    \n",
    "        self.batch_size = 512\n",
    "        self.ROWS = 80\n",
    "        self.COLS = 80\n",
    "        self.REM_STEP = 4\n",
    "        \n",
    "        self.state_size = (self.COLS, self.ROWS, self.REM_STEP)\n",
    "        self.image_memory = np.zeros(self.state_size)\n",
    "        \n",
    "        # Instantiate plot memory\n",
    "        self.scores, self.episodes, self.average = [], [], []\n",
    "\n",
    "        self.Save_Path = 'Models'\n",
    "        \n",
    "        if not os.path.exists(self.Save_Path): os.makedirs(self.Save_Path)\n",
    "        self.path = '{}_IMPALA_{}'.format(self.env_name, self.lr)\n",
    "        self.model_name = os.path.join(self.Save_Path, self.path)\n",
    "\n",
    "        # Create Actor-Critic network model\n",
    "        self.model = OurModel(input_shape=self.state_size, action_space=self.action_size)\n",
    "        \n",
    "        self.optimizer = tf.keras.optimizers.Adam(self.lr)\n",
    "\n",
    "    def remember_1(self, state, action, policy, reward, done):\n",
    "        experience = state, action, policy, reward, done\n",
    "        if len(self.memory_1) <= self.memory_size:\n",
    "            self.memory_1.append((experience))\n",
    "        else:\n",
    "            self.memory_1 = []\n",
    "            \n",
    "    def remember_2(self, state, action, policy, reward, done):\n",
    "        experience = state, action, policy, reward, done\n",
    "        if len(self.memory_2) <= self.memory_size:\n",
    "            self.memory_2.append((experience))\n",
    "        else:\n",
    "            self.memory_2 = []\n",
    "            \n",
    "    def act(self, state):\n",
    "        prediction = self.model(state, training=False)\n",
    "        dist = tfd.Categorical(logits=prediction[0])\n",
    "        action = int(dist.sample()[0])\n",
    "        policy = prediction[0]\n",
    "        \n",
    "        return action, policy\n",
    "\n",
    "    def update(self, states, actions, agent_policies, rewards, dones):\n",
    "        online_variables = self.model.trainable_variables\n",
    "        with tf.GradientTape() as tape:\n",
    "            tape.watch(online_variables)\n",
    "            \n",
    "            learner_outputs = self.model(states, training=True)\n",
    "            \n",
    "            agent_logits = tf.nn.softmax(agent_policies[:-1])\n",
    "            actions = actions[:-1]\n",
    "            rewards = rewards[1:]\n",
    "            dones = dones[1:]\n",
    "        \n",
    "            learner_policies = learner_outputs[0]\n",
    "            learner_logits = tf.nn.softmax(learner_policies[:-1])\n",
    "            \n",
    "            learner_values = learner_outputs[1]\n",
    "            learner_values = tf.squeeze(learner_values)\n",
    "            \n",
    "            bootstrap_value = learner_values[-1]\n",
    "            learner_values = learner_values[:-1]\n",
    "            \n",
    "            discounting = 0.99\n",
    "            discounts = tf.cast(~dones, tf.float32) * discounting\n",
    "            \n",
    "            actions = tf.convert_to_tensor(actions, dtype=tf.int32)\n",
    "                \n",
    "            target_action_probs = take_vector_elements(learner_logits, actions)\n",
    "            target_action_log_probs = tf.math.log(target_action_probs)\n",
    "            \n",
    "            behaviour_action_probs = take_vector_elements(agent_logits, actions)\n",
    "            behaviour_action_log_probs = tf.math.log(behaviour_action_probs)\n",
    "            \n",
    "            lambda_ = 1.0\n",
    "            \n",
    "            log_rhos = target_action_log_probs - behaviour_action_log_probs\n",
    "            \n",
    "            log_rhos = tf.convert_to_tensor(log_rhos, dtype=tf.float32)\n",
    "            discounts = tf.convert_to_tensor(discounts, dtype=tf.float32)\n",
    "            rewards = tf.convert_to_tensor(rewards, dtype=tf.float32)\n",
    "            values = tf.convert_to_tensor(learner_values, dtype=tf.float32)\n",
    "            bootstrap_value = tf.convert_to_tensor(bootstrap_value, dtype=tf.float32)\n",
    "            \n",
    "            clip_rho_threshold = tf.convert_to_tensor(1.0, dtype=tf.float32)\n",
    "            clip_pg_rho_threshold = tf.convert_to_tensor(1.0, dtype=tf.float32)\n",
    "            \n",
    "            rhos = tf.math.exp(log_rhos)\n",
    "            \n",
    "            clipped_rhos = tf.minimum(clip_rho_threshold, rhos, name='clipped_rhos')\n",
    "            \n",
    "            cs = tf.minimum(1.0, rhos, name='cs')\n",
    "            cs *= tf.convert_to_tensor(lambda_, dtype=tf.float32)\n",
    "\n",
    "            values_t_plus_1 = tf.concat([values[1:], tf.expand_dims(bootstrap_value, 0)], axis=0)\n",
    "            deltas = clipped_rhos * (rewards + discounts * values_t_plus_1 - values)\n",
    "        \n",
    "            acc = tf.zeros_like(bootstrap_value)\n",
    "            vs_minus_v_xs = []\n",
    "            for i in range(int(discounts.shape[0]) - 1, -1, -1):\n",
    "                discount, c, delta = discounts[i], cs[i], deltas[i]\n",
    "                acc = delta + discount * c * acc\n",
    "                vs_minus_v_xs.append(acc)  \n",
    "            \n",
    "            vs_minus_v_xs = vs_minus_v_xs[::-1]\n",
    "            \n",
    "            vs = tf.add(vs_minus_v_xs, values, name='vs')\n",
    "            vs_t_plus_1 = tf.concat([vs[1:], tf.expand_dims(bootstrap_value, 0)], axis=0)\n",
    "            clipped_pg_rhos = tf.minimum(clip_pg_rho_threshold, rhos, name='clipped_pg_rhos')\n",
    "            \n",
    "            pg_advantages = (clipped_pg_rhos * (rewards + discounts * vs_t_plus_1 - values))\n",
    "            \n",
    "            vs = tf.stop_gradient(vs)\n",
    "            pg_advantages = tf.stop_gradient(pg_advantages)\n",
    "            \n",
    "            actor_loss = -tf.reduce_mean(target_action_log_probs * pg_advantages)\n",
    "            \n",
    "            baseline_cost = 0.5\n",
    "            v_error = values - vs\n",
    "            critic_loss = baseline_cost * 0.5 * tf.reduce_mean(tf.square(v_error))\n",
    "            \n",
    "            total_loss = actor_loss + critic_loss\n",
    "\n",
    "        grads = tape.gradient(total_loss, self.model.trainable_variables)\n",
    "        self.optimizer.apply_gradients(zip(grads, self.model.trainable_variables))\n",
    "    \n",
    "    def replay_1(self):\n",
    "        memory_len = len(self.memory_1)\n",
    "        if len(self.memory_1) > self.batch_size:\n",
    "            start_index = random.randint(0, memory_len - self.batch_size)\n",
    "            minibatch = self.memory_1[start_index:start_index+self.batch_size]\n",
    "        else:\n",
    "            return\n",
    "\n",
    "        states = np.zeros((self.batch_size, *self.state_size), dtype=np.float32)\n",
    "        actions = np.zeros(self.batch_size, dtype=np.int32)\n",
    "        policies = np.zeros((self.batch_size, self.action_size), dtype=np.float32)\n",
    "        rewards = np.zeros(self.batch_size, dtype=np.float32)\n",
    "        dones = np.zeros(self.batch_size, dtype=np.bool)\n",
    "        for i in range(len(minibatch)):\n",
    "            states[i] = minibatch[i][0]\n",
    "            actions[i] = minibatch[i][1]\n",
    "            policies[i] = minibatch[i][2]\n",
    "            rewards[i] = minibatch[i][3]\n",
    "            dones[i] = minibatch[i][4]\n",
    "            \n",
    "        self.update(states, actions, policies, rewards, dones)\n",
    "        \n",
    "    def replay_2(self):\n",
    "        memory_len = len(self.memory_2)\n",
    "        if len(self.memory_2) > self.batch_size:\n",
    "            start_index = random.randint(0, memory_len - self.batch_size)\n",
    "            minibatch = self.memory_2[start_index:start_index+self.batch_size]\n",
    "        else:\n",
    "            return\n",
    "\n",
    "        states = np.zeros((self.batch_size, *self.state_size), dtype=np.float32)\n",
    "        actions = np.zeros(self.batch_size, dtype=np.int32)\n",
    "        policies = np.zeros((self.batch_size, self.action_size), dtype=np.float32)\n",
    "        rewards = np.zeros(self.batch_size, dtype=np.float32)\n",
    "        dones = np.zeros(self.batch_size, dtype=np.bool)\n",
    "        for i in range(len(minibatch)):\n",
    "            states[i] = minibatch[i][0]\n",
    "            actions[i] = minibatch[i][1]\n",
    "            policies[i] = minibatch[i][2]\n",
    "            rewards[i] = minibatch[i][3]\n",
    "            dones[i] = minibatch[i][4]\n",
    "            \n",
    "        self.update(states, actions, policies, rewards, dones)\n",
    "        \n",
    "    def load(self, model_name):\n",
    "        self.model = load_model(model_name, compile=False)\n",
    "\n",
    "    def save(self):\n",
    "        self.model.save(self.model_name)\n",
    "\n",
    "    pylab.figure(figsize=(18, 9))\n",
    "    def PlotModel(self, score, episode):\n",
    "        self.scores.append(score)\n",
    "        self.episodes.append(episode)\n",
    "        self.average.append(sum(self.scores[-50:]) / len(self.scores[-50:]))\n",
    "        if str(episode)[-2:] == \"00\":# much faster than episode % 100\n",
    "            pylab.plot(self.episodes, self.scores, 'b')\n",
    "            pylab.plot(self.episodes, self.average, 'r')\n",
    "            pylab.ylabel('Score', fontsize=18)\n",
    "            pylab.xlabel('Steps', fontsize=18)\n",
    "            try:\n",
    "                pylab.savefig(self.path + \".png\")\n",
    "            except OSError:\n",
    "                pass\n",
    "\n",
    "        return self.average[-1]\n",
    "    \n",
    "    def imshow(self, image, rem_step=0):\n",
    "        #print(\"image[:,:,rem_step].shape: \", image[:,:,rem_step].shape)\n",
    "        \n",
    "        cv2.imshow(\"pong\" + str(rem_step), image[:,:,rem_step])\n",
    "        if cv2.waitKey(25) & 0xFF == ord(\"q\"):\n",
    "            cv2.destroyAllWindows()\n",
    "\n",
    "    def GetImage(self, frame):\n",
    "        #print(\"frame.shape: \", frame.shape)\n",
    "        \n",
    "        # croping frame to 80x80 size\n",
    "        frame_cropped = frame[35:195:2, ::2,:]\n",
    "        if frame_cropped.shape[0] != self.COLS or frame_cropped.shape[1] != self.ROWS:\n",
    "            # OpenCV resize function \n",
    "            frame_cropped = cv2.resize(frame, (self.COLS, self.ROWS), interpolation=cv2.INTER_CUBIC)\n",
    "        \n",
    "        # converting to RGB (numpy way)\n",
    "        frame_rgb = 0.299*frame_cropped[:,:,0] + 0.587*frame_cropped[:,:,1] + 0.114*frame_cropped[:,:,2]\n",
    "        \n",
    "        # converting to Gray (OpenCV way)\n",
    "        #frame_gray = cv2.cvtColor(frame_cropped, cv2.COLOR_BGR2GRAY)     \n",
    "        #print(\"frame_gray.shape: \", frame_gray.shape)\n",
    "        \n",
    "        frame_rgb[frame_rgb < 100] = 0\n",
    "        frame_rgb[frame_rgb >= 100] = 255\n",
    "        # dividing by 255 we expresses value to 0-1 representation\n",
    "        new_frame = np.array(frame_rgb).astype(np.float32) / 255.0\n",
    "\n",
    "        # push our data by 1 frame, similar as deq() function work\n",
    "        self.image_memory = np.roll(self.image_memory, 1, axis=2)\n",
    "\n",
    "        # inserting new frame to free space\n",
    "        self.image_memory[:,:,0] = new_frame\n",
    "\n",
    "        # show image frame   \n",
    "        #self.imshow(self.image_memory, 0)\n",
    "        #self.imshow(self.image_memory, 1)\n",
    "        #self.imshow(self.image_memory, 2)\n",
    "        #self.imshow(self.image_memory, 3)\n",
    "\n",
    "        return np.expand_dims(self.image_memory, axis=0)\n",
    "        \n",
    "    def reset(self, env):\n",
    "        frame = env.reset()\n",
    "        for i in range(self.REM_STEP):\n",
    "            state = self.GetImage(frame)\n",
    "\n",
    "        return state\n",
    "\n",
    "    def step(self, action, env):\n",
    "        next_state, reward, done, info = env.step(action)\n",
    "        next_state = self.GetImage(next_state)\n",
    "        \n",
    "        return next_state, reward, done, info\n",
    "    \n",
    "    def train(self, n_threads):\n",
    "        self.env.close()\n",
    "        # Instantiate one environment per thread\n",
    "        envs = [gym.make(self.env_name) for i in range(n_threads)]\n",
    "\n",
    "        # Create threads\n",
    "        threads = [threading.Thread(\n",
    "                target=self.train_threading,\n",
    "                daemon=True,\n",
    "                args=(self, envs[i], i)) for i in range(n_threads)]\n",
    "\n",
    "        for t in threads:\n",
    "            time.sleep(2)\n",
    "            t.start()\n",
    "            \n",
    "        for t in threads:\n",
    "            time.sleep(10)\n",
    "            t.join()\n",
    "    \n",
    "    def render(self, obs):\n",
    "        cv2.imshow('obs', obs)\n",
    "        cv2.waitKey(1)\n",
    "    \n",
    "    def train_threading(self, agent, env, thread):\n",
    "        max_average = 15.0\n",
    "        total_step_1 = 0\n",
    "        total_step_2 = 0\n",
    "        for e in range(self.EPISODES):\n",
    "            state = self.reset(env)\n",
    "\n",
    "            done = False\n",
    "            score = 0\n",
    "            SAVING = ''\n",
    "            while not done:\n",
    "                #self.env.render()\n",
    "                \n",
    "                action, policy = self.act(state)\n",
    "                \n",
    "                next_state, reward, done, _ = self.step(action, env)\n",
    "                \n",
    "                if thread == 0:\n",
    "                    self.remember_1(state, action, policy, reward / 20.0, done)\n",
    "                elif thread ==1:\n",
    "                    self.remember_2(state, action, policy, reward / 20.0, done)\n",
    "                \n",
    "                state = next_state\n",
    "                score += reward\n",
    "                if done:\n",
    "                    break\n",
    "                \n",
    "                if thread == 0:\n",
    "                    if total_step_1 % 200 == 0:\n",
    "                        # train model\n",
    "                        self.replay_1()\n",
    "                        #self.lock.release()\n",
    "                    \n",
    "                    total_step_1 += 1\n",
    "                elif thread == 1:\n",
    "                    if total_step_2 % 201 == 0:\n",
    "                        # train model\n",
    "                        self.replay_2()\n",
    "                        #self.lock.release()\n",
    "                    \n",
    "                    total_step_2 += 1\n",
    "                \n",
    "            # Update episode count\n",
    "            with self.lock:\n",
    "                average = self.PlotModel(score, self.episode)\n",
    "                # saving best models\n",
    "                if average >= self.max_average:\n",
    "                    self.max_average = average\n",
    "                    #self.save()\n",
    "                    SAVING = \"SAVING\"\n",
    "                else:\n",
    "                    SAVING = \"\"\n",
    "                \n",
    "                print(\"total_step_1: \", total_step_1)\n",
    "                print(\"total_step_2: \", total_step_2)\n",
    "                print(\"episode: {}/{}, thread: {}, score: {}, average: {:.2f} {}\".format(self.episode, self.EPISODES, thread, score, average, SAVING))\n",
    "                if(self.episode < self.EPISODES):\n",
    "                    self.episode += 1\n",
    "                 \n",
    "    def test(self, Actor_name, Critic_name):\n",
    "        self.load(Actor_name, Critic_name)\n",
    "        for e in range(100):\n",
    "            state = self.reset(self.env)\n",
    "            done = False\n",
    "            score = 0\n",
    "            while not done:\n",
    "                self.env.render()\n",
    "                action = np.argmax(self.Actor.predict(state))\n",
    "                state, reward, done, _ = self.step(action, self.env, state)\n",
    "                score += reward\n",
    "                if done:\n",
    "                    print(\"episode: {}/{}, score: {}\".format(e, self.EPISODES, score))\n",
    "                    break\n",
    "\n",
    "        self.env.close()\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    env_name = 'Pong-v0'\n",
    "    agent = IMPALA_Agent(env_name)\n",
    "    \n",
    "    #agent.run() # use as IMPALA\n",
    "    agent.train(n_threads=2) # use as IMPALA\n",
    "    #agent.test('Models/Pong-v0_A3C_2.5e-05_Actor.h5', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
