{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YnGvpXU2YjO6",
    "outputId": "e969b181-49cd-4fba-85f8-7be1a61f689f",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-17 18:26:23.518008: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
      "2022-01-17 18:26:24.978412: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2022-01-17 18:26:24.979409: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1\n",
      "2022-01-17 18:26:25.005174: E tensorflow/stream_executor/cuda/cuda_driver.cc:328] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2022-01-17 18:26:25.005230: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: kimbring2-ROG-Strix-GA35DX-G35DX\n",
      "2022-01-17 18:26:25.005236: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: kimbring2-ROG-Strix-GA35DX-G35DX\n",
      "2022-01-17 18:26:25.005411: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 460.91.3\n",
      "2022-01-17 18:26:25.005446: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 460.91.3\n",
      "2022-01-17 18:26:25.005451: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 460.91.3\n",
      "2022-01-17 18:26:25.005918: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-01-17 18:26:25.007067: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 0/2000000, thread: 0, score: -20.0, average: -20.00 SAVING\n",
      "episode: 1/2000000, thread: 1, score: -20.0, average: -20.00 SAVING\n",
      "episode: 2/2000000, thread: 1, score: -20.0, average: -20.00 SAVING\n",
      "episode: 3/2000000, thread: 0, score: -20.0, average: -20.00 SAVING\n",
      "episode: 4/2000000, thread: 0, score: -21.0, average: -20.20 \n",
      "episode: 5/2000000, thread: 1, score: -20.0, average: -20.17 \n",
      "episode: 6/2000000, thread: 0, score: -20.0, average: -20.14 \n",
      "episode: 7/2000000, thread: 1, score: -18.0, average: -19.88 SAVING\n",
      "episode: 8/2000000, thread: 0, score: -21.0, average: -20.00 \n",
      "episode: 9/2000000, thread: 1, score: -20.0, average: -20.00 \n",
      "episode: 10/2000000, thread: 0, score: -20.0, average: -20.00 \n",
      "episode: 11/2000000, thread: 1, score: -21.0, average: -20.08 \n",
      "episode: 12/2000000, thread: 0, score: -21.0, average: -20.15 \n",
      "episode: 13/2000000, thread: 1, score: -20.0, average: -20.14 \n",
      "episode: 14/2000000, thread: 0, score: -21.0, average: -20.20 \n",
      "episode: 15/2000000, thread: 1, score: -20.0, average: -20.19 \n",
      "episode: 16/2000000, thread: 0, score: -21.0, average: -20.24 \n",
      "episode: 17/2000000, thread: 1, score: -19.0, average: -20.17 \n",
      "episode: 18/2000000, thread: 0, score: -21.0, average: -20.21 \n",
      "episode: 19/2000000, thread: 1, score: -21.0, average: -20.25 \n",
      "episode: 20/2000000, thread: 0, score: -21.0, average: -20.29 \n",
      "episode: 21/2000000, thread: 1, score: -20.0, average: -20.27 \n",
      "episode: 22/2000000, thread: 0, score: -20.0, average: -20.26 \n",
      "episode: 23/2000000, thread: 1, score: -19.0, average: -20.21 \n",
      "episode: 24/2000000, thread: 0, score: -20.0, average: -20.20 \n",
      "episode: 25/2000000, thread: 1, score: -19.0, average: -20.15 \n",
      "episode: 26/2000000, thread: 0, score: -21.0, average: -20.19 \n",
      "episode: 27/2000000, thread: 1, score: -19.0, average: -20.14 \n",
      "episode: 28/2000000, thread: 0, score: -21.0, average: -20.17 \n",
      "episode: 29/2000000, thread: 1, score: -21.0, average: -20.20 \n",
      "episode: 30/2000000, thread: 0, score: -21.0, average: -20.23 \n",
      "episode: 31/2000000, thread: 1, score: -20.0, average: -20.22 \n",
      "episode: 32/2000000, thread: 0, score: -19.0, average: -20.18 \n",
      "episode: 33/2000000, thread: 1, score: -21.0, average: -20.21 \n",
      "episode: 34/2000000, thread: 0, score: -20.0, average: -20.20 \n",
      "episode: 35/2000000, thread: 1, score: -20.0, average: -20.19 \n",
      "episode: 36/2000000, thread: 1, score: -21.0, average: -20.22 \n",
      "episode: 37/2000000, thread: 0, score: -21.0, average: -20.24 \n",
      "episode: 38/2000000, thread: 1, score: -20.0, average: -20.23 \n",
      "episode: 39/2000000, thread: 0, score: -20.0, average: -20.23 \n",
      "episode: 40/2000000, thread: 1, score: -21.0, average: -20.24 \n",
      "episode: 41/2000000, thread: 0, score: -20.0, average: -20.24 \n",
      "episode: 42/2000000, thread: 1, score: -21.0, average: -20.26 \n",
      "episode: 43/2000000, thread: 1, score: -21.0, average: -20.27 \n",
      "episode: 44/2000000, thread: 0, score: -19.0, average: -20.24 \n",
      "episode: 45/2000000, thread: 1, score: -21.0, average: -20.26 \n",
      "episode: 46/2000000, thread: 0, score: -21.0, average: -20.28 \n",
      "episode: 47/2000000, thread: 1, score: -20.0, average: -20.27 \n",
      "episode: 48/2000000, thread: 0, score: -20.0, average: -20.27 \n",
      "episode: 49/2000000, thread: 1, score: -18.0, average: -20.22 \n",
      "episode: 50/2000000, thread: 0, score: -21.0, average: -20.24 \n",
      "episode: 51/2000000, thread: 1, score: -21.0, average: -20.26 \n",
      "episode: 52/2000000, thread: 0, score: -20.0, average: -20.26 \n",
      "episode: 53/2000000, thread: 1, score: -20.0, average: -20.26 \n",
      "episode: 54/2000000, thread: 0, score: -21.0, average: -20.26 \n",
      "episode: 55/2000000, thread: 1, score: -21.0, average: -20.28 \n",
      "episode: 56/2000000, thread: 0, score: -21.0, average: -20.30 \n",
      "episode: 57/2000000, thread: 1, score: -20.0, average: -20.34 \n",
      "episode: 58/2000000, thread: 0, score: -21.0, average: -20.34 \n",
      "episode: 59/2000000, thread: 1, score: -21.0, average: -20.36 \n",
      "episode: 60/2000000, thread: 0, score: -20.0, average: -20.36 \n",
      "episode: 61/2000000, thread: 1, score: -18.0, average: -20.30 \n",
      "episode: 62/2000000, thread: 0, score: -19.0, average: -20.26 \n",
      "episode: 63/2000000, thread: 1, score: -21.0, average: -20.28 \n",
      "episode: 64/2000000, thread: 1, score: -21.0, average: -20.28 \n",
      "episode: 65/2000000, thread: 0, score: -20.0, average: -20.28 \n",
      "episode: 66/2000000, thread: 1, score: -20.0, average: -20.26 \n",
      "episode: 67/2000000, thread: 0, score: -18.0, average: -20.24 \n",
      "episode: 68/2000000, thread: 1, score: -20.0, average: -20.22 \n",
      "episode: 69/2000000, thread: 0, score: -19.0, average: -20.18 \n",
      "episode: 70/2000000, thread: 1, score: -20.0, average: -20.16 \n",
      "episode: 71/2000000, thread: 0, score: -19.0, average: -20.14 \n",
      "episode: 72/2000000, thread: 1, score: -19.0, average: -20.12 \n",
      "episode: 73/2000000, thread: 0, score: -18.0, average: -20.10 \n",
      "episode: 74/2000000, thread: 1, score: -20.0, average: -20.10 \n",
      "episode: 75/2000000, thread: 1, score: -20.0, average: -20.12 \n",
      "episode: 76/2000000, thread: 0, score: -20.0, average: -20.10 \n",
      "episode: 77/2000000, thread: 1, score: -21.0, average: -20.14 \n",
      "episode: 78/2000000, thread: 0, score: -20.0, average: -20.12 \n",
      "episode: 79/2000000, thread: 1, score: -20.0, average: -20.10 \n",
      "episode: 80/2000000, thread: 0, score: -21.0, average: -20.10 \n",
      "episode: 81/2000000, thread: 1, score: -21.0, average: -20.12 \n",
      "episode: 82/2000000, thread: 0, score: -21.0, average: -20.16 \n",
      "episode: 83/2000000, thread: 1, score: -20.0, average: -20.14 \n",
      "episode: 84/2000000, thread: 0, score: -21.0, average: -20.16 \n",
      "episode: 85/2000000, thread: 1, score: -21.0, average: -20.18 \n",
      "episode: 86/2000000, thread: 0, score: -21.0, average: -20.18 \n",
      "episode: 87/2000000, thread: 1, score: -21.0, average: -20.18 \n",
      "episode: 88/2000000, thread: 0, score: -21.0, average: -20.20 \n",
      "episode: 89/2000000, thread: 1, score: -20.0, average: -20.20 \n",
      "episode: 90/2000000, thread: 0, score: -18.0, average: -20.14 \n",
      "episode: 91/2000000, thread: 1, score: -18.0, average: -20.10 \n",
      "episode: 92/2000000, thread: 0, score: -21.0, average: -20.10 \n",
      "episode: 93/2000000, thread: 1, score: -20.0, average: -20.08 \n",
      "episode: 94/2000000, thread: 0, score: -20.0, average: -20.10 \n",
      "episode: 95/2000000, thread: 1, score: -20.0, average: -20.08 \n",
      "episode: 96/2000000, thread: 0, score: -19.0, average: -20.04 \n",
      "episode: 97/2000000, thread: 1, score: -21.0, average: -20.06 \n",
      "episode: 98/2000000, thread: 0, score: -20.0, average: -20.06 \n",
      "episode: 99/2000000, thread: 1, score: -21.0, average: -20.12 \n",
      "episode: 100/2000000, thread: 0, score: -20.0, average: -20.10 \n",
      "episode: 101/2000000, thread: 1, score: -21.0, average: -20.10 \n",
      "episode: 102/2000000, thread: 0, score: -21.0, average: -20.12 \n",
      "episode: 103/2000000, thread: 1, score: -18.0, average: -20.08 \n",
      "episode: 104/2000000, thread: 0, score: -20.0, average: -20.06 \n",
      "episode: 105/2000000, thread: 1, score: -20.0, average: -20.04 \n",
      "episode: 106/2000000, thread: 0, score: -20.0, average: -20.02 \n",
      "episode: 107/2000000, thread: 1, score: -19.0, average: -20.00 \n",
      "episode: 108/2000000, thread: 0, score: -20.0, average: -19.98 \n",
      "episode: 109/2000000, thread: 1, score: -21.0, average: -19.98 \n",
      "episode: 110/2000000, thread: 0, score: -20.0, average: -19.98 \n",
      "episode: 111/2000000, thread: 1, score: -19.0, average: -20.00 \n",
      "episode: 112/2000000, thread: 0, score: -21.0, average: -20.04 \n",
      "episode: 113/2000000, thread: 1, score: -20.0, average: -20.02 \n",
      "episode: 114/2000000, thread: 0, score: -20.0, average: -20.00 \n",
      "episode: 115/2000000, thread: 1, score: -20.0, average: -20.00 \n",
      "episode: 116/2000000, thread: 0, score: -20.0, average: -20.00 \n",
      "episode: 117/2000000, thread: 1, score: -20.0, average: -20.04 \n",
      "episode: 118/2000000, thread: 0, score: -20.0, average: -20.04 \n",
      "episode: 119/2000000, thread: 1, score: -21.0, average: -20.08 \n",
      "episode: 120/2000000, thread: 0, score: -19.0, average: -20.06 \n",
      "episode: 121/2000000, thread: 1, score: -19.0, average: -20.06 \n",
      "episode: 122/2000000, thread: 1, score: -20.0, average: -20.08 \n",
      "episode: 123/2000000, thread: 0, score: -20.0, average: -20.12 \n",
      "episode: 124/2000000, thread: 0, score: -20.0, average: -20.12 \n",
      "episode: 125/2000000, thread: 1, score: -21.0, average: -20.14 \n",
      "episode: 126/2000000, thread: 0, score: -21.0, average: -20.16 \n",
      "episode: 127/2000000, thread: 1, score: -21.0, average: -20.16 \n",
      "episode: 128/2000000, thread: 0, score: -20.0, average: -20.16 \n",
      "episode: 129/2000000, thread: 1, score: -19.0, average: -20.14 \n",
      "episode: 130/2000000, thread: 0, score: -20.0, average: -20.12 \n",
      "episode: 131/2000000, thread: 1, score: -20.0, average: -20.10 \n",
      "episode: 132/2000000, thread: 1, score: -21.0, average: -20.10 \n",
      "episode: 133/2000000, thread: 0, score: -21.0, average: -20.12 \n",
      "episode: 134/2000000, thread: 0, score: -20.0, average: -20.10 \n",
      "episode: 135/2000000, thread: 1, score: -20.0, average: -20.08 \n",
      "episode: 136/2000000, thread: 0, score: -20.0, average: -20.06 \n",
      "episode: 137/2000000, thread: 1, score: -20.0, average: -20.04 \n",
      "episode: 138/2000000, thread: 1, score: -19.0, average: -20.00 \n",
      "episode: 139/2000000, thread: 0, score: -21.0, average: -20.02 \n",
      "episode: 140/2000000, thread: 1, score: -20.0, average: -20.06 \n",
      "episode: 141/2000000, thread: 0, score: -20.0, average: -20.10 \n",
      "episode: 142/2000000, thread: 1, score: -20.0, average: -20.08 \n",
      "episode: 143/2000000, thread: 0, score: -20.0, average: -20.08 \n",
      "episode: 144/2000000, thread: 1, score: -21.0, average: -20.10 \n",
      "episode: 145/2000000, thread: 0, score: -21.0, average: -20.12 \n",
      "episode: 146/2000000, thread: 1, score: -21.0, average: -20.16 \n",
      "episode: 147/2000000, thread: 0, score: -21.0, average: -20.16 \n",
      "episode: 148/2000000, thread: 1, score: -19.0, average: -20.14 \n",
      "episode: 149/2000000, thread: 0, score: -20.0, average: -20.12 \n",
      "episode: 150/2000000, thread: 1, score: -21.0, average: -20.14 \n",
      "episode: 151/2000000, thread: 0, score: -20.0, average: -20.12 \n",
      "episode: 152/2000000, thread: 1, score: -21.0, average: -20.12 \n",
      "episode: 153/2000000, thread: 0, score: -20.0, average: -20.16 \n",
      "episode: 154/2000000, thread: 1, score: -21.0, average: -20.18 \n",
      "episode: 155/2000000, thread: 0, score: -20.0, average: -20.18 \n",
      "episode: 156/2000000, thread: 1, score: -21.0, average: -20.20 \n",
      "episode: 157/2000000, thread: 0, score: -21.0, average: -20.24 \n",
      "episode: 158/2000000, thread: 1, score: -21.0, average: -20.26 \n",
      "episode: 159/2000000, thread: 1, score: -20.0, average: -20.24 \n",
      "episode: 160/2000000, thread: 0, score: -20.0, average: -20.24 \n",
      "episode: 161/2000000, thread: 1, score: -17.0, average: -20.20 \n",
      "episode: 162/2000000, thread: 0, score: -19.0, average: -20.16 \n",
      "episode: 163/2000000, thread: 1, score: -20.0, average: -20.16 \n",
      "episode: 164/2000000, thread: 0, score: -20.0, average: -20.16 \n",
      "episode: 165/2000000, thread: 1, score: -21.0, average: -20.18 \n",
      "episode: 166/2000000, thread: 0, score: -20.0, average: -20.18 \n",
      "episode: 167/2000000, thread: 1, score: -21.0, average: -20.20 \n",
      "episode: 168/2000000, thread: 0, score: -19.0, average: -20.18 \n",
      "episode: 169/2000000, thread: 1, score: -20.0, average: -20.16 \n",
      "episode: 170/2000000, thread: 0, score: -21.0, average: -20.20 \n",
      "episode: 171/2000000, thread: 1, score: -21.0, average: -20.24 \n",
      "episode: 172/2000000, thread: 0, score: -21.0, average: -20.26 \n",
      "episode: 173/2000000, thread: 1, score: -21.0, average: -20.28 \n",
      "episode: 174/2000000, thread: 0, score: -20.0, average: -20.28 \n",
      "episode: 175/2000000, thread: 1, score: -20.0, average: -20.26 \n",
      "episode: 176/2000000, thread: 1, score: -21.0, average: -20.26 \n",
      "episode: 177/2000000, thread: 0, score: -19.0, average: -20.22 \n",
      "episode: 178/2000000, thread: 0, score: -21.0, average: -20.24 \n",
      "episode: 179/2000000, thread: 1, score: -18.0, average: -20.22 \n",
      "episode: 180/2000000, thread: 1, score: -20.0, average: -20.22 \n",
      "episode: 181/2000000, thread: 0, score: -19.0, average: -20.20 \n",
      "episode: 182/2000000, thread: 1, score: -20.0, average: -20.18 \n",
      "episode: 183/2000000, thread: 0, score: -20.0, average: -20.16 \n",
      "episode: 184/2000000, thread: 1, score: -20.0, average: -20.16 \n",
      "episode: 185/2000000, thread: 0, score: -19.0, average: -20.14 \n",
      "episode: 186/2000000, thread: 1, score: -18.0, average: -20.10 \n",
      "episode: 187/2000000, thread: 0, score: -21.0, average: -20.12 \n",
      "episode: 188/2000000, thread: 1, score: -19.0, average: -20.12 \n",
      "episode: 189/2000000, thread: 0, score: -21.0, average: -20.12 \n",
      "episode: 190/2000000, thread: 1, score: -20.0, average: -20.12 \n",
      "episode: 191/2000000, thread: 0, score: -19.0, average: -20.10 \n",
      "episode: 192/2000000, thread: 1, score: -19.0, average: -20.08 \n",
      "episode: 193/2000000, thread: 0, score: -20.0, average: -20.08 \n",
      "episode: 194/2000000, thread: 1, score: -18.0, average: -20.02 \n",
      "episode: 195/2000000, thread: 0, score: -20.0, average: -20.00 \n",
      "episode: 196/2000000, thread: 1, score: -20.0, average: -19.98 \n",
      "episode: 197/2000000, thread: 0, score: -19.0, average: -19.94 \n",
      "episode: 198/2000000, thread: 1, score: -18.0, average: -19.92 \n",
      "episode: 199/2000000, thread: 0, score: -21.0, average: -19.94 \n",
      "episode: 200/2000000, thread: 1, score: -21.0, average: -19.94 \n",
      "episode: 201/2000000, thread: 0, score: -20.0, average: -19.94 \n",
      "episode: 202/2000000, thread: 1, score: -19.0, average: -19.90 \n",
      "episode: 203/2000000, thread: 0, score: -20.0, average: -19.90 \n",
      "episode: 204/2000000, thread: 1, score: -19.0, average: -19.86 SAVING\n",
      "episode: 205/2000000, thread: 0, score: -20.0, average: -19.86 SAVING\n",
      "episode: 206/2000000, thread: 1, score: -21.0, average: -19.86 SAVING\n",
      "episode: 207/2000000, thread: 1, score: -21.0, average: -19.86 SAVING\n",
      "episode: 208/2000000, thread: 0, score: -20.0, average: -19.84 SAVING\n",
      "episode: 209/2000000, thread: 1, score: -20.0, average: -19.84 SAVING\n",
      "episode: 210/2000000, thread: 0, score: -20.0, average: -19.84 SAVING\n",
      "episode: 211/2000000, thread: 1, score: -21.0, average: -19.92 \n",
      "episode: 212/2000000, thread: 0, score: -21.0, average: -19.96 \n",
      "episode: 213/2000000, thread: 1, score: -19.0, average: -19.94 \n",
      "episode: 214/2000000, thread: 0, score: -21.0, average: -19.96 \n",
      "episode: 215/2000000, thread: 1, score: -21.0, average: -19.96 \n",
      "episode: 216/2000000, thread: 0, score: -20.0, average: -19.96 \n",
      "episode: 217/2000000, thread: 1, score: -21.0, average: -19.96 \n",
      "episode: 218/2000000, thread: 0, score: -20.0, average: -19.98 \n",
      "episode: 219/2000000, thread: 1, score: -20.0, average: -19.98 \n",
      "episode: 220/2000000, thread: 1, score: -19.0, average: -19.94 \n",
      "episode: 221/2000000, thread: 0, score: -19.0, average: -19.90 \n",
      "episode: 222/2000000, thread: 1, score: -19.0, average: -19.86 \n",
      "episode: 223/2000000, thread: 0, score: -20.0, average: -19.84 SAVING\n",
      "episode: 224/2000000, thread: 1, score: -21.0, average: -19.86 \n",
      "episode: 225/2000000, thread: 0, score: -20.0, average: -19.86 \n",
      "episode: 226/2000000, thread: 1, score: -20.0, average: -19.84 SAVING\n",
      "episode: 227/2000000, thread: 0, score: -21.0, average: -19.88 \n",
      "episode: 228/2000000, thread: 1, score: -21.0, average: -19.88 \n",
      "episode: 229/2000000, thread: 0, score: -19.0, average: -19.90 \n",
      "episode: 230/2000000, thread: 1, score: -20.0, average: -19.90 \n",
      "episode: 231/2000000, thread: 1, score: -19.0, average: -19.90 \n",
      "episode: 232/2000000, thread: 0, score: -19.0, average: -19.88 \n",
      "episode: 233/2000000, thread: 1, score: -21.0, average: -19.90 \n",
      "episode: 234/2000000, thread: 0, score: -17.0, average: -19.84 SAVING\n",
      "episode: 235/2000000, thread: 1, score: -21.0, average: -19.88 \n",
      "episode: 236/2000000, thread: 0, score: -20.0, average: -19.92 \n",
      "episode: 237/2000000, thread: 1, score: -19.0, average: -19.88 \n",
      "episode: 238/2000000, thread: 0, score: -21.0, average: -19.92 \n",
      "episode: 239/2000000, thread: 1, score: -18.0, average: -19.86 \n",
      "episode: 240/2000000, thread: 0, score: -19.0, average: -19.84 SAVING\n",
      "episode: 241/2000000, thread: 1, score: -21.0, average: -19.88 \n",
      "episode: 242/2000000, thread: 0, score: -20.0, average: -19.90 \n",
      "episode: 243/2000000, thread: 1, score: -20.0, average: -19.90 \n",
      "episode: 244/2000000, thread: 0, score: -20.0, average: -19.94 \n",
      "episode: 245/2000000, thread: 1, score: -21.0, average: -19.96 \n",
      "episode: 246/2000000, thread: 0, score: -20.0, average: -19.96 \n",
      "episode: 247/2000000, thread: 1, score: -20.0, average: -19.98 \n",
      "episode: 248/2000000, thread: 0, score: -21.0, average: -20.04 \n",
      "episode: 249/2000000, thread: 1, score: -20.0, average: -20.02 \n",
      "episode: 250/2000000, thread: 1, score: -21.0, average: -20.02 \n",
      "episode: 251/2000000, thread: 0, score: -18.0, average: -19.98 \n",
      "episode: 252/2000000, thread: 1, score: -20.0, average: -20.00 \n",
      "episode: 253/2000000, thread: 0, score: -21.0, average: -20.02 \n",
      "episode: 254/2000000, thread: 1, score: -19.0, average: -20.02 \n",
      "episode: 255/2000000, thread: 0, score: -21.0, average: -20.04 \n",
      "episode: 256/2000000, thread: 1, score: -21.0, average: -20.04 \n",
      "episode: 257/2000000, thread: 0, score: -20.0, average: -20.02 \n",
      "episode: 258/2000000, thread: 1, score: -19.0, average: -20.00 \n",
      "episode: 259/2000000, thread: 0, score: -17.0, average: -19.94 \n",
      "episode: 260/2000000, thread: 1, score: -19.0, average: -19.92 \n",
      "episode: 261/2000000, thread: 0, score: -20.0, average: -19.90 \n",
      "episode: 262/2000000, thread: 1, score: -21.0, average: -19.90 \n",
      "episode: 263/2000000, thread: 0, score: -21.0, average: -19.94 \n",
      "episode: 264/2000000, thread: 1, score: -20.0, average: -19.92 \n",
      "episode: 265/2000000, thread: 0, score: -21.0, average: -19.92 \n",
      "episode: 266/2000000, thread: 1, score: -20.0, average: -19.92 \n",
      "episode: 267/2000000, thread: 1, score: -19.0, average: -19.88 \n",
      "episode: 268/2000000, thread: 0, score: -18.0, average: -19.84 SAVING\n",
      "episode: 269/2000000, thread: 1, score: -20.0, average: -19.84 SAVING\n",
      "episode: 270/2000000, thread: 0, score: -21.0, average: -19.88 \n",
      "episode: 271/2000000, thread: 1, score: -21.0, average: -19.92 \n",
      "episode: 272/2000000, thread: 0, score: -20.0, average: -19.94 \n",
      "episode: 273/2000000, thread: 1, score: -21.0, average: -19.96 \n",
      "episode: 274/2000000, thread: 0, score: -20.0, average: -19.94 \n",
      "episode: 275/2000000, thread: 1, score: -19.0, average: -19.92 \n",
      "episode: 276/2000000, thread: 0, score: -20.0, average: -19.92 \n",
      "episode: 277/2000000, thread: 1, score: -21.0, average: -19.92 \n",
      "episode: 278/2000000, thread: 0, score: -21.0, average: -19.92 \n",
      "episode: 279/2000000, thread: 1, score: -20.0, average: -19.94 \n",
      "episode: 280/2000000, thread: 0, score: -20.0, average: -19.94 \n",
      "episode: 281/2000000, thread: 1, score: -20.0, average: -19.96 \n",
      "episode: 282/2000000, thread: 1, score: -21.0, average: -20.00 \n",
      "episode: 283/2000000, thread: 0, score: -20.0, average: -19.98 \n",
      "episode: 284/2000000, thread: 1, score: -21.0, average: -20.06 \n",
      "episode: 285/2000000, thread: 0, score: -19.0, average: -20.02 \n",
      "episode: 286/2000000, thread: 1, score: -20.0, average: -20.02 \n",
      "episode: 287/2000000, thread: 0, score: -19.0, average: -20.02 \n",
      "episode: 288/2000000, thread: 1, score: -20.0, average: -20.00 \n",
      "episode: 289/2000000, thread: 0, score: -20.0, average: -20.04 \n",
      "episode: 290/2000000, thread: 1, score: -19.0, average: -20.04 \n",
      "episode: 291/2000000, thread: 1, score: -21.0, average: -20.04 \n",
      "episode: 292/2000000, thread: 0, score: -20.0, average: -20.04 \n",
      "episode: 293/2000000, thread: 0, score: -21.0, average: -20.06 \n",
      "episode: 294/2000000, thread: 1, score: -19.0, average: -20.04 \n",
      "episode: 295/2000000, thread: 0, score: -21.0, average: -20.04 \n",
      "episode: 296/2000000, thread: 1, score: -20.0, average: -20.04 \n",
      "episode: 297/2000000, thread: 0, score: -21.0, average: -20.06 \n",
      "episode: 298/2000000, thread: 1, score: -21.0, average: -20.06 \n",
      "episode: 299/2000000, thread: 0, score: -21.0, average: -20.08 \n",
      "episode: 300/2000000, thread: 1, score: -21.0, average: -20.08 \n",
      "episode: 301/2000000, thread: 0, score: -21.0, average: -20.14 \n",
      "episode: 302/2000000, thread: 1, score: -20.0, average: -20.14 \n",
      "episode: 303/2000000, thread: 0, score: -20.0, average: -20.12 \n",
      "episode: 304/2000000, thread: 1, score: -20.0, average: -20.14 \n",
      "episode: 305/2000000, thread: 0, score: -21.0, average: -20.14 \n",
      "episode: 306/2000000, thread: 1, score: -19.0, average: -20.10 \n",
      "episode: 307/2000000, thread: 0, score: -20.0, average: -20.10 \n",
      "episode: 308/2000000, thread: 1, score: -21.0, average: -20.14 \n",
      "episode: 309/2000000, thread: 0, score: -19.0, average: -20.18 \n",
      "episode: 310/2000000, thread: 1, score: -18.0, average: -20.16 \n",
      "episode: 311/2000000, thread: 1, score: -20.0, average: -20.16 \n",
      "episode: 312/2000000, thread: 0, score: -19.0, average: -20.12 \n",
      "episode: 313/2000000, thread: 1, score: -21.0, average: -20.12 \n",
      "episode: 314/2000000, thread: 0, score: -21.0, average: -20.14 \n",
      "episode: 315/2000000, thread: 1, score: -20.0, average: -20.12 \n",
      "episode: 316/2000000, thread: 0, score: -20.0, average: -20.12 \n",
      "episode: 317/2000000, thread: 1, score: -20.0, average: -20.14 \n",
      "episode: 318/2000000, thread: 1, score: -21.0, average: -20.20 \n",
      "episode: 319/2000000, thread: 0, score: -18.0, average: -20.16 \n",
      "episode: 320/2000000, thread: 1, score: -20.0, average: -20.14 \n",
      "episode: 321/2000000, thread: 0, score: -20.0, average: -20.12 \n",
      "episode: 322/2000000, thread: 1, score: -19.0, average: -20.10 \n",
      "episode: 323/2000000, thread: 0, score: -20.0, average: -20.08 \n",
      "episode: 324/2000000, thread: 1, score: -18.0, average: -20.04 \n",
      "episode: 325/2000000, thread: 0, score: -17.0, average: -20.00 \n",
      "episode: 326/2000000, thread: 1, score: -21.0, average: -20.02 \n",
      "episode: 327/2000000, thread: 0, score: -18.0, average: -19.96 \n",
      "episode: 328/2000000, thread: 1, score: -18.0, average: -19.90 \n",
      "episode: 329/2000000, thread: 0, score: -18.0, average: -19.86 \n",
      "episode: 330/2000000, thread: 1, score: -19.0, average: -19.84 SAVING\n",
      "episode: 331/2000000, thread: 0, score: -19.0, average: -19.82 SAVING\n",
      "episode: 332/2000000, thread: 1, score: -19.0, average: -19.78 SAVING\n",
      "episode: 333/2000000, thread: 0, score: -20.0, average: -19.78 SAVING\n",
      "episode: 334/2000000, thread: 1, score: -18.0, average: -19.72 SAVING\n",
      "episode: 335/2000000, thread: 0, score: -21.0, average: -19.76 \n",
      "episode: 336/2000000, thread: 1, score: -21.0, average: -19.78 \n",
      "episode: 337/2000000, thread: 0, score: -20.0, average: -19.80 \n",
      "episode: 338/2000000, thread: 1, score: -21.0, average: -19.82 \n",
      "episode: 339/2000000, thread: 1, score: -19.0, average: -19.80 \n",
      "episode: 340/2000000, thread: 0, score: -17.0, average: -19.76 \n",
      "episode: 341/2000000, thread: 1, score: -20.0, average: -19.74 \n",
      "episode: 342/2000000, thread: 0, score: -20.0, average: -19.74 \n",
      "episode: 343/2000000, thread: 1, score: -20.0, average: -19.72 SAVING\n",
      "episode: 344/2000000, thread: 0, score: -20.0, average: -19.74 \n",
      "episode: 345/2000000, thread: 1, score: -19.0, average: -19.70 SAVING\n",
      "episode: 346/2000000, thread: 0, score: -19.0, average: -19.68 SAVING\n",
      "episode: 347/2000000, thread: 1, score: -21.0, average: -19.68 SAVING\n",
      "episode: 348/2000000, thread: 0, score: -18.0, average: -19.62 SAVING\n",
      "episode: 349/2000000, thread: 1, score: -21.0, average: -19.62 SAVING\n",
      "episode: 350/2000000, thread: 0, score: -20.0, average: -19.60 SAVING\n",
      "episode: 351/2000000, thread: 1, score: -19.0, average: -19.56 SAVING\n",
      "episode: 352/2000000, thread: 0, score: -19.0, average: -19.54 SAVING\n",
      "episode: 353/2000000, thread: 1, score: -21.0, average: -19.56 \n",
      "episode: 354/2000000, thread: 0, score: -19.0, average: -19.54 SAVING\n",
      "episode: 355/2000000, thread: 1, score: -21.0, average: -19.54 SAVING\n",
      "episode: 356/2000000, thread: 0, score: -19.0, average: -19.54 SAVING\n",
      "episode: 357/2000000, thread: 1, score: -21.0, average: -19.56 \n",
      "episode: 358/2000000, thread: 1, score: -21.0, average: -19.56 \n",
      "episode: 359/2000000, thread: 0, score: -19.0, average: -19.56 \n",
      "episode: 360/2000000, thread: 1, score: -21.0, average: -19.62 \n",
      "episode: 361/2000000, thread: 0, score: -19.0, average: -19.60 \n",
      "episode: 362/2000000, thread: 1, score: -21.0, average: -19.64 \n",
      "episode: 363/2000000, thread: 0, score: -19.0, average: -19.60 \n",
      "episode: 364/2000000, thread: 1, score: -21.0, average: -19.60 \n",
      "episode: 365/2000000, thread: 0, score: -20.0, average: -19.60 \n",
      "episode: 366/2000000, thread: 1, score: -20.0, average: -19.60 \n",
      "episode: 367/2000000, thread: 1, score: -18.0, average: -19.56 \n",
      "episode: 368/2000000, thread: 0, score: -19.0, average: -19.52 SAVING\n",
      "episode: 369/2000000, thread: 1, score: -21.0, average: -19.58 \n",
      "episode: 370/2000000, thread: 0, score: -20.0, average: -19.58 \n",
      "episode: 371/2000000, thread: 1, score: -19.0, average: -19.56 \n",
      "episode: 372/2000000, thread: 0, score: -19.0, average: -19.56 \n",
      "episode: 373/2000000, thread: 1, score: -16.0, average: -19.48 SAVING\n",
      "episode: 374/2000000, thread: 0, score: -20.0, average: -19.52 \n",
      "episode: 375/2000000, thread: 1, score: -21.0, average: -19.60 \n",
      "episode: 376/2000000, thread: 0, score: -21.0, average: -19.60 \n",
      "episode: 377/2000000, thread: 1, score: -21.0, average: -19.66 \n",
      "episode: 378/2000000, thread: 1, score: -19.0, average: -19.68 \n",
      "episode: 379/2000000, thread: 0, score: -18.0, average: -19.68 \n",
      "episode: 380/2000000, thread: 1, score: -19.0, average: -19.68 \n",
      "episode: 381/2000000, thread: 0, score: -21.0, average: -19.72 \n",
      "episode: 382/2000000, thread: 1, score: -21.0, average: -19.76 \n",
      "episode: 383/2000000, thread: 0, score: -19.0, average: -19.74 \n",
      "episode: 384/2000000, thread: 1, score: -20.0, average: -19.78 \n",
      "episode: 385/2000000, thread: 0, score: -21.0, average: -19.78 \n",
      "episode: 386/2000000, thread: 1, score: -21.0, average: -19.78 \n",
      "episode: 387/2000000, thread: 0, score: -21.0, average: -19.80 \n",
      "episode: 388/2000000, thread: 1, score: -21.0, average: -19.80 \n",
      "episode: 389/2000000, thread: 0, score: -20.0, average: -19.82 \n",
      "episode: 390/2000000, thread: 1, score: -21.0, average: -19.90 \n",
      "episode: 391/2000000, thread: 0, score: -21.0, average: -19.92 \n",
      "episode: 392/2000000, thread: 1, score: -20.0, average: -19.92 \n",
      "episode: 393/2000000, thread: 0, score: -20.0, average: -19.92 \n",
      "episode: 394/2000000, thread: 1, score: -19.0, average: -19.90 \n",
      "episode: 395/2000000, thread: 1, score: -20.0, average: -19.92 \n",
      "episode: 396/2000000, thread: 0, score: -20.0, average: -19.94 \n",
      "episode: 397/2000000, thread: 1, score: -19.0, average: -19.90 \n",
      "episode: 398/2000000, thread: 0, score: -21.0, average: -19.96 \n",
      "episode: 399/2000000, thread: 1, score: -20.0, average: -19.94 \n",
      "episode: 400/2000000, thread: 1, score: -20.0, average: -19.94 \n",
      "episode: 401/2000000, thread: 0, score: -19.0, average: -19.94 \n",
      "episode: 402/2000000, thread: 1, score: -19.0, average: -19.94 \n",
      "episode: 403/2000000, thread: 0, score: -19.0, average: -19.90 \n",
      "episode: 404/2000000, thread: 1, score: -20.0, average: -19.92 \n",
      "episode: 405/2000000, thread: 0, score: -21.0, average: -19.92 \n",
      "episode: 406/2000000, thread: 0, score: -21.0, average: -19.96 \n",
      "episode: 407/2000000, thread: 1, score: -19.0, average: -19.92 \n",
      "episode: 408/2000000, thread: 0, score: -20.0, average: -19.90 \n",
      "episode: 409/2000000, thread: 1, score: -20.0, average: -19.92 \n",
      "episode: 410/2000000, thread: 1, score: -21.0, average: -19.92 \n",
      "episode: 411/2000000, thread: 0, score: -19.0, average: -19.92 \n",
      "episode: 412/2000000, thread: 1, score: -20.0, average: -19.90 \n",
      "episode: 413/2000000, thread: 0, score: -20.0, average: -19.92 \n",
      "episode: 414/2000000, thread: 1, score: -20.0, average: -19.90 \n",
      "episode: 415/2000000, thread: 0, score: -18.0, average: -19.86 \n",
      "episode: 416/2000000, thread: 1, score: -19.0, average: -19.84 \n",
      "episode: 417/2000000, thread: 0, score: -17.0, average: -19.82 \n",
      "episode: 418/2000000, thread: 1, score: -17.0, average: -19.78 \n",
      "episode: 419/2000000, thread: 0, score: -20.0, average: -19.76 \n",
      "episode: 420/2000000, thread: 1, score: -20.0, average: -19.76 \n",
      "episode: 421/2000000, thread: 0, score: -20.0, average: -19.78 \n",
      "episode: 422/2000000, thread: 1, score: -20.0, average: -19.80 \n",
      "episode: 423/2000000, thread: 0, score: -19.0, average: -19.86 \n",
      "episode: 424/2000000, thread: 1, score: -20.0, average: -19.86 \n",
      "episode: 425/2000000, thread: 0, score: -19.0, average: -19.82 \n",
      "episode: 426/2000000, thread: 1, score: -19.0, average: -19.78 \n",
      "episode: 427/2000000, thread: 1, score: -20.0, average: -19.76 \n",
      "episode: 428/2000000, thread: 0, score: -20.0, average: -19.78 \n",
      "episode: 429/2000000, thread: 1, score: -21.0, average: -19.84 \n",
      "episode: 430/2000000, thread: 0, score: -19.0, average: -19.84 \n",
      "episode: 431/2000000, thread: 1, score: -19.0, average: -19.80 \n",
      "episode: 432/2000000, thread: 0, score: -21.0, average: -19.80 \n",
      "episode: 433/2000000, thread: 1, score: -18.0, average: -19.78 \n",
      "episode: 434/2000000, thread: 0, score: -20.0, average: -19.78 \n",
      "episode: 435/2000000, thread: 1, score: -20.0, average: -19.76 \n",
      "episode: 436/2000000, thread: 0, score: -20.0, average: -19.74 \n",
      "episode: 437/2000000, thread: 1, score: -20.0, average: -19.72 \n",
      "episode: 438/2000000, thread: 0, score: -20.0, average: -19.70 \n",
      "episode: 439/2000000, thread: 1, score: -21.0, average: -19.72 \n",
      "episode: 440/2000000, thread: 0, score: -21.0, average: -19.72 \n",
      "episode: 441/2000000, thread: 1, score: -20.0, average: -19.70 \n",
      "episode: 442/2000000, thread: 0, score: -19.0, average: -19.68 \n",
      "episode: 443/2000000, thread: 1, score: -20.0, average: -19.68 \n",
      "episode: 444/2000000, thread: 0, score: -20.0, average: -19.70 \n",
      "episode: 445/2000000, thread: 1, score: -21.0, average: -19.72 \n",
      "episode: 446/2000000, thread: 0, score: -20.0, average: -19.72 \n",
      "episode: 447/2000000, thread: 1, score: -21.0, average: -19.76 \n",
      "episode: 448/2000000, thread: 0, score: -21.0, average: -19.76 \n",
      "episode: 449/2000000, thread: 1, score: -20.0, average: -19.76 \n",
      "episode: 450/2000000, thread: 0, score: -20.0, average: -19.76 \n",
      "episode: 451/2000000, thread: 1, score: -19.0, average: -19.76 \n",
      "episode: 452/2000000, thread: 1, score: -20.0, average: -19.78 \n",
      "episode: 453/2000000, thread: 0, score: -21.0, average: -19.82 \n",
      "episode: 454/2000000, thread: 1, score: -21.0, average: -19.84 \n",
      "episode: 455/2000000, thread: 0, score: -20.0, average: -19.82 \n",
      "episode: 456/2000000, thread: 1, score: -20.0, average: -19.80 \n",
      "episode: 457/2000000, thread: 0, score: -21.0, average: -19.84 \n",
      "episode: 458/2000000, thread: 1, score: -20.0, average: -19.84 \n",
      "episode: 459/2000000, thread: 0, score: -18.0, average: -19.80 \n",
      "episode: 460/2000000, thread: 1, score: -19.0, average: -19.76 \n",
      "episode: 461/2000000, thread: 0, score: -21.0, average: -19.80 \n",
      "episode: 462/2000000, thread: 1, score: -19.0, average: -19.78 \n",
      "episode: 463/2000000, thread: 0, score: -19.0, average: -19.76 \n",
      "episode: 464/2000000, thread: 1, score: -21.0, average: -19.78 \n",
      "episode: 465/2000000, thread: 0, score: -19.0, average: -19.80 \n",
      "episode: 466/2000000, thread: 1, score: -19.0, average: -19.80 \n",
      "episode: 467/2000000, thread: 0, score: -19.0, average: -19.84 \n",
      "episode: 468/2000000, thread: 1, score: -20.0, average: -19.90 \n",
      "episode: 469/2000000, thread: 0, score: -21.0, average: -19.92 \n",
      "episode: 470/2000000, thread: 1, score: -17.0, average: -19.86 \n",
      "episode: 471/2000000, thread: 0, score: -20.0, average: -19.86 \n",
      "episode: 472/2000000, thread: 1, score: -18.0, average: -19.82 \n",
      "episode: 473/2000000, thread: 0, score: -19.0, average: -19.82 \n",
      "episode: 474/2000000, thread: 1, score: -19.0, average: -19.80 \n",
      "episode: 475/2000000, thread: 0, score: -21.0, average: -19.84 \n",
      "episode: 476/2000000, thread: 1, score: -19.0, average: -19.84 \n",
      "episode: 477/2000000, thread: 0, score: -19.0, average: -19.82 \n",
      "episode: 478/2000000, thread: 1, score: -20.0, average: -19.82 \n",
      "episode: 479/2000000, thread: 0, score: -21.0, average: -19.82 \n",
      "episode: 480/2000000, thread: 1, score: -21.0, average: -19.86 \n",
      "episode: 481/2000000, thread: 0, score: -21.0, average: -19.90 \n",
      "episode: 482/2000000, thread: 1, score: -21.0, average: -19.90 \n",
      "episode: 483/2000000, thread: 0, score: -20.0, average: -19.94 \n",
      "episode: 484/2000000, thread: 1, score: -21.0, average: -19.96 \n",
      "episode: 485/2000000, thread: 0, score: -19.0, average: -19.94 \n",
      "episode: 486/2000000, thread: 1, score: -18.0, average: -19.90 \n",
      "episode: 487/2000000, thread: 0, score: -19.0, average: -19.88 \n",
      "episode: 488/2000000, thread: 1, score: -19.0, average: -19.86 \n",
      "episode: 489/2000000, thread: 1, score: -21.0, average: -19.86 \n",
      "episode: 490/2000000, thread: 0, score: -19.0, average: -19.82 \n",
      "episode: 491/2000000, thread: 0, score: -19.0, average: -19.80 \n",
      "episode: 492/2000000, thread: 1, score: -19.0, average: -19.80 \n",
      "episode: 493/2000000, thread: 1, score: -20.0, average: -19.80 \n",
      "episode: 494/2000000, thread: 0, score: -18.0, average: -19.76 \n",
      "episode: 495/2000000, thread: 1, score: -19.0, average: -19.72 \n",
      "episode: 496/2000000, thread: 0, score: -21.0, average: -19.74 \n",
      "episode: 497/2000000, thread: 1, score: -20.0, average: -19.72 \n",
      "episode: 498/2000000, thread: 0, score: -21.0, average: -19.72 \n",
      "episode: 499/2000000, thread: 1, score: -20.0, average: -19.72 \n",
      "episode: 500/2000000, thread: 0, score: -19.0, average: -19.70 \n",
      "episode: 501/2000000, thread: 1, score: -21.0, average: -19.74 \n",
      "episode: 502/2000000, thread: 0, score: -20.0, average: -19.74 \n",
      "episode: 503/2000000, thread: 1, score: -19.0, average: -19.70 \n",
      "episode: 504/2000000, thread: 0, score: -19.0, average: -19.66 \n",
      "episode: 505/2000000, thread: 1, score: -18.0, average: -19.62 \n",
      "episode: 506/2000000, thread: 0, score: -19.0, average: -19.60 \n",
      "episode: 507/2000000, thread: 1, score: -20.0, average: -19.58 \n",
      "episode: 508/2000000, thread: 0, score: -20.0, average: -19.58 \n",
      "episode: 509/2000000, thread: 1, score: -21.0, average: -19.64 \n",
      "episode: 510/2000000, thread: 0, score: -20.0, average: -19.66 \n",
      "episode: 511/2000000, thread: 1, score: -18.0, average: -19.60 \n",
      "episode: 512/2000000, thread: 0, score: -20.0, average: -19.62 \n",
      "episode: 513/2000000, thread: 1, score: -21.0, average: -19.66 \n",
      "episode: 514/2000000, thread: 0, score: -18.0, average: -19.60 \n",
      "episode: 515/2000000, thread: 1, score: -17.0, average: -19.56 \n",
      "episode: 516/2000000, thread: 1, score: -20.0, average: -19.58 \n",
      "episode: 517/2000000, thread: 0, score: -17.0, average: -19.54 \n",
      "episode: 518/2000000, thread: 1, score: -21.0, average: -19.56 \n",
      "episode: 519/2000000, thread: 0, score: -20.0, average: -19.54 \n",
      "episode: 520/2000000, thread: 1, score: -19.0, average: -19.58 \n",
      "episode: 521/2000000, thread: 0, score: -16.0, average: -19.50 \n",
      "episode: 522/2000000, thread: 1, score: -19.0, average: -19.52 \n",
      "episode: 523/2000000, thread: 0, score: -20.0, average: -19.54 \n",
      "episode: 524/2000000, thread: 1, score: -20.0, average: -19.56 \n",
      "episode: 525/2000000, thread: 0, score: -21.0, average: -19.56 \n",
      "episode: 526/2000000, thread: 1, score: -20.0, average: -19.58 \n",
      "episode: 527/2000000, thread: 0, score: -21.0, average: -19.62 \n",
      "episode: 528/2000000, thread: 1, score: -20.0, average: -19.62 \n",
      "episode: 529/2000000, thread: 0, score: -19.0, average: -19.58 \n",
      "episode: 530/2000000, thread: 1, score: -18.0, average: -19.52 \n",
      "episode: 531/2000000, thread: 1, score: -20.0, average: -19.50 \n",
      "episode: 532/2000000, thread: 0, score: -16.0, average: -19.40 SAVING\n",
      "episode: 533/2000000, thread: 1, score: -20.0, average: -19.40 SAVING\n",
      "episode: 534/2000000, thread: 0, score: -19.0, average: -19.36 SAVING\n",
      "episode: 535/2000000, thread: 1, score: -18.0, average: -19.34 SAVING\n",
      "episode: 536/2000000, thread: 0, score: -19.0, average: -19.36 \n",
      "episode: 537/2000000, thread: 1, score: -19.0, average: -19.36 \n",
      "episode: 538/2000000, thread: 0, score: -20.0, average: -19.38 \n",
      "episode: 539/2000000, thread: 1, score: -21.0, average: -19.38 \n",
      "episode: 540/2000000, thread: 0, score: -19.0, average: -19.38 \n",
      "episode: 541/2000000, thread: 1, score: -21.0, average: -19.42 \n",
      "episode: 542/2000000, thread: 0, score: -19.0, average: -19.42 \n",
      "episode: 543/2000000, thread: 1, score: -19.0, average: -19.40 \n",
      "episode: 544/2000000, thread: 0, score: -21.0, average: -19.46 \n",
      "episode: 545/2000000, thread: 1, score: -18.0, average: -19.44 \n",
      "episode: 546/2000000, thread: 0, score: -18.0, average: -19.38 \n",
      "episode: 547/2000000, thread: 1, score: -19.0, average: -19.36 \n",
      "episode: 548/2000000, thread: 0, score: -20.0, average: -19.34 SAVING\n",
      "episode: 549/2000000, thread: 1, score: -18.0, average: -19.30 SAVING\n",
      "episode: 550/2000000, thread: 1, score: -21.0, average: -19.34 \n",
      "episode: 551/2000000, thread: 0, score: -21.0, average: -19.34 \n",
      "episode: 552/2000000, thread: 1, score: -19.0, average: -19.32 \n",
      "episode: 553/2000000, thread: 0, score: -21.0, average: -19.36 \n",
      "episode: 554/2000000, thread: 1, score: -19.0, average: -19.36 \n",
      "episode: 555/2000000, thread: 0, score: -20.0, average: -19.40 \n",
      "episode: 556/2000000, thread: 0, score: -21.0, average: -19.44 \n",
      "episode: 557/2000000, thread: 1, score: -20.0, average: -19.44 \n",
      "episode: 558/2000000, thread: 0, score: -20.0, average: -19.44 \n",
      "episode: 559/2000000, thread: 1, score: -21.0, average: -19.44 \n",
      "episode: 560/2000000, thread: 1, score: -19.0, average: -19.42 \n",
      "episode: 561/2000000, thread: 0, score: -18.0, average: -19.42 \n",
      "episode: 562/2000000, thread: 1, score: -19.0, average: -19.40 \n",
      "episode: 563/2000000, thread: 0, score: -20.0, average: -19.38 \n",
      "episode: 564/2000000, thread: 1, score: -21.0, average: -19.44 \n",
      "episode: 565/2000000, thread: 0, score: -19.0, average: -19.48 \n",
      "episode: 566/2000000, thread: 1, score: -21.0, average: -19.50 \n",
      "episode: 567/2000000, thread: 0, score: -21.0, average: -19.58 \n",
      "episode: 568/2000000, thread: 1, score: -21.0, average: -19.58 \n",
      "episode: 569/2000000, thread: 0, score: -21.0, average: -19.60 \n",
      "episode: 570/2000000, thread: 1, score: -20.0, average: -19.62 \n",
      "episode: 571/2000000, thread: 0, score: -20.0, average: -19.70 \n",
      "episode: 572/2000000, thread: 1, score: -21.0, average: -19.74 \n",
      "episode: 573/2000000, thread: 0, score: -20.0, average: -19.74 \n",
      "episode: 574/2000000, thread: 1, score: -19.0, average: -19.72 \n",
      "episode: 575/2000000, thread: 0, score: -20.0, average: -19.70 \n",
      "episode: 576/2000000, thread: 1, score: -19.0, average: -19.68 \n",
      "episode: 577/2000000, thread: 1, score: -19.0, average: -19.64 \n",
      "episode: 578/2000000, thread: 0, score: -19.0, average: -19.62 \n",
      "episode: 579/2000000, thread: 0, score: -20.0, average: -19.64 \n",
      "episode: 580/2000000, thread: 1, score: -20.0, average: -19.68 \n",
      "episode: 581/2000000, thread: 0, score: -21.0, average: -19.70 \n",
      "episode: 582/2000000, thread: 1, score: -20.0, average: -19.78 \n",
      "episode: 583/2000000, thread: 0, score: -20.0, average: -19.78 \n",
      "episode: 584/2000000, thread: 1, score: -21.0, average: -19.82 \n",
      "episode: 585/2000000, thread: 0, score: -19.0, average: -19.84 \n",
      "episode: 586/2000000, thread: 1, score: -19.0, average: -19.84 \n",
      "episode: 587/2000000, thread: 1, score: -20.0, average: -19.86 \n",
      "episode: 588/2000000, thread: 0, score: -20.0, average: -19.86 \n",
      "episode: 589/2000000, thread: 1, score: -20.0, average: -19.84 \n",
      "episode: 590/2000000, thread: 0, score: -19.0, average: -19.84 \n",
      "episode: 591/2000000, thread: 1, score: -20.0, average: -19.82 \n",
      "episode: 592/2000000, thread: 0, score: -19.0, average: -19.82 \n",
      "episode: 593/2000000, thread: 1, score: -21.0, average: -19.86 \n",
      "episode: 594/2000000, thread: 0, score: -19.0, average: -19.82 \n",
      "episode: 595/2000000, thread: 1, score: -19.0, average: -19.84 \n",
      "episode: 596/2000000, thread: 0, score: -20.0, average: -19.88 \n",
      "episode: 597/2000000, thread: 1, score: -20.0, average: -19.90 \n",
      "episode: 598/2000000, thread: 0, score: -20.0, average: -19.90 \n",
      "episode: 599/2000000, thread: 1, score: -16.0, average: -19.86 \n",
      "episode: 600/2000000, thread: 0, score: -20.0, average: -19.84 \n",
      "episode: 601/2000000, thread: 1, score: -17.0, average: -19.76 \n",
      "episode: 602/2000000, thread: 0, score: -19.0, average: -19.76 \n",
      "episode: 603/2000000, thread: 1, score: -19.0, average: -19.72 \n",
      "episode: 604/2000000, thread: 0, score: -20.0, average: -19.74 \n",
      "episode: 605/2000000, thread: 1, score: -21.0, average: -19.76 \n",
      "episode: 606/2000000, thread: 0, score: -20.0, average: -19.74 \n",
      "episode: 607/2000000, thread: 1, score: -21.0, average: -19.76 \n",
      "episode: 608/2000000, thread: 0, score: -21.0, average: -19.78 \n",
      "episode: 609/2000000, thread: 1, score: -19.0, average: -19.74 \n",
      "episode: 610/2000000, thread: 0, score: -20.0, average: -19.76 \n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import gym\n",
    "import pylab\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.layers import Input, Dense, Lambda, Add, Conv2D, Flatten\n",
    "from tensorflow.keras.optimizers import Adam, RMSprop\n",
    "from tensorflow.keras import backend as K\n",
    "import cv2\n",
    "import threading\n",
    "from threading import Thread, Lock\n",
    "import time\n",
    "import tensorflow_probability as tfp\n",
    "from typing import Any, List, Sequence, Tuple\n",
    "from gym.spaces import Dict, Discrete, Box, Tuple\n",
    "from parametric_distribution import get_parametric_distribution_for_action_space\n",
    "from collections import deque\n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '-1'\n",
    "#gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "#tf.config.experimental.set_virtual_device_configuration(gpus[0],\n",
    "#          [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=4000)])\n",
    "\n",
    "tfd = tfp.distributions\n",
    "\n",
    "class OurModel(tf.keras.Model):\n",
    "    def __init__(self, input_shape, action_space):\n",
    "        super(OurModel, self).__init__()\n",
    "        \n",
    "        self.flatten = Flatten()\n",
    "        self.dense_0 = Dense(512, activation='relu')\n",
    "        self.dense_1 = Dense(action_space)\n",
    "        self.dense_2 = Dense(1)\n",
    "        \n",
    "    def call(self, X_input):\n",
    "        X_input = self.flatten(X_input)\n",
    "        X_input = self.dense_0(X_input)\n",
    "        action_logit = self.dense_1(X_input)\n",
    "        value = self.dense_2(X_input)\n",
    "        \n",
    "        return action_logit, value\n",
    "\n",
    "\n",
    "def safe_log(x):\n",
    "  \"\"\"Computes a safe logarithm which returns 0 if x is zero.\"\"\"\n",
    "  return tf.where(\n",
    "      tf.math.equal(x, 0),\n",
    "      tf.zeros_like(x),\n",
    "      tf.math.log(tf.math.maximum(1e-12, x)))\n",
    "\n",
    "\n",
    "def take_vector_elements(vectors, indices):\n",
    "    \"\"\"\n",
    "    For a batch of vectors, take a single vector component\n",
    "    out of each vector.\n",
    "    Args:\n",
    "      vectors: a [batch x dims] Tensor.\n",
    "      indices: an int32 Tensor with `batch` entries.\n",
    "    Returns:\n",
    "      A Tensor with `batch` entries, one for each vector.\n",
    "    \"\"\"\n",
    "    return tf.gather_nd(vectors, tf.stack([tf.range(tf.shape(vectors)[0]), indices], axis=1))\n",
    "\n",
    "\n",
    "huber_loss = tf.keras.losses.Huber(reduction=tf.keras.losses.Reduction.SUM)\n",
    "sparse_ce = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True, reduction=tf.keras.losses.Reduction.SUM)\n",
    "mse_loss = tf.keras.losses.MeanSquaredError()\n",
    "\n",
    "parametric_action_distribution = get_parametric_distribution_for_action_space(Discrete(6))\n",
    "\n",
    "class IMPALA_Agent:\n",
    "    # IMPALA Main Optimization Algorithm\n",
    "    def __init__(self, env_name):\n",
    "        # Initialization Environment and parameters\n",
    "        self.env_name = env_name       \n",
    "        self.env = gym.make(env_name)\n",
    "        self.action_size = self.env.action_space.n\n",
    "        self.EPISODES, self.episode, self.max_average = 2000000, 0, -21.0 # specific for pong\n",
    "        \n",
    "        self.memory_size = 25000\n",
    "        self.memory_1 = []\n",
    "        self.memory_2 = []\n",
    "        \n",
    "        self.batch_size = 2\n",
    "        self.unroll_length = 101\n",
    "        \n",
    "        self.ROWS = 80\n",
    "        self.COLS = 80\n",
    "        self.REM_STEP = 4\n",
    "        self.state_size = (self.COLS, self.ROWS, self.REM_STEP)\n",
    "        \n",
    "        self.memory_index_1 = 1\n",
    "        self.memory_index_2 = 1\n",
    "        \n",
    "        self.states_1 = np.zeros((self.unroll_length + 1, *self.state_size), dtype=np.float32)\n",
    "        self.actions_1 = np.zeros((self.unroll_length + 1), dtype=np.int32)\n",
    "        self.policies_1 = np.zeros((self.unroll_length + 1, self.action_size), dtype=np.float32)\n",
    "        self.rewards_1 = np.zeros((self.unroll_length + 1), dtype=np.float32)\n",
    "        self.dones_1 = np.zeros((self.unroll_length + 1), dtype=np.bool)\n",
    "        \n",
    "        self.states_2 = np.zeros((self.unroll_length + 1, *self.state_size), dtype=np.float32)\n",
    "        self.actions_2 = np.zeros((self.unroll_length + 1), dtype=np.int32)\n",
    "        self.policies_2 = np.zeros((self.unroll_length + 1, self.action_size), dtype=np.float32)\n",
    "        self.rewards_2 = np.zeros((self.unroll_length + 1), dtype=np.float32)\n",
    "        self.dones_2 = np.zeros((self.unroll_length + 1), dtype=np.bool)\n",
    "        \n",
    "        self.deq = deque(maxlen=10)\n",
    "        \n",
    "        self.states = np.zeros((self.batch_size, self.unroll_length, *self.state_size), dtype=np.float32)\n",
    "        self.actions = np.zeros((self.batch_size, self.unroll_length), dtype=np.int32)\n",
    "        self.policies = np.zeros((self.batch_size, self.unroll_length, self.action_size), dtype=np.float32)\n",
    "        self.rewards = np.zeros((self.batch_size, self.unroll_length), dtype=np.float32)\n",
    "        self.dones = np.zeros((self.batch_size, self.unroll_length), dtype=np.bool)\n",
    "        \n",
    "        self.lock = Lock()\n",
    "        self.lr = 0.0001\n",
    "\n",
    "        num_hidden_units = 512\n",
    "        self.image_memory = np.zeros(self.state_size)\n",
    "        \n",
    "        # Instantiate plot memory\n",
    "        self.scores, self.episodes, self.average = [], [], []\n",
    "\n",
    "        self.Save_Path = 'Models'\n",
    "        \n",
    "        if not os.path.exists(self.Save_Path): os.makedirs(self.Save_Path)\n",
    "        self.path = '{}_IMPALA_{}'.format(self.env_name, self.lr)\n",
    "        self.model_name = os.path.join(self.Save_Path, self.path)\n",
    "\n",
    "        # Create Actor-Critic network model\n",
    "        self.model = OurModel(input_shape=self.state_size, action_space=self.action_size)\n",
    "        \n",
    "        self.optimizer = tf.keras.optimizers.Adam(self.lr)\n",
    "\n",
    "    def remember(self, state, action, policy, reward, done, thread):\n",
    "        if thread == 0:\n",
    "            self.states_1[self.memory_index_1] = state\n",
    "            self.actions_1[self.memory_index_1] = action\n",
    "            self.policies_1[self.memory_index_1] = policy\n",
    "            self.rewards_1[self.memory_index_1] = reward\n",
    "            self.dones_1[self.memory_index_1] = done\n",
    "\n",
    "            if self.memory_index_1 == 100:\n",
    "                for i in range(0, 101):\n",
    "                    self.states[thread][i] = self.states_1[i]\n",
    "                    self.actions[thread][i] = self.actions_1[i]\n",
    "                    self.policies[thread][i] = self.policies_1[i]\n",
    "                    self.rewards[thread][i] = self.rewards_1[i]\n",
    "                    self.dones[thread][i] = self.dones_1[i]\n",
    "\n",
    "                self.deq.append([self.states[thread], self.actions[thread], self.policies[thread], \n",
    "                                 self.rewards[thread], self.dones[thread]])\n",
    "                \n",
    "                self.states_1[0] = self.states_1[self.memory_index_1]\n",
    "                self.actions_1[0] = self.actions_1[self.memory_index_1]\n",
    "                self.policies_1[0] = self.policies_1[self.memory_index_1]\n",
    "                self.rewards_1[0] = self.rewards_1[self.memory_index_1]\n",
    "                self.dones_1[0] = self.dones_1[self.memory_index_1]\n",
    " \n",
    "                self.memory_index_1 = 1\n",
    "                \n",
    "            self.memory_index_1 += 1\n",
    "        elif thread == 1:\n",
    "            self.states_2[self.memory_index_2] = state\n",
    "            self.actions_2[self.memory_index_2] = action\n",
    "            self.policies_2[self.memory_index_2] = policy\n",
    "            self.rewards_2[self.memory_index_2] = reward\n",
    "            self.dones_2[self.memory_index_2] = done\n",
    "\n",
    "            if self.memory_index_2 == 100:\n",
    "                for i in range(0, 101):\n",
    "                    self.states[thread][i] = self.states_2[i]\n",
    "                    self.actions[thread][i] = self.actions_2[i]\n",
    "                    self.policies[thread][i] = self.policies_2[i]\n",
    "                    self.rewards[thread][i] = self.rewards_2[i]\n",
    "                    self.dones[thread][i] = self.dones_2[i]\n",
    "\n",
    "                self.deq.append([self.states[thread], self.actions[thread], self.policies[thread], \n",
    "                                 self.rewards[thread], self.dones[thread]])\n",
    "                    \n",
    "                self.states_2[0] = self.states_2[self.memory_index_2]\n",
    "                self.actions_2[0] = self.actions_2[self.memory_index_2]\n",
    "                self.policies_2[0] = self.policies_2[self.memory_index_2]\n",
    "                self.rewards_2[0] = self.rewards_2[self.memory_index_2]\n",
    "                self.dones_2[0] = self.dones_2[self.memory_index_2]\n",
    "                    \n",
    "                self.memory_index_2 = 1\n",
    "\n",
    "            self.memory_index_2 += 1 \n",
    "    def act(self, state):\n",
    "        #print(\"state.shape: \", state.shape)\n",
    "        prediction = self.model(state, training=False)\n",
    "        dist = tfd.Categorical(logits=prediction[0])\n",
    "        action = int(dist.sample()[0])\n",
    "        policy = prediction[0]\n",
    "        \n",
    "        return action, policy\n",
    "\n",
    "    def update(self, states, actions, agent_policies, rewards, dones):\n",
    "        '''\n",
    "        states.shape:  (8, 100, 80, 80, 4)\n",
    "        actions.shape:  (8, 100)\n",
    "        agent_policies.shape:  (8, 100, 6)\n",
    "        rewards.shape:  (8, 100)\n",
    "        dones.shape:  (8, 100)\n",
    "        '''\n",
    "        states = tf.transpose(states, perm=[1, 0, 2, 3, 4])\n",
    "        actions = tf.transpose(actions, perm=[1, 0])\n",
    "        agent_policies = tf.transpose(agent_policies, perm=[1, 0, 2])\n",
    "        rewards = tf.transpose(rewards, perm=[1, 0])\n",
    "        dones = tf.transpose(dones, perm=[1, 0])\n",
    "        \n",
    "        batch_size = states.shape[0]\n",
    "        \n",
    "        online_variables = self.model.trainable_variables\n",
    "        with tf.GradientTape() as tape:\n",
    "            tape.watch(online_variables)\n",
    "            \n",
    "            # states.shape:  (8, 100, 80, 80, 4)\n",
    "            states_folded = tf.reshape(states, [states.shape[0]*states.shape[1], states.shape[2], states.shape[3], states.shape[4]])\n",
    "\n",
    "            learner_output = self.model(states_folded, training=True)\n",
    "            learner_policies = tf.reshape(learner_output[0], [states.shape[0], states.shape[1], -1])\n",
    "            learner_values = tf.reshape(learner_output[1], [states.shape[0], states.shape[1], -1])\n",
    "            \n",
    "            agent_logits = tf.nn.softmax(agent_policies[:-1])\n",
    "            actions = actions[:-1]\n",
    "            rewards = rewards[1:]\n",
    "            dones = dones[1:]\n",
    "        \n",
    "            learner_logits = tf.nn.softmax(learner_policies[:-1])\n",
    "            \n",
    "            learner_values = tf.squeeze(learner_values, axis=2)\n",
    "            \n",
    "            bootstrap_value = learner_values[-1]\n",
    "            learner_values = learner_values[:-1]\n",
    "            \n",
    "            discounting = 0.99\n",
    "            discounts = tf.cast(~dones, tf.float32) * discounting\n",
    "            \n",
    "            actions = tf.convert_to_tensor(actions, dtype=tf.int32)\n",
    "            \n",
    "            target_action_log_probs = parametric_action_distribution.log_prob(learner_policies[:-1], actions)\n",
    "            behaviour_action_log_probs = parametric_action_distribution.log_prob(agent_policies[:-1], actions)\n",
    "            \n",
    "            lambda_ = 1.0\n",
    "            \n",
    "            log_rhos = target_action_log_probs - behaviour_action_log_probs\n",
    "            \n",
    "            log_rhos = tf.convert_to_tensor(log_rhos, dtype=tf.float32)\n",
    "            discounts = tf.convert_to_tensor(discounts, dtype=tf.float32)\n",
    "            rewards = tf.convert_to_tensor(rewards, dtype=tf.float32)\n",
    "            values = tf.convert_to_tensor(learner_values, dtype=tf.float32)\n",
    "            bootstrap_value = tf.convert_to_tensor(bootstrap_value, dtype=tf.float32)\n",
    "            \n",
    "            clip_rho_threshold = tf.convert_to_tensor(1.0, dtype=tf.float32)\n",
    "            clip_pg_rho_threshold = tf.convert_to_tensor(1.0, dtype=tf.float32)\n",
    "            \n",
    "            rhos = tf.math.exp(log_rhos)\n",
    "            \n",
    "            clipped_rhos = tf.minimum(clip_rho_threshold, rhos, name='clipped_rhos')\n",
    "            \n",
    "            cs = tf.minimum(1.0, rhos, name='cs')\n",
    "            cs *= tf.convert_to_tensor(lambda_, dtype=tf.float32)\n",
    "\n",
    "            values_t_plus_1 = tf.concat([values[1:], tf.expand_dims(bootstrap_value, 0)], axis=0)\n",
    "            deltas = clipped_rhos * (rewards + discounts * values_t_plus_1 - values)\n",
    "        \n",
    "            acc = tf.zeros_like(bootstrap_value)\n",
    "            vs_minus_v_xs = []\n",
    "            for i in range(int(discounts.shape[0]) - 1, -1, -1):\n",
    "                discount, c, delta = discounts[i], cs[i], deltas[i]\n",
    "                acc = delta + discount * c * acc\n",
    "                vs_minus_v_xs.append(acc)  \n",
    "            \n",
    "            vs_minus_v_xs = vs_minus_v_xs[::-1]\n",
    "            \n",
    "            vs = tf.add(vs_minus_v_xs, values, name='vs')\n",
    "            vs_t_plus_1 = tf.concat([vs[1:], tf.expand_dims(bootstrap_value, 0)], axis=0)\n",
    "            clipped_pg_rhos = tf.minimum(clip_pg_rho_threshold, rhos, name='clipped_pg_rhos')\n",
    "            \n",
    "            pg_advantages = (clipped_pg_rhos * (rewards + discounts * vs_t_plus_1 - values))\n",
    "            \n",
    "            vs = tf.stop_gradient(vs)\n",
    "            pg_advantages = tf.stop_gradient(pg_advantages)\n",
    "            \n",
    "            actor_loss = -tf.reduce_mean(target_action_log_probs * pg_advantages)\n",
    "            \n",
    "            baseline_cost = 0.5\n",
    "            v_error = values - vs\n",
    "            critic_loss = baseline_cost * 0.5 * tf.reduce_mean(tf.square(v_error))\n",
    "            \n",
    "            total_loss = actor_loss + critic_loss\n",
    "\n",
    "        grads = tape.gradient(total_loss, self.model.trainable_variables)\n",
    "        self.optimizer.apply_gradients(zip(grads, self.model.trainable_variables))\n",
    "    \n",
    "    def replay(self):\n",
    "        state_list, action_list, policy_list, reward_list, done_list = [], [], [], [], []\n",
    "        for i in range(0, 2):\n",
    "            state, action, policy, reward, done = self.deq.popleft()\n",
    "            \n",
    "            state_list.append(state)\n",
    "            action_list.append(action)\n",
    "            policy_list.append(policy)\n",
    "            reward_list.append(reward)\n",
    "            done_list.append(done)\n",
    "            \n",
    "        state_array = np.array(state_list)\n",
    "        action_array = np.array(action_list)\n",
    "        policy_array = np.array(policy_list)\n",
    "        reward_array = np.array(reward_list)\n",
    "        done_array = np.array(done_list)\n",
    "            \n",
    "        #print(\"state_array.shape: \", state_array.shape)\n",
    "        #print(\"action_array.shape: \", action_array.shape)\n",
    "        #print(\"policy_array.shape: \", policy_array.shape)\n",
    "        #print(\"reward_array.shape: \", reward_array.shape)\n",
    "        #print(\"done_array.shape: \", done_array.shape)\n",
    "        \n",
    "        self.update(state_array, action_array, policy_array, reward_array, done_array)\n",
    "           \n",
    "    def load(self, model_name):\n",
    "        self.model = load_model(model_name, compile=False)\n",
    "\n",
    "    def save(self):\n",
    "        self.model.save(self.model_name)\n",
    "\n",
    "    pylab.figure(figsize=(18, 9))\n",
    "    def PlotModel(self, score, episode):\n",
    "        self.scores.append(score)\n",
    "        self.episodes.append(episode)\n",
    "        self.average.append(sum(self.scores[-50:]) / len(self.scores[-50:]))\n",
    "        if str(episode)[-2:] == \"00\":# much faster than episode % 100\n",
    "            pylab.plot(self.episodes, self.scores, 'b')\n",
    "            pylab.plot(self.episodes, self.average, 'r')\n",
    "            pylab.ylabel('Score', fontsize=18)\n",
    "            pylab.xlabel('Steps', fontsize=18)\n",
    "            try:\n",
    "                pylab.savefig(self.path + \".png\")\n",
    "            except OSError:\n",
    "                pass\n",
    "\n",
    "        return self.average[-1]\n",
    "    \n",
    "    def imshow(self, image, rem_step=0):\n",
    "        #print(\"image[:,:,rem_step].shape: \", image[:,:,rem_step].shape)\n",
    "        \n",
    "        cv2.imshow(\"pong\" + str(rem_step), image[:,:,rem_step])\n",
    "        if cv2.waitKey(25) & 0xFF == ord(\"q\"):\n",
    "            cv2.destroyAllWindows()\n",
    "\n",
    "    def GetImage(self, frame):\n",
    "        #print(\"frame.shape: \", frame.shape)\n",
    "        \n",
    "        # croping frame to 80x80 size\n",
    "        frame_cropped = frame[35:195:2, ::2,:]\n",
    "        if frame_cropped.shape[0] != self.COLS or frame_cropped.shape[1] != self.ROWS:\n",
    "            # OpenCV resize function \n",
    "            frame_cropped = cv2.resize(frame, (self.COLS, self.ROWS), interpolation=cv2.INTER_CUBIC)\n",
    "        \n",
    "        # converting to RGB (numpy way)\n",
    "        frame_rgb = 0.299*frame_cropped[:,:,0] + 0.587*frame_cropped[:,:,1] + 0.114*frame_cropped[:,:,2]\n",
    "        \n",
    "        # converting to Gray (OpenCV way)\n",
    "        #frame_gray = cv2.cvtColor(frame_cropped, cv2.COLOR_BGR2GRAY)     \n",
    "        #print(\"frame_gray.shape: \", frame_gray.shape)\n",
    "        \n",
    "        frame_rgb[frame_rgb < 100] = 0\n",
    "        frame_rgb[frame_rgb >= 100] = 255\n",
    "        # dividing by 255 we expresses value to 0-1 representation\n",
    "        new_frame = np.array(frame_rgb).astype(np.float32) / 255.0\n",
    "\n",
    "        # push our data by 1 frame, similar as deq() function work\n",
    "        self.image_memory = np.roll(self.image_memory, 1, axis=2)\n",
    "\n",
    "        # inserting new frame to free space\n",
    "        self.image_memory[:,:,0] = new_frame\n",
    "\n",
    "        # show image frame   \n",
    "        #self.imshow(self.image_memory, 0)\n",
    "        #self.imshow(self.image_memory, 1)\n",
    "        #self.imshow(self.image_memory, 2)\n",
    "        #self.imshow(self.image_memory, 3)\n",
    "\n",
    "        return np.expand_dims(self.image_memory, axis=0)\n",
    "        \n",
    "    def reset(self, env):\n",
    "        frame = env.reset()\n",
    "        for i in range(self.REM_STEP):\n",
    "            state = self.GetImage(frame)\n",
    "\n",
    "        return state\n",
    "\n",
    "    def step(self, action, env):\n",
    "        next_state, reward, done, info = env.step(action)\n",
    "        next_state = self.GetImage(next_state)\n",
    "        \n",
    "        return next_state, reward, done, info\n",
    "    \n",
    "    def train(self, n_threads):\n",
    "        self.env.close()\n",
    "        # Instantiate one environment per thread\n",
    "        envs = [gym.make(self.env_name) for i in range(n_threads)]\n",
    "\n",
    "        # Create threads\n",
    "        threads = [threading.Thread(\n",
    "                target=self.train_threading,\n",
    "                daemon=True,\n",
    "                args=(self, envs[i], i)) for i in range(n_threads)]\n",
    "\n",
    "        for t in threads:\n",
    "            time.sleep(2)\n",
    "            t.start()\n",
    "            \n",
    "        for t in threads:\n",
    "            time.sleep(10)\n",
    "            t.join()\n",
    "    \n",
    "    def render(self, obs):\n",
    "        cv2.imshow('obs', obs)\n",
    "        cv2.waitKey(1)\n",
    "    \n",
    "    def train_threading(self, agent, env, thread):\n",
    "        max_average = 15.0\n",
    "        total_step_1 = 0\n",
    "        total_step_2 = 0\n",
    "        for e in range(self.EPISODES):\n",
    "            state = self.reset(env)\n",
    "\n",
    "            done = False\n",
    "            score = 0\n",
    "            SAVING = ''\n",
    "            while not done:\n",
    "                #self.env.render()\n",
    "                \n",
    "                action, policy = self.act(state)\n",
    "                next_state, reward, done, _ = self.step(action, env)\n",
    "                \n",
    "                #if self.memory_index != 2:\n",
    "                self.remember(state, action, policy, reward / 20.0, done, thread)\n",
    "\n",
    "                state = next_state\n",
    "                score += reward\n",
    "                if done:\n",
    "                    break\n",
    "                \n",
    "                if total_step_1 % 200 == 0 and thread == 0:\n",
    "                    #print(\"len(self.deq): \", len(self.deq))\n",
    "                    if len(self.deq) > 2:\n",
    "                        self.replay()\n",
    "                \n",
    "            # Update episode count\n",
    "            with self.lock:\n",
    "                average = self.PlotModel(score, self.episode)\n",
    "                # saving best models\n",
    "                if average >= self.max_average:\n",
    "                    self.max_average = average\n",
    "                    #self.save()\n",
    "                    SAVING = \"SAVING\"\n",
    "                else:\n",
    "                    SAVING = \"\"\n",
    "                \n",
    "                #print(\"total_step_1: \", total_step_1)\n",
    "                #print(\"total_step_2: \", total_step_2)\n",
    "                print(\"episode: {}/{}, thread: {}, score: {}, average: {:.2f} {}\".format(self.episode, self.EPISODES, thread, score, average, SAVING))\n",
    "                if(self.episode < self.EPISODES):\n",
    "                    self.episode += 1\n",
    "                 \n",
    "    def test(self, Actor_name, Critic_name):\n",
    "        self.load(Actor_name, Critic_name)\n",
    "        \n",
    "        for e in range(100):\n",
    "            state = self.reset(self.env)\n",
    "            done = False\n",
    "            \n",
    "            score = 0\n",
    "            while not done:\n",
    "                self.env.render()\n",
    "                action = np.argmax(self.Actor.predict(state))\n",
    "                state, reward, done, _ = self.step(action, self.env, state)\n",
    "                score += reward\n",
    "                if done:\n",
    "                    print(\"episode: {}/{}, score: {}\".format(e, self.EPISODES, score))\n",
    "                    break\n",
    "\n",
    "        self.env.close()\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    env_name = 'Pong-v0'\n",
    "    agent = IMPALA_Agent(env_name)\n",
    "    \n",
    "    #agent.run() # use as IMPALA\n",
    "    agent.train(n_threads=2) # use as IMPALA\n",
    "    #agent.test('Models/Pong-v0_A3C_2.5e-05_Actor.h5', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "y5kZIVGNYjO_"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "Pong-v0_IMPALA.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "py37",
   "language": "python",
   "name": "py37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
